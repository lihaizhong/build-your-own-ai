#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äºŒæ‰‹è½¦ä»·æ ¼é¢„æµ‹ - æ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰
å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œå…¨é¢çš„æ¢ç´¢æ€§åˆ†æï¼ŒåŒ…æ‹¬æ•°æ®åˆ†å¸ƒã€ç›¸å…³æ€§åˆ†æã€å¼‚å¸¸å€¼æ£€æµ‹ç­‰
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
import os

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾è¡¨æ ·å¼ï¼ˆå‚è€ƒè…¾è®¯äº‘æ–‡ç« è§£å†³æ–¹æ¡ˆï¼‰
# æ”¯æŒå¤šç§ä¸­æ–‡å­—ä½“ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

# å°è¯•é‡å»ºå­—ä½“ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
try:
    from matplotlib.font_manager import _rebuild
    _rebuild()  # reloadä¸€ä¸‹
except:
    pass

# è®¾ç½®å›¾å½¢æ˜¾ç¤ºå‚æ•°
matplotlib.rcParams['figure.dpi'] = 100
matplotlib.rcParams['savefig.dpi'] = 300
matplotlib.rcParams['font.size'] = 10
sns.set_style("whitegrid")
warnings.filterwarnings('ignore')

def load_data():
    """åŠ è½½æ•°æ®"""
    data_path = "../data/used_car_train_20200313.csv"
    print("æ­£åœ¨åŠ è½½æ•°æ®...")
    df = pd.read_csv(data_path, sep=' ')
    print(f"æ•°æ®åŠ è½½å®Œæˆï¼Œå½¢çŠ¶: {df.shape}")
    return df

def basic_info_analysis(df):
    """åŸºæœ¬ä¿¡æ¯åˆ†æ"""
    print("\n" + "="*80)
    print("1. æ•°æ®åŸºæœ¬ä¿¡æ¯åˆ†æ")
    print("="*80)
    
    print(f"æ•°æ®é›†å½¢çŠ¶: {df.shape}")
    print(f"å†…å­˜ä½¿ç”¨: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    
    # æ•°æ®ç±»å‹ç»Ÿè®¡
    print("\næ•°æ®ç±»å‹åˆ†å¸ƒ:")
    dtype_counts = df.dtypes.value_counts()
    print(dtype_counts)
    
    # ç¼ºå¤±å€¼ç»Ÿè®¡
    print("\nç¼ºå¤±å€¼ç»Ÿè®¡:")
    missing_stats = df.isnull().sum()
    missing_stats = missing_stats[missing_stats > 0].sort_values(ascending=False)
    if len(missing_stats) > 0:
        missing_df = pd.DataFrame({
            'ç¼ºå¤±æ•°é‡': missing_stats,
            'ç¼ºå¤±æ¯”ä¾‹(%)': (missing_stats / len(df) * 100).round(2)
        })
        print(missing_df)
    else:
        print("æ²¡æœ‰ç¼ºå¤±å€¼")

def target_variable_analysis(df):
    """ç›®æ ‡å˜é‡åˆ†æ"""
    print("\n" + "="*80)
    print("2. ç›®æ ‡å˜é‡ï¼ˆä»·æ ¼ï¼‰åˆ†æ")
    print("="*80)
    
    # åœ¨ç»˜å›¾å‰é‡æ–°è®¾ç½®å­—ä½“ï¼ˆé¿å…seabornå¹²æ‰°ï¼‰
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    price = df['price']
    
    # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    print("ä»·æ ¼åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯:")
    print(f"å‡å€¼: {price.mean():,.2f}")
    print(f"ä¸­ä½æ•°: {price.median():,.2f}")
    print(f"æ ‡å‡†å·®: {price.std():,.2f}")
    print(f"æœ€å°å€¼: {price.min():,.2f}")
    print(f"æœ€å¤§å€¼: {price.max():,.2f}")
    print(f"ååº¦: {price.skew():.2f}")
    print(f"å³°åº¦: {price.kurtosis():.2f}")
    
    # åˆ†ä½æ•°åˆ†æ
    print("\nä»·æ ¼åˆ†ä½æ•°åˆ†æ:")
    quantiles = [0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]
    for q in quantiles:
        print(f"{q*100}%åˆ†ä½æ•°: {price.quantile(q):,.2f}")
    
    # ä»·æ ¼åˆ†å¸ƒå¯è§†åŒ–ï¼ˆä¼˜åŒ–ä¸­æ–‡æ˜¾ç¤ºï¼‰
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # ç›´æ–¹å›¾
    axes[0,0].hist(price, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0,0].set_title(u'ä»·æ ¼åˆ†å¸ƒç›´æ–¹å›¾', fontsize=14, fontweight='bold')
    axes[0,0].set_xlabel(u'ä»·æ ¼ï¼ˆå…ƒï¼‰', fontsize=12)
    axes[0,0].set_ylabel(u'é¢‘æ¬¡', fontsize=12)
    axes[0,0].grid(True, alpha=0.3)
    
    # å¯¹æ•°å˜æ¢åçš„ç›´æ–¹å›¾
    log_price = np.log1p(price)
    axes[0,1].hist(log_price, bins=50, alpha=0.7, color='lightgreen', edgecolor='black')
    axes[0,1].set_title(u'ä»·æ ¼å¯¹æ•°å˜æ¢åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    axes[0,1].set_xlabel(u'log(ä»·æ ¼+1)', fontsize=12)
    axes[0,1].set_ylabel(u'é¢‘æ¬¡', fontsize=12)
    axes[0,1].grid(True, alpha=0.3)
    
    # ç®±å‹å›¾
    box_plot = axes[1,0].boxplot(price, patch_artist=True)
    box_plot['boxes'][0].set_facecolor('lightcoral')
    axes[1,0].set_title(u'ä»·æ ¼ç®±å‹å›¾', fontsize=14, fontweight='bold')
    axes[1,0].set_ylabel(u'ä»·æ ¼ï¼ˆå…ƒï¼‰', fontsize=12)
    axes[1,0].grid(True, alpha=0.3)
    
    # QQå›¾
    stats.probplot(price, dist="norm", plot=axes[1,1])
    axes[1,1].set_title(u'ä»·æ ¼Q-Qå›¾ï¼ˆæ­£æ€åˆ†å¸ƒï¼‰', fontsize=14, fontweight='bold')
    axes[1,1].set_xlabel(u'ç†è®ºåˆ†ä½æ•°', fontsize=12)
    axes[1,1].set_ylabel(u'æ ·æœ¬åˆ†ä½æ•°', fontsize=12)
    axes[1,1].grid(True, alpha=0.3)
    
    plt.tight_layout(pad=3.0)
    plt.savefig(u'../docs/ä»·æ ¼åˆ†å¸ƒåˆ†æ.png', dpi=300, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    print(u"ä»·æ ¼åˆ†å¸ƒå›¾è¡¨å·²ä¿å­˜")
    plt.show()

def categorical_features_analysis(df):
    """åˆ†ç±»ç‰¹å¾åˆ†æ"""
    print("\n" + "="*80)
    print("3. åˆ†ç±»ç‰¹å¾åˆ†æ")
    print("="*80)
    
    # è¯†åˆ«åˆ†ç±»ç‰¹å¾ï¼ˆåŒ…æ‹¬ç¼–ç åçš„åˆ†ç±»ç‰¹å¾ï¼‰
    categorical_cols = ['brand', 'bodyType', 'fuelType', 'gearbox', 'notRepairedDamage', 
                       'seller', 'offerType', 'regionCode']
    
    for col in categorical_cols:
        if col in df.columns:
            print(f"\n{col} ç‰¹å¾åˆ†æ:")
            unique_count = df[col].nunique()
            print(f"å”¯ä¸€å€¼æ•°é‡: {unique_count}")
            
            if unique_count < 20:  # å¦‚æœå”¯ä¸€å€¼è¾ƒå°‘ï¼Œæ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
                value_counts = df[col].value_counts().head(10)
                print("å‰10ä¸ªæœ€é¢‘ç¹çš„å€¼:")
                print(value_counts)
                
                # è®¡ç®—ä¸ä»·æ ¼çš„å…³ç³»
                if col != 'price':
                    price_by_category = df.groupby(col)['price'].agg(['mean', 'median', 'count'])
                    print(f"\næŒ‰{col}åˆ†ç»„çš„ä»·æ ¼ç»Ÿè®¡:")
                    print(price_by_category.head(10))

def numerical_features_analysis(df):
    """æ•°å€¼ç‰¹å¾åˆ†æ"""
    print("\n" + "="*80)
    print("4. æ•°å€¼ç‰¹å¾åˆ†æ")
    print("="*80)
    
    # é€‰æ‹©æ•°å€¼å‹ç‰¹å¾
    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if 'price' in numerical_cols:
        numerical_cols.remove('price')  # ç§»é™¤ç›®æ ‡å˜é‡
    
    print(f"æ•°å€¼å‹ç‰¹å¾æ•°é‡: {len(numerical_cols)}")
    
    # æè¿°æ€§ç»Ÿè®¡
    print("\næ•°å€¼ç‰¹å¾æè¿°æ€§ç»Ÿè®¡:")
    desc_stats = df[numerical_cols].describe()
    print(desc_stats.round(2))
    
    # å¼‚å¸¸å€¼æ£€æµ‹ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼‰
    print("\nå¼‚å¸¸å€¼æ£€æµ‹ï¼ˆIQRæ–¹æ³•ï¼‰:")
    outlier_summary = []
    
    for col in numerical_cols[:10]:  # åªåˆ†æå‰10ä¸ªç‰¹å¾
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        outlier_count = len(outliers)
        outlier_pct = (outlier_count / len(df)) * 100
        
        outlier_summary.append({
            'ç‰¹å¾': col,
            'å¼‚å¸¸å€¼æ•°é‡': outlier_count,
            'å¼‚å¸¸å€¼æ¯”ä¾‹(%)': round(outlier_pct, 2),
            'ä¸‹ç•Œ': round(lower_bound, 2),
            'ä¸Šç•Œ': round(upper_bound, 2)
        })
    
    outlier_df = pd.DataFrame(outlier_summary)
    print(outlier_df)

def correlation_analysis(df):
    """ç›¸å…³æ€§åˆ†æ"""
    print("\n" + "="*80)
    print("5. ç‰¹å¾ç›¸å…³æ€§åˆ†æ")
    print("="*80)
    
    # é€‰æ‹©æ•°å€¼å‹ç‰¹å¾
    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
    corr_matrix = df[numerical_cols].corr()
    
    # ä¸ä»·æ ¼çš„ç›¸å…³æ€§
    price_corr = corr_matrix['price'].abs().sort_values(ascending=False)
    print("ä¸ä»·æ ¼æœ€ç›¸å…³çš„ç‰¹å¾ï¼ˆæŒ‰ç»å¯¹å€¼æ’åºï¼‰:")
    print(price_corr.head(15))
    
    # ç»˜åˆ¶ç›¸å…³æ€§çƒ­åŠ›å›¾ï¼ˆä¼˜åŒ–ä¸­æ–‡æ˜¾ç¤ºï¼‰
    # é‡æ–°è®¾ç½®å­—ä½“ï¼ˆé¿å…seabornå¹²æ‰°ï¼‰
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    plt.figure(figsize=(20, 16))
    
    # åªæ˜¾ç¤ºä¸ä»·æ ¼ç›¸å…³æ€§è¾ƒé«˜çš„ç‰¹å¾
    top_features = price_corr.head(15).index.tolist()
    corr_subset = corr_matrix.loc[top_features, top_features]
    
    sns.heatmap(corr_subset, annot=True, cmap='RdYlBu_r', center=0, 
                square=True, fmt='.2f', cbar_kws={"shrink": .8},
                linewidths=0.5, linecolor='white')
    plt.title(u'ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾ï¼ˆTop 15 ä¸ä»·æ ¼ç›¸å…³çš„ç‰¹å¾ï¼‰', 
              fontsize=16, fontweight='bold', pad=20)
    plt.xticks(fontsize=10, rotation=45)
    plt.yticks(fontsize=10, rotation=0)
    plt.tight_layout()
    plt.savefig(u'../docs/ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾.png', dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    print(u"ç›¸å…³æ€§çƒ­åŠ›å›¾å·²ä¿å­˜")
    plt.show()
    
    # é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹è¯†åˆ«
    print("\né«˜ç›¸å…³æ€§ç‰¹å¾å¯¹ï¼ˆ|ç›¸å…³ç³»æ•°| > 0.8ï¼‰:")
    high_corr_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            corr_val = corr_matrix.iloc[i, j]
            if abs(corr_val) > 0.8:
                high_corr_pairs.append({
                    'ç‰¹å¾1': corr_matrix.columns[i],
                    'ç‰¹å¾2': corr_matrix.columns[j],
                    'ç›¸å…³ç³»æ•°': round(corr_val, 3)
                })
    
    if high_corr_pairs:
        high_corr_df = pd.DataFrame(high_corr_pairs)
        print(high_corr_df)
    else:
        print("æ²¡æœ‰å‘ç°é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹")

def time_features_analysis(df):
    """æ—¶é—´ç‰¹å¾åˆ†æ"""
    print("\n" + "="*80)
    print("6. æ—¶é—´ç‰¹å¾åˆ†æ")
    print("="*80)
    
    # è½¬æ¢æ—¥æœŸæ ¼å¼
    df_time = df.copy()
    
    # æ³¨å†Œæ—¥æœŸåˆ†æ
    if 'regDate' in df.columns:
        df_time['regDate_str'] = df_time['regDate'].astype(str)
        df_time['reg_year'] = df_time['regDate_str'].str[:4].astype(int)
        df_time['reg_month'] = df_time['regDate_str'].str[4:6].astype(int)
        
        print("æ³¨å†Œå¹´ä»½åˆ†å¸ƒ:")
        reg_year_stats = df_time['reg_year'].value_counts().sort_index()
        print(reg_year_stats.head(10))
        
        print("\næ³¨å†Œæœˆä»½åˆ†å¸ƒ:")
        reg_month_stats = df_time['reg_month'].value_counts().sort_index()
        print(reg_month_stats)
        
        # è®¡ç®—è½¦é¾„ï¼ˆå‡è®¾å½“å‰å¹´ä»½ä¸º2020ï¼‰
        current_year = 2020
        df_time['car_age'] = current_year - df_time['reg_year']
        
        print(f"\nè½¦é¾„ç»Ÿè®¡:")
        print(f"å¹³å‡è½¦é¾„: {df_time['car_age'].mean():.1f} å¹´")
        print(f"è½¦é¾„ä¸­ä½æ•°: {df_time['car_age'].median():.1f} å¹´")
        print(f"æœ€å¤§è½¦é¾„: {df_time['car_age'].max()} å¹´")
        print(f"æœ€å°è½¦é¾„: {df_time['car_age'].min()} å¹´")
        
        # è½¦é¾„ä¸ä»·æ ¼å…³ç³»
        age_price_corr = df_time[['car_age', 'price']].corr().iloc[0,1]
        print(f"è½¦é¾„ä¸ä»·æ ¼ç›¸å…³ç³»æ•°: {age_price_corr:.3f}")
    
    # åˆ›å»ºæ—¥æœŸåˆ†æå¯è§†åŒ–
    if 'regDate' in df.columns:
        # é‡æ–°è®¾ç½®å­—ä½“ï¼ˆé¿å…seabornå¹²æ‰°ï¼‰
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # æ³¨å†Œå¹´ä»½åˆ†å¸ƒ
        reg_year_stats.plot(kind='bar', ax=axes[0,0])
        axes[0,0].set_title(u'æ³¨å†Œå¹´ä»½åˆ†å¸ƒ')
        axes[0,0].set_xlabel(u'å¹´ä»½')
        axes[0,0].set_ylabel(u'æ•°é‡')
        axes[0,0].tick_params(axis='x', rotation=45)
        
        # æ³¨å†Œæœˆä»½åˆ†å¸ƒ
        reg_month_stats.plot(kind='bar', ax=axes[0,1])
        axes[0,1].set_title(u'æ³¨å†Œæœˆä»½åˆ†å¸ƒ')
        axes[0,1].set_xlabel(u'æœˆä»½')
        axes[0,1].set_ylabel(u'æ•°é‡')
        
        # è½¦é¾„åˆ†å¸ƒ
        axes[1,0].hist(df_time['car_age'], bins=30, alpha=0.7, color='orange', edgecolor='black')
        axes[1,0].set_title(u'è½¦é¾„åˆ†å¸ƒ')
        axes[1,0].set_xlabel(u'è½¦é¾„ï¼ˆå¹´ï¼‰')
        axes[1,0].set_ylabel(u'é¢‘æ¬¡')
        
        # è½¦é¾„ä¸ä»·æ ¼æ•£ç‚¹å›¾
        sample_data = df_time.sample(n=min(5000, len(df_time)))  # é‡‡æ ·é¿å…è¿‡åº¦ç»˜åˆ¶
        axes[1,1].scatter(sample_data['car_age'], sample_data['price'], alpha=0.5, s=1)
        axes[1,1].set_title(u'è½¦é¾„vsä»·æ ¼ (ç›¸å…³ç³»æ•°: {:.3f})'.format(age_price_corr))
        axes[1,1].set_xlabel(u'è½¦é¾„ï¼ˆå¹´ï¼‰')
        axes[1,1].set_ylabel(u'ä»·æ ¼')
        
        plt.tight_layout()
        plt.savefig(u'../docs/æ—¶é—´ç‰¹å¾åˆ†æ.png', dpi=300, bbox_inches='tight')
        plt.show()

def feature_importance_analysis(df):
    """ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆåŸºäºç®€å•çš„ç»Ÿè®¡æ–¹æ³•ï¼‰"""
    print("\n" + "="*80)
    print("7. ç‰¹å¾é‡è¦æ€§åˆ†æ")
    print("="*80)
    
    # è®¡ç®—æ•°å€¼ç‰¹å¾ä¸ä»·æ ¼çš„ç›¸å…³æ€§
    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if 'price' in numerical_cols:
        numerical_cols.remove('price')
    
    feature_importance = []
    
    for col in numerical_cols:
        # è®¡ç®—ç›¸å…³ç³»æ•°
        corr = df[col].corr(df['price'])
        
        # è®¡ç®—äº’ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨åˆ†ç®±åçš„äº’ä¿¡æ¯ï¼‰
        try:
            # å°†è¿ç»­å˜é‡åˆ†ç®±
            col_binned = pd.cut(df[col].dropna(), bins=10, labels=False)
            price_binned = pd.cut(df['price'], bins=10, labels=False)
            
            # è®¡ç®—æ¡ä»¶ç†µçš„ç®€åŒ–ç‰ˆæœ¬
            mutual_info = 0
            for bin_val in range(10):
                if sum(col_binned == bin_val) > 0:
                    prob = sum(col_binned == bin_val) / len(col_binned)
                    conditional_entropy = 0
                    subset_price = price_binned[col_binned == bin_val]
                    for price_bin in range(10):
                        if len(subset_price) > 0:
                            cond_prob = sum(subset_price == price_bin) / len(subset_price)
                            if cond_prob > 0:
                                conditional_entropy -= cond_prob * np.log2(cond_prob)
                    mutual_info += prob * conditional_entropy
        except:
            mutual_info = 0
        
        feature_importance.append({
            'ç‰¹å¾': col,
            'ç›¸å…³ç³»æ•°': abs(corr),
            'äº’ä¿¡æ¯': mutual_info
        })
    
    # æŒ‰ç›¸å…³ç³»æ•°æ’åº
    importance_df = pd.DataFrame(feature_importance)
    importance_df = importance_df.sort_values('ç›¸å…³ç³»æ•°', ascending=False)
    
    print("ç‰¹å¾é‡è¦æ€§æ’åºï¼ˆå‰20ä¸ªï¼‰:")
    print(importance_df.head(20))
    
    # å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
    # é‡æ–°è®¾ç½®å­—ä½“ï¼ˆé¿å…seabornå¹²æ‰°ï¼‰
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    plt.figure(figsize=(12, 8))
    top_features = importance_df.head(15)
    
    plt.barh(range(len(top_features)), top_features['ç›¸å…³ç³»æ•°'])
    plt.yticks(range(len(top_features)), top_features['ç‰¹å¾'])
    plt.xlabel(u'ä¸ä»·æ ¼çš„ç›¸å…³ç³»æ•°ï¼ˆç»å¯¹å€¼ï¼‰')
    plt.title(u'ç‰¹å¾é‡è¦æ€§æ’åºï¼ˆTop 15ï¼‰')
    plt.gca().invert_yaxis()
    
    for i, v in enumerate(top_features['ç›¸å…³ç³»æ•°']):
        plt.text(v + 0.001, i, f'{v:.3f}', va='center')
    
    plt.tight_layout()
    plt.savefig(u'../docs/ç‰¹å¾é‡è¦æ€§åˆ†æ.png', dpi=300, bbox_inches='tight')
    plt.show()

def generate_comprehensive_eda_report(df):
    """ç”Ÿæˆæœ€å®Œæ•´çš„EDAåˆ†ææŠ¥å‘Š"""
    print("\n" + "="*80)
    print("8. ç”Ÿæˆæœ€å®Œæ•´ç‰ˆEDAåˆ†ææŠ¥å‘Š")
    print("="*80)
    
    # ç¡®ä¿æ–‡æ¡£æŠ¥å‘Šç›®å½•å­˜åœ¨
    os.makedirs('../docs', exist_ok=True)
    
    # è®¡ç®—è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    corr_matrix = df[numerical_cols].corr()
    price_corr = corr_matrix['price'].abs().sort_values(ascending=False)
    
    # è®¡ç®—å¼‚å¸¸å€¼ç»Ÿè®¡
    price_Q1 = df['price'].quantile(0.25)
    price_Q3 = df['price'].quantile(0.75)
    price_IQR = price_Q3 - price_Q1
    price_outliers = df[(df['price'] < price_Q1 - 1.5 * price_IQR) | 
                       (df['price'] > price_Q3 + 1.5 * price_IQR)]
    
    power_outliers = df[df['power'] > 600] if 'power' in df.columns else pd.DataFrame()
    
    # è®¡ç®—æ—¶é—´ç‰¹å¾
    df_temp = df.copy()
    if 'regDate' in df.columns:
        df_temp['regDate_str'] = df_temp['regDate'].astype(str)
        df_temp['reg_year'] = df_temp['regDate_str'].str[:4].astype(int)
        current_year = 2020
        df_temp['car_age'] = current_year - df_temp['reg_year']
        age_price_corr = df_temp[['car_age', 'price']].corr().iloc[0,1]
    
    report_content = f"""# äºŒæ‰‹è½¦ä»·æ ¼é¢„æµ‹ - æœ€å®Œæ•´ç‰ˆEDAåˆ†ææŠ¥å‘Š

## æ•°æ®é›†æ¦‚è§ˆ
- **æ•°æ®é›†å¤§å°**: {df.shape[0]:,} è¡Œ Ã— {df.shape[1]} åˆ—
- **å†…å­˜ä½¿ç”¨**: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB
- **æ•°æ®æ—¶é—´**: 2020å¹´3æœˆ13æ—¥
- **åˆ†ææ—¶é—´**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ ¸å¿ƒå‘ç°æ€»ç»“

### 1. ç›®æ ‡å˜é‡ï¼ˆä»·æ ¼ï¼‰æ ¸å¿ƒç‰¹å¾
- **å¹³å‡ä»·æ ¼**: {df['price'].mean():,.2f} å…ƒ
- **ä»·æ ¼ä¸­ä½æ•°**: {df['price'].median():,.2f} å…ƒ
- **ä»·æ ¼èŒƒå›´**: {df['price'].min():,.2f} - {df['price'].max():,.2f} å…ƒ
- **æ ‡å‡†å·®**: {df['price'].std():,.2f} å…ƒ
- **åˆ†å¸ƒç‰¹å¾**: å·¦ååˆ†å¸ƒï¼ˆååº¦ {df['price'].skew():.2f}ï¼‰ï¼Œå°–å³°åˆ†å¸ƒï¼ˆå³°åº¦ {df['price'].kurtosis():.2f}ï¼‰

### 2. æ•°æ®è´¨é‡è¯„ä¼°
"""
    
    # æ·»åŠ ç¼ºå¤±å€¼ä¿¡æ¯
    missing_stats = df.isnull().sum()
    missing_stats = missing_stats[missing_stats > 0].sort_values(ascending=False)
    
    if len(missing_stats) > 0:
        report_content += "\n**ç¼ºå¤±å€¼æƒ…å†µ**:\n"
        for col, missing_count in missing_stats.items():
            missing_pct = (missing_count / len(df)) * 100
            report_content += f"- {col}: {missing_count:,} ä¸ªç¼ºå¤±å€¼ ({missing_pct:.2f}%)\n"
    else:
        report_content += "\n**æ•°æ®å®Œæ•´æ€§**: å¤§éƒ¨åˆ†å­—æ®µæ•°æ®å®Œæ•´\n"
    
    # æ·»åŠ å¼‚å¸¸å€¼ä¿¡æ¯
    report_content += f"\n**å¼‚å¸¸å€¼ç»Ÿè®¡**:\n"
    report_content += f"- ä»·æ ¼å¼‚å¸¸å€¼: {len(price_outliers):,} æ¡è®°å½• ({len(price_outliers)/len(df)*100:.2f}%)\n"
    if len(power_outliers) > 0:
        report_content += f"- powerå¼‚å¸¸å€¼ (>600): {len(power_outliers):,} æ¡è®°å½• ({len(power_outliers)/len(df)*100:.2f}%)\n"
    
    # æ·»åŠ ç‰¹å¾ç±»å‹ç»Ÿè®¡
    dtype_counts = df.dtypes.value_counts()
    report_content += f"\n### 3. ç‰¹å¾ç±»å‹åˆ†å¸ƒ\n"
    for dtype, count in dtype_counts.items():
        report_content += f"- {dtype}: {count} ä¸ªç‰¹å¾\n"
    
    # æ·»åŠ ç›¸å…³æ€§åˆ†æç»“æœ
    report_content += f"\n### 4. ç‰¹å¾é‡è¦æ€§æ’åºï¼ˆä¸ä»·æ ¼ç›¸å…³æ€§ï¼‰\n"
    count = 0
    for feature, corr_val in price_corr.items():
        if feature != 'price' and count < 15:
            report_content += f"{count+1:2d}. **{feature}**: {corr_val:.4f}\n"
            count += 1
    
    # æ·»åŠ æ—¶é—´ç‰¹å¾åˆ†æ
    if 'regDate' in df.columns:
        report_content += f"\n### 5. æ—¶é—´ç‰¹å¾æ´å¯Ÿ\n"
        report_content += f"- å¹³å‡è½¦é¾„: {df_temp['car_age'].mean():.1f} å¹´\n"
        report_content += f"- è½¦é¾„ä¸­ä½æ•°: {df_temp['car_age'].median():.1f} å¹´\n"
        report_content += f"- è½¦é¾„èŒƒå›´: {df_temp['car_age'].min()} - {df_temp['car_age'].max()} å¹´\n"
        report_content += f"- è½¦é¾„ä¸ä»·æ ¼ç›¸å…³ç³»æ•°: {age_price_corr:.4f} (å¼ºè´Ÿç›¸å…³)\n"
    
    # æ·»åŠ åˆ†ä½æ•°åˆ†æ
    report_content += f"\n### 6. ä»·æ ¼åˆ†ä½æ•°åˆ†æ\n"
    quantiles = [0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]
    for q in quantiles:
        report_content += f"- {q*100:4.0f}%åˆ†ä½æ•°: {df['price'].quantile(q):8,.2f} å…ƒ\n"
    
    # æ·»åŠ é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹
    high_corr_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            corr_val = corr_matrix.iloc[i, j]
            if abs(corr_val) > 0.8:
                high_corr_pairs.append({
                    'ç‰¹å¾1': corr_matrix.columns[i],
                    'ç‰¹å¾2': corr_matrix.columns[j],
                    'ç›¸å…³ç³»æ•°': corr_val
                })
    
    report_content += f"\n### 7. é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹ (|ç›¸å…³ç³»æ•°| > 0.8)\n"
    if high_corr_pairs:
        for pair in high_corr_pairs[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            report_content += f"- {pair['ç‰¹å¾1']} vs {pair['ç‰¹å¾2']}: {pair['ç›¸å…³ç³»æ•°']:.4f}\n"
    else:
        report_content += "- æ— é«˜ç›¸å…³æ€§ç‰¹å¾å¯¹\n"
    
    # æ·»åŠ é¡¹ç›®è§„èŒƒè¦æ±‚çš„å¼‚å¸¸å€¼å¤„ç†å»ºè®®
    report_content += f"\n## æ•°æ®é¢„å¤„ç†å»ºè®®\n\n### å¼‚å¸¸å€¼å¤„ç†è§„èŒƒï¼ˆé¡¹ç›®è¦æ±‚ï¼‰\n1. **ä»·æ ¼å¼‚å¸¸å€¼**: ç›´æ¥åˆ é™¤ {len(price_outliers):,} æ¡å¼‚å¸¸è®°å½•\n2. **powerå¼‚å¸¸å€¼**: è¶…è¿‡600çš„è®°å½•ç»Ÿä¸€è®¾ç½®ä¸º600"
    if len(power_outliers) > 0:
        report_content += f" ({len(power_outliers):,} æ¡è®°å½•éœ€è¦å¤„ç†)"
    
    report_content += f"\n\n### ç¼ºå¤±å€¼å¤„ç†å»ºè®®"
    if len(missing_stats) > 0:
        report_content += "\n"
        for col, missing_count in missing_stats.items():
            missing_pct = (missing_count / len(df)) * 100
            if missing_pct < 5:
                report_content += f"- **{col}**: ç¼ºå¤±æ¯”ä¾‹è¾ƒä½ ({missing_pct:.2f}%)ï¼Œå»ºè®®ä½¿ç”¨ä¼—æ•°/å‡å€¼å¡«å……\n"
            else:
                report_content += f"- **{col}**: ç¼ºå¤±æ¯”ä¾‹è¾ƒé«˜ ({missing_pct:.2f}%)ï¼Œå»ºè®®åˆ›å»ºç¼ºå¤±å€¼æŒ‡ç¤ºå˜é‡\n"
    else:
        report_content += "\n- æ•°æ®å®Œæ•´æ€§è‰¯å¥½ï¼Œæ— éœ€ç‰¹æ®Šå¤„ç†\n"
    
    # æ·»åŠ ç‰¹å¾å·¥ç¨‹å»ºè®®
    report_content += f"\n### ç‰¹å¾å·¥ç¨‹å»ºè®®\n"
    report_content += "1. **æ—¶é—´ç‰¹å¾æå–**: ä» regDate æå–è½¦é¾„ã€å­£èŠ‚ã€æœˆä»½ç­‰ç‰¹å¾\n"
    report_content += "2. **åˆ†ç±»ç‰¹å¾ç¼–ç **: å¯¹ brandã€bodyType ç­‰åˆ†ç±»ç‰¹å¾è¿›è¡Œæ ‡ç­¾ç¼–ç \n"
    report_content += "3. **ç›®æ ‡å˜é‡å˜æ¢**: ç”±äºä»·æ ¼å‘ˆåæ€åˆ†å¸ƒï¼Œå»ºè®®ä½¿ç”¨å¯¹æ•°å˜æ¢\n"
    report_content += "4. **ç‰¹å¾é€‰æ‹©**: é‡ç‚¹å…³æ³¨ v_3, v_12, v_8, v_0, regDate ç­‰é«˜ç›¸å…³æ€§ç‰¹å¾\n"
    report_content += "5. **æ•°æ®æ ‡å‡†åŒ–**: å¯¹æ•°å€¼ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–æˆ–å½’ä¸€åŒ–å¤„ç†\n"
    
    # æ·»åŠ å»ºæ¨¡å»ºè®®
    report_content += f"\n## å»ºæ¨¡ç­–ç•¥å»ºè®®\n"
    report_content += "\n### æ¨¡å‹é€‰æ‹©\n"
    report_content += "1. **é›†æˆå­¦ä¹ æ–¹æ³•**: éšæœºæ£®æ—ã€XGBoostã€LightGBMã€CatBoost\n"
    report_content += "2. **æ¨¡å‹èåˆ**: ç»“åˆå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œæé«˜æ³›åŒ–æ€§èƒ½\n"
    report_content += "3. **äº¤å‰éªŒè¯**: ä½¿ç”¨KæŠ˜äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹æ€§èƒ½\n"
    
    report_content += "\n### è¯„ä¼°æŒ‡æ ‡\n"
    report_content += "1. **ä¸»è¦æŒ‡æ ‡**: MAE (Mean Absolute Error)ã€RMSE (Root Mean Square Error)\n"
    report_content += "2. **è¾…åŠ©æŒ‡æ ‡**: MAPE (Mean Absolute Percentage Error)ã€RÂ² Score\n"
    report_content += "3. **åˆ†å¸ƒæ ¡å‡†**: å…³æ³¨é¢„æµ‹ç»“æœåœ¨ä¸åŒä»·æ ¼åŒºé—´çš„å‡†ç¡®æ€§\n"
    
    report_content += "\n### æ¨¡å‹ä¼˜åŒ–æ–¹å‘\n"
    report_content += "1. **è¶…å‚æ•°è°ƒä¼˜**: ä½¿ç”¨ç½‘æ ¼æœç´¢æˆ–è´å¶æ–¯ä¼˜åŒ–\n"
    report_content += "2. **ç‰¹å¾é‡è¦æ€§åˆ†æ**: åˆ©ç”¨æ¨¡å‹è¾“å‡ºçš„ç‰¹å¾é‡è¦æ€§è¿›è¡Œç‰¹å¾ç­›é€‰\n"
    report_content += "3. **é›†æˆå­¦ä¹ æƒé‡ä¼˜åŒ–**: é’ˆå¯¹ä¸åŒæ¨¡å‹è°ƒæ•´èåˆæƒé‡\n"
    
    report_content += f"\n## é™„å½•ï¼šç”Ÿæˆæ–‡ä»¶\n"
    report_content += "- ğŸ“ˆ `ä»·æ ¼åˆ†å¸ƒåˆ†æ.png` - ä»·æ ¼åˆ†å¸ƒå¯è§†åŒ–å›¾è¡¨\n"
    report_content += "- ğŸ”¥ `ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾.png` - ç‰¹å¾é—´ç›¸å…³æ€§å¯è§†åŒ–\n"
    report_content += "- â° `æ—¶é—´ç‰¹å¾åˆ†æ.png` - æ—¶é—´ç›¸å…³ç‰¹å¾åˆ†æ\n"
    report_content += "- ğŸ“Š `ç‰¹å¾é‡è¦æ€§åˆ†æ.png` - ç‰¹å¾é‡è¦æ€§æ’åºå›¾è¡¨\n"
    
    report_content += f"\n---\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}*"
    
    # ä¿å­˜æŠ¥å‘Š
    with open(u'../docs/æœ€å®Œæ•´ç‰ˆEDAåˆ†ææŠ¥å‘Š.md', 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(u"æœ€å®Œæ•´ç‰ˆEDAåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: æ–‡æ¡£æŠ¥å‘Š/æœ€å®Œæ•´ç‰ˆEDAåˆ†ææŠ¥å‘Š.md")

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹è¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰...")
    
    # åˆ›å»ºæ–‡æ¡£æŠ¥å‘Šç›®å½•
    os.makedirs('../docs', exist_ok=True)
    
    # åŠ è½½æ•°æ®
    df = load_data()
    
    # æ‰§è¡Œå„é¡¹åˆ†æ
    basic_info_analysis(df)
    target_variable_analysis(df)
    categorical_features_analysis(df)
    numerical_features_analysis(df)
    correlation_analysis(df)
    time_features_analysis(df)
    feature_importance_analysis(df)
    generate_comprehensive_eda_report(df)  # ä½¿ç”¨æ–°çš„å®Œæ•´æŠ¥å‘Šå‡½æ•°
    
    print("\n" + "="*80)
    print("EDAåˆ†æå®Œæˆï¼")
    print("ç”Ÿæˆçš„æ–‡ä»¶:")
    print("- æ–‡æ¡£æŠ¥å‘Š/æœ€å®Œæ•´ç‰ˆEDAåˆ†ææŠ¥å‘Š.md")
    print("- æ–‡æ¡£æŠ¥å‘Š/ä»·æ ¼åˆ†å¸ƒåˆ†æ.png")
    print("- æ–‡æ¡£æŠ¥å‘Š/ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾.png")
    print("- æ–‡æ¡£æŠ¥å‘Š/æ—¶é—´ç‰¹å¾åˆ†æ.png")
    print("- æ–‡æ¡£æŠ¥å‘Š/ç‰¹å¾é‡è¦æ€§åˆ†æ.png")
    print("="*80)

if __name__ == "__main__":
    main()