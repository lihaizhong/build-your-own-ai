#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äºŒæ‰‹è½¦ä»·æ ¼é¢„æµ‹ - æ•°æ®ç‰¹å¾é¢„å¤„ç†è„šæœ¬
å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿›è¡Œå…¨é¢çš„ç‰¹å¾é¢„å¤„ç†ï¼Œä¿å­˜é¢„å¤„ç†ç»“æœä¾›åç»­æ¨¡å‹è®­ç»ƒä½¿ç”¨

å¤„ç†æµç¨‹ï¼š
1. å¼‚å¸¸å€¼å¤„ç†ï¼ˆä»·æ ¼ã€powerã€notRepairedDamageï¼‰
2. ç¼ºå¤±å€¼å¤„ç†ï¼ˆä¼—æ•°å¡«å…… + æŒ‡ç¤ºå˜é‡ï¼‰
3. æ—¶é—´ç‰¹å¾æå–ï¼ˆè½¦é¾„ã€å¹´ä»½ã€å­£èŠ‚ã€æœˆä»½ï¼‰
4. åˆ†ç±»ç‰¹å¾ç¼–ç ï¼ˆå¤šç§ç¼–ç æ–¹æ³•ï¼‰
5. ç›®æ ‡å˜é‡å˜æ¢ï¼ˆå¯¹æ•°å˜æ¢ï¼‰
6. å¤šé‡å…±çº¿æ€§å¤„ç†ï¼ˆåˆ é™¤å¼ºç›¸å…³ç‰¹å¾ï¼‰
7. æ•°æ®è´¨é‡éªŒè¯

ä½œè€…: AIåŠ©æ‰‹
æ—¥æœŸ: 2025-10-01
"""

import pandas as pd
import numpy as np
import os
import pickle
from datetime import datetime

try:
    from sklearn.preprocessing import LabelEncoder, StandardScaler
    from sklearn.model_selection import train_test_split
    SKLEARN_AVAILABLE = True
except ImportError:
    print("è­¦å‘Šï¼šsklearnæœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬çš„ç¼–ç æ–¹æ³•")
    SKLEARN_AVAILABLE = False
    
    # ç®€åŒ–ç‰ˆLabelEncoder
    class LabelEncoder:
        def __init__(self):
            self.classes_ = {}
            self.class_to_label = {}
            
        def fit_transform(self, data):
            unique_values = pd.Series(data).unique()
            self.classes_ = {i: val for i, val in enumerate(unique_values)}
            self.class_to_label = {val: i for i, val in enumerate(unique_values)}
            return pd.Series(data).map(self.class_to_label)
            
        def transform(self, data):
            return pd.Series(data).map(self.class_to_label).fillna(-1)
    
    # ç®€åŒ–ç‰ˆtrain_test_split
    def train_test_split(X, y, test_size=0.2, random_state=42, stratify=None):
        np.random.seed(random_state)
        n_samples = len(X)
        n_test = int(n_samples * test_size)
        
        indices = np.arange(n_samples)
        np.random.shuffle(indices)
        
        test_indices = indices[:n_test]
        train_indices = indices[n_test:]
        
        return (X.iloc[train_indices], X.iloc[test_indices], 
                y.iloc[train_indices], y.iloc[test_indices])

import warnings
warnings.filterwarnings('ignore')

class CarPricePreprocessor:
    """äºŒæ‰‹è½¦ä»·æ ¼é¢„æµ‹æ•°æ®é¢„å¤„ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é¢„å¤„ç†å™¨"""
        self.label_encoders = {}
        self.freq_encoders = {}
        if SKLEARN_AVAILABLE:
            self.scaler = StandardScaler()
        else:
            self.scaler = None
        self.feature_stats = {}
        self.processing_report = {
            'outliers_removed': 0,
            'missing_filled': {},
            'features_created': 0,
            'features_removed': 0,
            'final_shape': None
        }
    
    def detect_price_outliers(self, df, method='iqr'):
        """
        æ£€æµ‹ä»·æ ¼å¼‚å¸¸å€¼
        Args:
            df: æ•°æ®æ¡†
            method: æ£€æµ‹æ–¹æ³•ï¼Œé»˜è®¤ä½¿ç”¨IQRæ–¹æ³•
        Returns:
            outlier_mask: å¼‚å¸¸å€¼æ©ç 
        """
        if 'price' not in df.columns:
            return pd.Series([False] * len(df), index=df.index)
            
        prices = df['price']
        
        if method == 'iqr':
            Q1 = prices.quantile(0.25)
            Q3 = prices.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outlier_mask = (prices < lower_bound) | (prices > upper_bound)
        
        print(f"ä»·æ ¼å¼‚å¸¸å€¼æ£€æµ‹å®Œæˆï¼šå‘ç° {outlier_mask.sum()} ä¸ªå¼‚å¸¸å€¼")
        return outlier_mask
    
    def handle_outliers(self, df):
        """
        å¤„ç†å¼‚å¸¸å€¼
        1. ä»·æ ¼å¼‚å¸¸å€¼ï¼šç›´æ¥åˆ é™¤
        2. powerå¼‚å¸¸å€¼ï¼šæˆªæ–­åˆ°600
        3. notRepairedDamageå¼‚å¸¸å€¼ï¼š'-' è®¾ç½®ä¸º -1
        """
        print("\n=== å¼€å§‹å¼‚å¸¸å€¼å¤„ç† ===")
        original_shape = df.shape
        
        # 1. å¤„ç†ä»·æ ¼å¼‚å¸¸å€¼ï¼ˆç›´æ¥åˆ é™¤ï¼‰
        if 'price' in df.columns:
            outlier_mask = self.detect_price_outliers(df)
            df = df[~outlier_mask].copy()
            removed_count = outlier_mask.sum()
            self.processing_report['outliers_removed'] = removed_count
            print(f"åˆ é™¤ä»·æ ¼å¼‚å¸¸å€¼ï¼š{removed_count} æ¡è®°å½•")
        
        # 2. å¤„ç†powerå¼‚å¸¸å€¼ï¼ˆæˆªæ–­åˆ°600ï¼‰
        if 'power' in df.columns:
            power_outliers = df['power'] > 600
            outlier_count = power_outliers.sum()
            df.loc[power_outliers, 'power'] = 600
            print(f"powerå¼‚å¸¸å€¼å¤„ç†ï¼š{outlier_count} æ¡è®°å½•è¢«æˆªæ–­åˆ°600")
        
        # 3. å¤„ç†notRepairedDamageå¼‚å¸¸å€¼ï¼ˆ'-' è®¾ç½®ä¸º -1ï¼‰
        if 'notRepairedDamage' in df.columns:
            dash_count = (df['notRepairedDamage'] == '-').sum()
            df['notRepairedDamage'] = df['notRepairedDamage'].replace('-', -1)
            print(f"notRepairedDamageå¼‚å¸¸å€¼å¤„ç†ï¼š{dash_count} æ¡è®°å½•ä»'-'è½¬æ¢ä¸º-1")
        
        print(f"å¼‚å¸¸å€¼å¤„ç†å®Œæˆï¼š{original_shape} -> {df.shape}")
        return df
    
    def handle_missing_values(self, df):
        """
        å¤„ç†ç¼ºå¤±å€¼
        - fuelType: ä¼—æ•°å¡«å…… + ç¼ºå¤±å€¼æŒ‡ç¤ºå˜é‡
        - gearbox, bodyType, model: ä¼—æ•°å¡«å……
        """
        print("\n=== å¼€å§‹ç¼ºå¤±å€¼å¤„ç† ===")
        
        missing_info = {}
        
        # å¤„ç†fuelTypeï¼ˆä¼—æ•°å¡«å…… + ç¼ºå¤±å€¼æŒ‡ç¤ºå˜é‡ï¼‰
        if 'fuelType' in df.columns:
            missing_count = df['fuelType'].isnull().sum()
            if missing_count > 0:
                # åˆ›å»ºç¼ºå¤±å€¼æŒ‡ç¤ºå˜é‡
                df['fuelType_missing'] = df['fuelType'].isnull().astype(int)
                # ä¼—æ•°å¡«å……
                mode_value = df['fuelType'].mode().iloc[0] if not df['fuelType'].mode().empty else 0
                df['fuelType'].fillna(mode_value, inplace=True)
                missing_info['fuelType'] = missing_count
                print(f"fuelTypeç¼ºå¤±å€¼å¤„ç†ï¼š{missing_count} ä¸ªç¼ºå¤±å€¼ï¼Œå·²å¡«å……å¹¶åˆ›å»ºæŒ‡ç¤ºå˜é‡")
        
        # å¤„ç†å…¶ä»–åˆ†ç±»ç‰¹å¾ï¼ˆä¼—æ•°å¡«å……ï¼‰
        categorical_features = ['gearbox', 'bodyType', 'model']
        for feature in categorical_features:
            if feature in df.columns:
                missing_count = df[feature].isnull().sum()
                if missing_count > 0:
                    mode_value = df[feature].mode().iloc[0] if not df[feature].mode().empty else 0
                    df[feature].fillna(mode_value, inplace=True)
                    missing_info[feature] = missing_count
                    print(f"{feature}ç¼ºå¤±å€¼å¤„ç†ï¼š{missing_count} ä¸ªç¼ºå¤±å€¼å·²ç”¨ä¼—æ•°å¡«å……")
        
        self.processing_report['missing_filled'] = missing_info
        print("ç¼ºå¤±å€¼å¤„ç†å®Œæˆ")
        return df
    
    def extract_time_features(self, df):
        """
        æå–æ—¶é—´ç‰¹å¾
        ä»regDateå­—æ®µæå–ï¼šè½¦é¾„ã€æ³¨å†Œå¹´ä»½ã€æ³¨å†Œå­£èŠ‚ã€æ³¨å†Œæœˆä»½
        """
        print("\n=== å¼€å§‹æ—¶é—´ç‰¹å¾æå– ===")
        
        if 'regDate' not in df.columns:
            print("è­¦å‘Šï¼šæœªæ‰¾åˆ°regDateå­—æ®µï¼Œè·³è¿‡æ—¶é—´ç‰¹å¾æå–")
            return df
        
        # å°†regDateè½¬æ¢ä¸ºæ—¥æœŸæ ¼å¼
        df['regDate_str'] = df['regDate'].astype(str)
        
        # è§£ææ—¥æœŸï¼ˆå‡è®¾æ ¼å¼ä¸ºYYYYMMDDï¼‰
        try:
            df['reg_year'] = df['regDate_str'].str[:4].astype(int)
            df['reg_month'] = df['regDate_str'].str[4:6].astype(int)
            df['reg_day'] = df['regDate_str'].str[6:8].astype(int)
            
            # è®¡ç®—è½¦é¾„ï¼ˆä»¥2020å¹´ä¸ºåŸºå‡†ï¼‰
            current_year = 2020
            df['car_age'] = current_year - df['reg_year']
            
            # æ³¨å†Œå­£èŠ‚
            df['reg_season'] = df['reg_month'].apply(
                lambda x: 1 if x in [3,4,5] else 
                         2 if x in [6,7,8] else 
                         3 if x in [9,10,11] else 4
            )
            
            # ä¿ç•™åŸå§‹æ—¶é—´ç‰¹å¾
            time_features = ['car_age', 'reg_year', 'reg_month', 'reg_season']
            self.processing_report['features_created'] += len(time_features)
            
            print(f"æ—¶é—´ç‰¹å¾æå–å®Œæˆï¼š{time_features}")
            
        except Exception as e:
            print(f"æ—¶é—´ç‰¹å¾æå–å¤±è´¥ï¼š{str(e)}")
        
        return df
    
    def encode_categorical_features(self, df, is_training=True):
        """
        åˆ†ç±»ç‰¹å¾ç¼–ç 
        - brand: æ ‡ç­¾ç¼–ç 
        - model: é¢‘æ¬¡ç¼–ç  + æ ‡ç­¾ç¼–ç 
        - bodyType: æ ‡ç­¾ç¼–ç 
        - fuelType: One-Hotç¼–ç 
        - gearbox: äºŒè¿›åˆ¶ç¼–ç 
        - notRepairedDamage: One-Hotç¼–ç 
        """
        print("\n=== å¼€å§‹åˆ†ç±»ç‰¹å¾ç¼–ç  ===")
        
        # 1. brandæ ‡ç­¾ç¼–ç 
        if 'brand' in df.columns:
            if is_training:
                self.label_encoders['brand'] = LabelEncoder()
                df['brand_encoded'] = self.label_encoders['brand'].fit_transform(df['brand'])
            else:
                df['brand_encoded'] = self.label_encoders['brand'].transform(df['brand'])
            print("brandæ ‡ç­¾ç¼–ç å®Œæˆ")
        
        # 2. modelé¢‘æ¬¡ç¼–ç  + æ ‡ç­¾ç¼–ç 
        if 'model' in df.columns:
            if is_training:
                # é¢‘æ¬¡ç¼–ç 
                model_freq = df['model'].value_counts().to_dict()
                self.freq_encoders['model'] = model_freq
                df['model_freq'] = df['model'].map(model_freq)
                
                # æ ‡ç­¾ç¼–ç 
                self.label_encoders['model'] = LabelEncoder()
                df['model_encoded'] = self.label_encoders['model'].fit_transform(df['model'])
            else:
                df['model_freq'] = df['model'].map(self.freq_encoders['model']).fillna(0)
                df['model_encoded'] = self.label_encoders['model'].transform(df['model'])
            print("modelé¢‘æ¬¡ç¼–ç +æ ‡ç­¾ç¼–ç å®Œæˆ")
        
        # 3. bodyTypeæ ‡ç­¾ç¼–ç 
        if 'bodyType' in df.columns:
            if is_training:
                self.label_encoders['bodyType'] = LabelEncoder()
                df['bodyType_encoded'] = self.label_encoders['bodyType'].fit_transform(df['bodyType'])
            else:
                df['bodyType_encoded'] = self.label_encoders['bodyType'].transform(df['bodyType'])
            print("bodyTypeæ ‡ç­¾ç¼–ç å®Œæˆ")
        
        # 4. fuelType One-Hotç¼–ç 
        if 'fuelType' in df.columns:
            fuel_dummies = pd.get_dummies(df['fuelType'], prefix='fuelType')
            df = pd.concat([df, fuel_dummies], axis=1)
            print("fuelType One-Hotç¼–ç å®Œæˆ")
        
        # 5. gearboxäºŒè¿›åˆ¶ç¼–ç 
        if 'gearbox' in df.columns:
            df['gearbox_binary'] = df['gearbox'].astype(int)
            print("gearboxäºŒè¿›åˆ¶ç¼–ç å®Œæˆ")
        
        # 6. notRepairedDamage One-Hotç¼–ç 
        if 'notRepairedDamage' in df.columns:
            damage_dummies = pd.get_dummies(df['notRepairedDamage'], prefix='notRepairedDamage')
            df = pd.concat([df, damage_dummies], axis=1)
            print("notRepairedDamage One-Hotç¼–ç å®Œæˆ")
        
        return df
    
    def apply_target_transformation(self, df):
        """
        ç›®æ ‡å˜é‡å˜æ¢
        å¯¹priceè¿›è¡Œå¯¹æ•°å˜æ¢ä»¥æ”¹å–„åˆ†å¸ƒ
        """
        print("\n=== å¼€å§‹ç›®æ ‡å˜é‡å˜æ¢ ===")
        
        if 'price' in df.columns:
            # æ£€æŸ¥æ˜¯å¦æœ‰é›¶å€¼æˆ–è´Ÿå€¼
            if (df['price'] <= 0).any():
                print("è­¦å‘Šï¼špriceä¸­å­˜åœ¨é›¶å€¼æˆ–è´Ÿå€¼ï¼Œå°†ä½¿ç”¨log1på˜æ¢")
                df['price_log'] = np.log1p(df['price'])
            else:
                df['price_log'] = np.log(df['price'])
            
            print("priceå¯¹æ•°å˜æ¢å®Œæˆ")
        
        return df
    
    def remove_multicollinearity_features(self, df):
        """
        åˆ é™¤å¤šé‡å…±çº¿æ€§ç‰¹å¾
        åˆ é™¤ï¼šv_1, v_7, v_4, v_8, v_2, v_12
        """
        print("\n=== å¼€å§‹å¤šé‡å…±çº¿æ€§å¤„ç† ===")
        
        features_to_remove = ['v_1', 'v_7', 'v_4', 'v_8', 'v_2', 'v_12']
        
        removed_features = []
        for feature in features_to_remove:
            if feature in df.columns:
                df.drop(feature, axis=1, inplace=True)
                removed_features.append(feature)
        
        self.processing_report['features_removed'] = len(removed_features)
        print(f"åˆ é™¤å¤šé‡å…±çº¿æ€§ç‰¹å¾ï¼š{removed_features}")
        
        return df
    
    def remove_irrelevant_features(self, df):
        """
        åˆ é™¤æ— å…³ç‰¹å¾
        åˆ é™¤ï¼šSaleID, name, offerType, seller
        """
        print("\n=== å¼€å§‹åˆ é™¤æ— å…³ç‰¹å¾ ===")
        
        irrelevant_features = ['SaleID', 'name', 'offerType', 'seller']
        
        removed_features = []
        for feature in irrelevant_features:
            if feature in df.columns:
                df.drop(feature, axis=1, inplace=True)
                removed_features.append(feature)
        
        print(f"åˆ é™¤æ— å…³ç‰¹å¾ï¼š{removed_features}")
        
        return df
    
    def validate_data_quality(self, df, dataset_name="æ•°æ®é›†"):
        """
        æ•°æ®è´¨é‡éªŒè¯
        """
        print(f"\n=== {dataset_name}è´¨é‡éªŒè¯ ===")
        
        # 1. å®Œæ•´æ€§æ£€æŸ¥
        missing_count = df.isnull().sum().sum()
        completeness_rate = (1 - missing_count / (df.shape[0] * df.shape[1])) * 100
        print(f"æ•°æ®å®Œæ•´ç‡: {completeness_rate:.2f}%")
        
        # 2. å¼‚å¸¸å€¼æ¯”ä¾‹æ£€æŸ¥
        if 'price' in df.columns:
            outlier_mask = self.detect_price_outliers(df)
            outlier_rate = (outlier_mask.sum() / len(df)) * 100
            print(f"ä»·æ ¼å¼‚å¸¸å€¼æ¯”ä¾‹: {outlier_rate:.2f}%")
        
        # 3. æ•°æ®ç±»å‹æ£€æŸ¥
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        print(f"æ•°å€¼ç‰¹å¾æ•°é‡: {len(numeric_cols)}")
        
        # 4. ç‰¹å¾æœ‰æ•ˆæ€§è¯„åˆ†ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if 'price' in df.columns:
            correlations = df[numeric_cols].corr()['price'].abs()
            avg_correlation = correlations.drop('price').mean()
            print(f"ç‰¹å¾æœ‰æ•ˆæ€§è¯„åˆ†: {avg_correlation:.3f}")
        
        # è´¨é‡æŒ‡æ ‡è¯„ä¼°
        quality_checks = {
            'æ•°æ®å®Œæ•´ç‡ > 99%': completeness_rate > 99,
            'å¼‚å¸¸å€¼æ¯”ä¾‹ < 1%': outlier_rate < 1 if 'price' in df.columns else True,
            'ç‰¹å¾æœ‰æ•ˆæ€§è¯„åˆ† > 0.8': avg_correlation > 0.8 if 'price' in df.columns else True
        }
        
        print("è´¨é‡æŒ‡æ ‡æ£€æŸ¥:")
        for check, passed in quality_checks.items():
            status = "âœ… é€šè¿‡" if passed else "âŒ æœªé€šè¿‡"
            print(f"  {check}: {status}")
        
        return df
    
    def prepare_modeling_data(self, df):
        """
        å»ºæ¨¡æ•°æ®å‡†å¤‡
        åˆ†å±‚æŠ½æ ·åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        """
        print("\n=== å»ºæ¨¡æ•°æ®å‡†å¤‡ ===")
        
        if 'price' not in df.columns:
            print("æµ‹è¯•é›†æ— éœ€åˆ’åˆ†")
            return df, None
        
        # åˆ†å±‚æŠ½æ ·ï¼ˆåŸºäºä»·æ ¼åˆ†ä½æ•°ï¼‰
        df['price_quartile'] = pd.qcut(df['price'], q=4, labels=False)
        
        # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
        feature_cols = [col for col in df.columns if col not in ['price', 'price_log', 'price_quartile']]
        X = df[feature_cols]
        y = df['price_log'] if 'price_log' in df.columns else df['price']
        
        # åˆ†å±‚åˆ’åˆ†
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, 
            test_size=0.2, 
            random_state=42, 
            stratify=df['price_quartile']
        )
        
        # é‡æ–°ç»„åˆæ•°æ®
        train_data = pd.concat([X_train, y_train], axis=1)
        val_data = pd.concat([X_val, y_val], axis=1)
        
        print(f"è®­ç»ƒé›†å¤§å°: {train_data.shape}")
        print(f"éªŒè¯é›†å¤§å°: {val_data.shape}")
        
        return train_data, val_data
    
    def process_dataset(self, df, is_training=True):
        """
        å®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµç¨‹
        """
        print(f"\n{'='*60}")
        print(f"å¼€å§‹å¤„ç†{'è®­ç»ƒé›†' if is_training else 'æµ‹è¯•é›†'}")
        print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"{'='*60}")
        
        # 1. å¼‚å¸¸å€¼å¤„ç†
        df = self.handle_outliers(df)
        
        # 2. ç¼ºå¤±å€¼å¤„ç†
        df = self.handle_missing_values(df)
        
        # 3. æ—¶é—´ç‰¹å¾æå–
        df = self.extract_time_features(df)
        
        # 4. åˆ†ç±»ç‰¹å¾ç¼–ç 
        df = self.encode_categorical_features(df, is_training)
        
        # 5. ç›®æ ‡å˜é‡å˜æ¢ï¼ˆä»…è®­ç»ƒé›†ï¼‰
        if is_training and 'price' in df.columns:
            df = self.apply_target_transformation(df)
        
        # 6. åˆ é™¤æ— å…³ç‰¹å¾
        df = self.remove_irrelevant_features(df)
        
        # 7. å¤šé‡å…±çº¿æ€§å¤„ç†
        df = self.remove_multicollinearity_features(df)
        
        # 8. æ•°æ®è´¨é‡éªŒè¯
        df = self.validate_data_quality(df, "è®­ç»ƒé›†" if is_training else "æµ‹è¯•é›†")
        
        self.processing_report['final_shape'] = df.shape
        
        print(f"\né¢„å¤„ç†å®Œæˆï¼æœ€ç»ˆæ•°æ®å½¢çŠ¶: {df.shape}")
        
        return df

def main():
    """ä¸»å‡½æ•°"""
    print("äºŒæ‰‹è½¦ä»·æ ¼é¢„æµ‹ - æ•°æ®ç‰¹å¾é¢„å¤„ç†")
    print("="*60)
    
    data_dir = "../data"
    # åˆ›å»ºä¸´æ—¶æ•°æ®ç›®å½•
    temp_dir = "../temp"
    if not os.path.exists(temp_dir):
        os.makedirs(temp_dir)
        print(f"åˆ›å»ºä¸´æ—¶æ•°æ®ç›®å½•: {temp_dir}")
    
    # åˆå§‹åŒ–é¢„å¤„ç†å™¨
    preprocessor = CarPricePreprocessor()
    
    try:
        # è¯»å–è®­ç»ƒé›†
        print("\nè¯»å–è®­ç»ƒé›†...")
        train_path = os.path.join(data_dir, "used_car_train_20200313.csv")
        train_df = pd.read_csv(train_path, sep=' ')
        print(f"è®­ç»ƒé›†åŠ è½½æˆåŠŸ: {train_df.shape}")
        
        # å¤„ç†è®­ç»ƒé›†
        train_processed = preprocessor.process_dataset(train_df, is_training=True)
        
        # å‡†å¤‡å»ºæ¨¡æ•°æ®ï¼ˆåˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼‰
        train_final, val_final = preprocessor.prepare_modeling_data(train_processed)
        
        # ä¿å­˜è®­ç»ƒé›†
        train_save_path = os.path.join(temp_dir, "used_car_train_preprocess.csv")
        train_processed.to_csv(train_save_path, index=False)
        print(f"è®­ç»ƒé›†ä¿å­˜æˆåŠŸ: {train_save_path}")
        
        # è¯»å–æµ‹è¯•é›†
        print("\nè¯»å–æµ‹è¯•é›†...")
        test_path = os.path.join(data_dir, "used_car_testB_20200421.csv")
        test_df = pd.read_csv(test_path, sep=' ')
        print(f"æµ‹è¯•é›†åŠ è½½æˆåŠŸ: {test_df.shape}")
        
        # å¤„ç†æµ‹è¯•é›†
        test_processed = preprocessor.process_dataset(test_df, is_training=False)
        
        # ä¿å­˜æµ‹è¯•é›†
        test_save_path = os.path.join(temp_dir, "used_car_testB_preprocess.csv")
        test_processed.to_csv(test_save_path, index=False)
        print(f"æµ‹è¯•é›†ä¿å­˜æˆåŠŸ: {test_save_path}")
        
        # ä¿å­˜é¢„å¤„ç†å™¨å¯¹è±¡
        preprocessor_path = os.path.join(temp_dir, "preprocessor.pkl")
        with open(preprocessor_path, 'wb') as f:
            pickle.dump(preprocessor, f)
        print(f"é¢„å¤„ç†å™¨ä¿å­˜æˆåŠŸ: {preprocessor_path}")
        
        # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
        print("\n" + "="*60)
        print("æ•°æ®é¢„å¤„ç†å®ŒæˆæŠ¥å‘Š")
        print("="*60)
        print(f"å¼‚å¸¸å€¼åˆ é™¤æ•°é‡: {preprocessor.processing_report['outliers_removed']}")
        print(f"ç¼ºå¤±å€¼å¡«å……æƒ…å†µ: {preprocessor.processing_report['missing_filled']}")
        print(f"æ–°å¢ç‰¹å¾æ•°é‡: {preprocessor.processing_report['features_created']}")
        print(f"åˆ é™¤ç‰¹å¾æ•°é‡: {preprocessor.processing_report['features_removed']}")
        print(f"æœ€ç»ˆæ•°æ®å½¢çŠ¶: {preprocessor.processing_report['final_shape']}")
        
        print(f"\nâœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“ è®­ç»ƒé›†: {train_save_path}")
        print(f"ğŸ“ æµ‹è¯•é›†: {test_save_path}")
        print(f"ğŸ”§ é¢„å¤„ç†å™¨: {preprocessor_path}")
        
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()