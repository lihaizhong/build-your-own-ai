# 二手车价格预测模型优化方案

## 📊 问题诊断

### 原始模型问题
- **本地验证 MAE**: 445.60
- **线上提交 MAE**: 1030.1062
- **差距**: **584.51** (偏差率 130%)

### 根本原因分析

| 指标 | 训练集 | 验证集 | 测试集预测 | 问题 |
|------|--------|--------|------------|------|
| 均值 | 4,378 | 4,339 | **5,295** ⚠️ | 预测值系统性**偏高** |
| 中位数 | 2,900 | 2,850 | **3,242** ⚠️ | 中位数偏移 342 |
| 标准差 | 4,085 | 4,070 | **5,177** ⚠️ | 方差差异达 **1,092** |

### 关键问题点

1. **训练集分布偏移**
   - 原模型删除了价格异常值 (使用IQR方法)
   - 导致训练集价格均值从 5,923 降到 4,378
   - 训练集标准差从 7,502 降到 4,085
   - **结果**: 模型在低价区间过拟合,在高价区间表现差

2. **过拟合严重**
   - 验证集来自训练集,分布一致,所以MAE很低(445)
   - 测试集B可能包含更多高价车或不同分布样本
   - 模型泛化能力不足

3. **特征分布不一致**
   - 训练集和测试集在关键特征上存在分布差异
   - 缺乏特征缩放和鲁棒性处理

---

## 🔧 优化方案

### 优化策略对比

| 优化点 | 原模型 | 优化模型 V2 | 改进效果 |
|--------|--------|-------------|----------|
| **异常值处理** | 删除异常值 (IQR) | ✅ **保留异常值** | 保持完整分布 |
| **训练集大小** | 139,647 样本 | ✅ **150,000 样本** | 增加 10,353 样本 |
| **训练集均值** | 4,378 | ✅ **5,923** | 更接近真实分布 |
| **特征缩放** | 无 | ✅ **RobustScaler** | 降低异常值影响 |
| **模型复杂度** | 高 (易过拟合) | ✅ **降低复杂度** | 增强泛化能力 |
| **正则化** | 弱 (λ=0.1) | ✅ **强正则化 (λ=0.5)** | 防止过拟合 |
| **验证方式** | 单次分割 | ✅ **5折交叉验证** | 更稳健评估 |
| **集成方式** | Stacking | ✅ **加权平均** | 更稳定 |
| **预测校准** | 无 | ✅ **分布校准** | 调整到训练集分布 |

### 详细优化措施

#### 1. 保留价格异常值 ✅
```python
# 原模型: 删除异常值
Q1 = train_df['price'].quantile(0.25)
Q3 = train_df['price'].quantile(0.75)
IQR = Q3 - Q1
train_df = train_df[(train_df['price'] >= Q1 - 1.5*IQR) & 
                    (train_df['price'] <= Q3 + 1.5*IQR)]
# 结果: 丢失 10,353 个样本

# 优化模型: 保留所有样本
# 不删除任何价格数据,保持完整分布
```

**理由**: 测试集B可能包含高价车,删除训练集高价样本会导致模型无法学习高价区间的模式。

#### 2. 特征缩放 (RobustScaler) ✅
```python
from sklearn.preprocessing import RobustScaler

scaler = RobustScaler()  # 基于中位数和IQR,对异常值鲁棒
X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])
X_test[numeric_features] = scaler.transform(X_test[numeric_features])
```

**理由**: 降低特征分布差异的影响,提高模型对不同数据分布的适应性。

#### 3. 降低模型复杂度 ✅

| 参数 | 原模型 | 优化模型 | 说明 |
|------|--------|----------|------|
| LGB num_leaves | 64 | **31** ⬇️ | 降低树复杂度 |
| LGB max_depth | 6 | **5** ⬇️ | 减少深度 |
| LGB min_data_in_leaf | 50 | **100** ⬆️ | 增加叶节点最小样本 |
| LGB n_estimators | 300 | **200** ⬇️ | 减少树的数量 |
| RF n_estimators | 200 | **150** ⬇️ | 减少树的数量 |
| RF max_depth | 6 | **5** ⬇️ | 减少深度 |

**理由**: 降低模型复杂度,防止在训练集上过拟合,增强泛化能力。

#### 4. 增强正则化 ✅
```python
# LightGBM
'lambda_l1': 0.5,  # 原: 0.1
'lambda_l2': 0.5,  # 原: 0.1
'feature_fraction': 0.7,  # 原: 0.8
'bagging_fraction': 0.7,  # 原: 0.8

# Ridge
Ridge(alpha=10.0)  # 原: 1.0
```

**理由**: 更强的正则化可以防止模型记忆训练集特征,提高泛化能力。

#### 5. 5折交叉验证 ✅
```python
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
# 结果: 666.44 ± 6.80
```

**理由**: 
- 更准确地评估模型真实性能
- 降低评估方差 (标准差仅 6.80)
- 5折平均MAE (666.44) 比单次验证 (445.60) 更可靠

#### 6. 加权平均替代Stacking ✅
```python
# 原模型: Stacking (容易过拟合)
meta_model = Ridge(alpha=1.0)
meta_model.fit(stack_train, y_val)

# 优化模型: 加权平均 (更稳定)
final_pred = 0.5 * lgb_pred + 0.3 * rf_pred + 0.2 * ridge_pred
```

**理由**: 加权平均更简单,不会在小验证集上过拟合。

#### 7. 预测值校准 ✅
```python
# 计算训练集和预测集的分布差异
train_mean = 5923.33
pred_mean = 5622.22
calibration_factor = 0.3

# 温和调整预测值
final_pred_calibrated = final_pred - 0.3 * (pred_mean - train_mean)
# 结果: 预测均值从 5622 调整到 5713
```

**理由**: 将预测分布拉近训练集分布,但避免过度调整。

---

## 📈 优化效果预期

### 本地验证对比

| 模型版本 | 验证方式 | MAE | 说明 |
|----------|----------|-----|------|
| 原模型 | 单次分割 | 445.60 | 过于乐观,存在过拟合 |
| 优化模型 | 5折交叉验证 | **666.44 ± 6.80** | 更真实的性能评估 |

### 预期线上效果

| 场景 | 原模型 | 优化模型 | 改进 |
|------|--------|----------|------|
| 本地验证 | 445.60 | 666.44 | 更保守但更真实 |
| 线上提交 | 1030.10 | **预期 650-750** | 大幅降低 |
| 线上线下差距 | 584.50 | **预期 <100** | 显著缩小 |

### 关键改进点

1. ✅ **保留完整分布**: 训练集均值从 4,378 恢复到 5,923
2. ✅ **降低过拟合**: 模型复杂度降低,正则化增强
3. ✅ **提高鲁棒性**: 特征缩放 + 5折交叉验证
4. ✅ **预测校准**: 调整预测分布接近训练集
5. ✅ **更稳定**: 交叉验证标准差仅 6.80

---

## 🎯 下一步建议

### 提交验证
1. 将生成的 `lgmb_modeling_v2_*.csv` 文件提交到平台
2. 查看线上MAE是否在 650-750 区间
3. 如果效果仍不理想,可以尝试以下进一步优化

### 进一步优化方向

如果线上MAE仍 > 750,可以考虑:

1. **特征工程增强**
   - 添加更多交叉特征
   - 分析测试集B的特征分布,针对性调整

2. **分层建模**
   - 按价格区间训练不同的模型
   - 高价车(>10000)单独建模

3. **调整校准因子**
   - 当前校准强度为 30%
   - 可以尝试 40%-50% 的更强校准

4. **使用分位数回归**
   - LightGBM objective 改为 'quantile'
   - alpha=0.5 (中位数回归)

5. **集成更多模型**
   - 添加 XGBoost, CatBoost
   - 使用 Voting 或 Blending

---

## 📝 总结

### 核心问题
原模型因删除异常值导致训练集分布偏移,在低价区间过拟合,泛化能力差。

### 解决方案
1. 保留完整数据分布
2. 降低模型复杂度
3. 增强正则化
4. 使用更稳健的评估方法
5. 应用预测值校准

### 预期效果
- 本地MAE: 666.44 (更真实)
- 线上MAE: 预期 650-750 (大幅改善)
- 线上线下差距: 预期缩小到 <100

---

## 🔗 相关文件

- **原模型**: `lgmb_modeling.py`
- **优化模型**: `lgmb_modeling_v2.py`
- **诊断脚本**: `model_diagnosis.py`
- **诊断图表**: `user_data/diagnosis/`
- **预测结果**: `prediction_result/lgmb_v2_optimized_*.csv`

---

**最后更新**: 2025-10-21 00:26
