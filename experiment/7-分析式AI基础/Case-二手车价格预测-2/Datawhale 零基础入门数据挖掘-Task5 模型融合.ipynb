{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320a0974",
   "metadata": {},
   "source": [
    "# 一、模型融合目标\n",
    "\n",
    "- 对于多种调参完成的模型进行融合。\n",
    "- 完成对于多种模型的融合，提交融合结果并打卡。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66796287",
   "metadata": {},
   "source": [
    "# 二、内容介绍\n",
    "\n",
    "模型融合是比赛后期一个重要的环节。大体来说，有如下的类型方式：\n",
    "\n",
    "1. 简单加权融合：\n",
    "    - 回归（分类概率）：算术平均融合（Arithmetic Mean），几何平均融合（Geometric Mean）；\n",
    "    - 分类：投票（Voting）；\n",
    "    - 综合：排序融合（Rank Averaging），log融合；\n",
    "2. stacking/blending：\n",
    "    - 构建多层模型，并利用预测结果再拟合预测。\n",
    "3. boosting/bagging（在 XGBoost，AdaBoost，GBDT 中已经用到）：\n",
    "    - 多树的提升方法；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8613a854",
   "metadata": {},
   "source": [
    "# 三、Stacking 相关理论介绍\n",
    "\n",
    "## 什么是 stacking\n",
    "\n",
    "简单来说，stacking 就是当用初始训练数据学习出若干个基学习器后，将这几个学习器的预测结果作为新的训练集，来学习一个新的学习器。\n",
    "\n",
    "![Concept Diagram of Stacking](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/2326541042/1584448793231_6TygjXwjNb.jpg)\n",
    "\n",
    "将个体学习器结合在一起的时候，使用的方法叫做 **结合策略**。对于分类问题，我们可以使用投票法来选择输出最多的类。对于回归问题，我们可以将分类器输出的结果求平均值。\n",
    "\n",
    "上面说的 **投票法** 和 **平均法** 都是很有效的结合策略。还有一种结合策略是使用另外一个机器学习算法来将个体机器学习器的结果结合在一起，这个方法就是 **stacking**。\n",
    "\n",
    "在 stacking 方法中，我们把个体学习器叫做 **初级学习器**，用于结合的学习器叫做 **次级学习器** 或 **元学习器（meta-learner）**，次级学习器用于训练的数据叫做 **次级训练集**。次级训练集是在训练集上用初级学习器得到的。\n",
    "\n",
    "## 如何进行 stacking\n",
    "\n",
    "算法示意图如下：\n",
    "\n",
    "![Stacking 算法](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/2326541042/1584448806789_1ElRtHaacw.jpg)\n",
    "\n",
    "> 引用自 西瓜书《机器学习》\n",
    "\n",
    "- 过程 1-3 是训练出来个体学习器，也就是初级学习器。\n",
    "- 过程 5-9 是使用训练出来的个体学习器得来的预测结果，这个预测的结果当做次级学习器的训练集。\n",
    "- 过程 11 是用初级学习器预测的结果训练出次级学习器，得到我们最后训练的模型。\n",
    "\n",
    "## Stacking 的方法讲解\n",
    "\n",
    "首先，我们先从一种“不那么正确”但是容易懂的 Stacking 方法讲起。\n",
    "\n",
    "Stacking 模型本质上是一种分层的结构，这里简单起见，只分析二级 Stacking。假设我们有 2 个基模型 Model1_1、Model1_2 和 一个次级模型 Model2。\n",
    "\n",
    "**Step 1**：基模型 Model1_1，对训练集 train 训练，然后用于预测 train 和 test 的标签列，分别是 P1，T1\n",
    "\n",
    "Model1_1 模型训练：\n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        X_{train} \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "\\substack{\n",
    "    Model1\\_1\\;Train \\\\\n",
    "    \\overbrace\\Longrightarrow\n",
    "}\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        Y_{true} \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "训练后的模型 Model1_1 分别在 train 和 test 上预测，得到预测标签分别是 P1, T1\n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        X_{train} \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "\\substack{\n",
    "    Model1\\_1\\;Predict \\\\\n",
    "    \\overbrace\\Longrightarrow\n",
    "}\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        P_1 \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        X_{test} \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "\\substack{\n",
    "    Model1\\_1\\;Predict \\\\\n",
    "    \\overbrace\\Longrightarrow\n",
    "}\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        T_1 \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "**Step 2**：基模型 Model1_2，对训练集 train 训练，然后用于预测 train 和 test 的标签列，分别是 P2，T2\n",
    "\n",
    "Model1_2 模型训练：\n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        X_{train} \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "\\substack{\n",
    "    Model1\\_2\\;Train \\\\\n",
    "    \\overbrace\\Longrightarrow\n",
    "}\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        Y_{true} \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "训练后的模型 Model1_2 分别在 train 和 test 上预测，得到预测标签分别是 P2，T2\n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        X_{train} \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "\\substack{\n",
    "    Model1\\_2\\;Predict \\\\\n",
    "    \\overbrace\\Longrightarrow\n",
    "}\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        P_2 \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        X_{test} \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "\\substack{\n",
    "    Model1\\_2\\;Predict \\\\\n",
    "    \\overbrace\\Longrightarrow\n",
    "}\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        T_2 \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "**Step 3**：分别把 P1，P2 以及 T1，T2 合并，得到一个新的训练集和测试集 train2，test2。\n",
    "$$\n",
    "\\substack{\n",
    "    Train_2 \\\\\n",
    "    \\overbrace{\n",
    "        \\left\\{\n",
    "            \\begin{matrix}\n",
    "                \\vdots & \\vdots \\\\\n",
    "                P1 & P2 \\\\\n",
    "                \\vdots & \\vdots\n",
    "            \\end{matrix}\n",
    "        \\right\\}\n",
    "    }\n",
    "}\n",
    "and\n",
    "\\substack{\n",
    "    Test_2 \\\\\n",
    "    \\overbrace{\n",
    "        \\left\\{\n",
    "            \\begin{matrix}\n",
    "                \\vdots & \\vdots \\\\\n",
    "                T1 & T2 \\\\\n",
    "                \\vdots & \\vdots\n",
    "            \\end{matrix}\n",
    "        \\right\\}\n",
    "    }\n",
    "}\n",
    "$$\n",
    "\n",
    "再用 次级模型 Model2 以真实训练集标签为 **标签训练**，以 train2 为特征进行训练，预测 test2，得到的测试集预测的标签列 $Y_{Pre}$\n",
    "$$\n",
    "\\substack{\n",
    "    Train_2 \\\\\n",
    "    \\overbrace{\n",
    "        \\left\\{\n",
    "            \\begin{matrix}\n",
    "                \\vdots & \\vdots \\\\\n",
    "                P1 & P2 \\\\\n",
    "                \\vdots & \\vdots\n",
    "            \\end{matrix}\n",
    "        \\right\\}\n",
    "    }\n",
    "}\n",
    "\\substack{\n",
    "    Model2\\;Train \\\\\n",
    "    \\overbrace\\Longrightarrow\n",
    "}\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        Y_{True} \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\substack{\n",
    "    Test_2 \\\\\n",
    "    \\overbrace{\n",
    "        \\left\\{\n",
    "            \\begin{matrix}\n",
    "                \\vdots & \\vdots \\\\\n",
    "                P1 & P2 \\\\\n",
    "                \\vdots & \\vdots\n",
    "            \\end{matrix}\n",
    "        \\right\\}\n",
    "    }\n",
    "}\n",
    "\\substack{\n",
    "    Model1\\_2\\;Predict \\\\\n",
    "    \\overbrace\\Longrightarrow\n",
    "}\n",
    "\\left\\{\n",
    "    \\begin{matrix}\n",
    "        \\vdots \\\\\n",
    "        Y_{Pre} \\\\\n",
    "        \\vdots\n",
    "    \\end{matrix}\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "这就是我们两层堆叠的一种基本的原始思路想法。在不同模型预测的结果基础上再加一层模型，进行再训练，从而得到模型最终的预测。\n",
    "\n",
    "Stacking 本质上就是这么直接的思路，但是直接这样有时对于如果训练集和测试集分布不那么一致的情况下是有一点问题的，器问题在于用初始模型训练的标签再利用真实标签进行再训练，毫无疑问会导致一定的模型过拟合训练集，这样或许模型在测试集上的泛化能力或者说效果会有一定的下降，因此现在的问题变成了如何降低再训练的过拟合性，这里我们一般有两种方法。\n",
    "\n",
    "- 1. 次级模型尽量选择简单的线性模型\n",
    "- 2. 利用 K-折交叉验证\n",
    "\n",
    "K-折交叉验证：\n",
    "\n",
    "训练：\n",
    "\n",
    "![训练](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/2326541042/1584448819632_YvJOXMk02P.jpg)\n",
    "\n",
    "预测：\n",
    "\n",
    "![预测](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/2326541042/1584448826203_k8KPy9n7D9.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a344b8",
   "metadata": {},
   "source": [
    "# 四、代码预测\n",
    "\n",
    "## 回归/分类概率-融合\n",
    "\n",
    "### 简单加权平均，结果直接融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f22a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 生成一些简单的样本数据，test_pre i 代表第i个模型的预测值\n",
    "test_pre1 = [1.2, 3.2, 2.1, 6.2]\n",
    "test_pre2 = [0.9, 3.1, 2.0, 5.9]\n",
    "test_pre3 = [1.1, 2.9, 2.2, 6.0]\n",
    "\n",
    "# y_test_true 代表第模型的真实值\n",
    "y_test_true = [1, 3, 2, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## 定义结果的加权平均函数\n",
    "def Weighted_method(test_pre1, test_pre2, test_pre3, w=[1/3, 1/3, 1/3]):\n",
    "    Weighted_result = w[0] * pd.Series(test_pre1) + w[1] * pd.Series(test_pre2) + w[2] * pd.Series(test_pre3)\n",
    "\n",
    "    return Weighted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6724c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# 各模型的预测结果计算 MAE\n",
    "print('Pred1 MAE:', metrics.mean_absolute_error(y_test_true, test_pre1))\n",
    "print('Pred2 MAE:', metrics.mean_absolute_error(y_test_true, test_pre2))\n",
    "print('Pre3 MAE:', metrics.mean_absolute_error(y_test_true, test_pre3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4656116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 根据加权计算 MAE\n",
    "w = [0.3, 0.4, 0.3]\n",
    "Weighted_pre = Weighted_method(test_pre1, test_pre2, test_pre3, w)\n",
    "print('Weighted_pre MAE:', metrics.mean_absolute_error(y_test_true, Weighted_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910262c0",
   "metadata": {},
   "source": [
    "可以发现，加权结果相对于之前的结果是有提升的，这种我们称其为简单的加权平均。\n",
    "\n",
    "还有一些特殊的形式，比如 mean 平均，median 平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faff217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 定义结果的加权平均函数\n",
    "def Mean_method(test_pre1, test_pre2, test_pre3):\n",
    "    Mean_result = pd.concat([\n",
    "        pd.Series(test_pre1),\n",
    "        pd.Series(test_pre2),\n",
    "        pd.Series(test_pre3)\n",
    "    ], axis=1).mean(axis=1)\n",
    "\n",
    "    return Mean_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean_pre = Mean_method(test_pre1, test_pre2, test_pre3)\n",
    "print('Mean_pre MAE:', metrics.mean_absolute_error(y_test_true, Mean_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad78b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 定义结果的加权平均函数\n",
    "def Median_method(test_pre1, test_pre2, test_pre3):\n",
    "    Median_result = pd.concat([\n",
    "        pd.Series(test_pre1),\n",
    "        pd.Series(test_pre2),\n",
    "        pd.Series(test_pre3)\n",
    "    ], axis=1).mean(axis=1)\n",
    "\n",
    "    return Median_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Median_pre = Median_method(test_pre1, test_pre2, test_pre3)\n",
    "print('Median_pre MAE:', metrics.mean_absolute_error(y_test_true, Median_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e5359",
   "metadata": {},
   "source": [
    "### Stacking 融合（回归）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def Stacking_method(train_reg1, train_reg2, train_reg3, y_train_true, test_pre1, test_pre3, model_L2=linear_model.LinearRegression()):\n",
    "    model_L2.fit(\n",
    "        pd.concat([\n",
    "            pd.Series(train_reg1),\n",
    "            pd.Series(train_reg2),\n",
    "            pd.Series(train_reg3)\n",
    "        ], axis=1).values,\n",
    "        y_train_true\n",
    "    )\n",
    "    Stacking_result = model_L2.predict(\n",
    "        pd.concat(\n",
    "            [\n",
    "                pd.Series(test_pre1),\n",
    "                pd.Series(test_pre2),\n",
    "                pd.Series(test_pre3)\n",
    "            ],\n",
    "            axis=1\n",
    "        ).values\n",
    "    )\n",
    "\n",
    "    return Stacking_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 生成一些简单的样本数据，test_prei 代表第i个模型的预测值\n",
    "train_reg1 = [3.2, 8.2, 9.1, 5.2]\n",
    "train_reg2 = [2.9, 8.1, 9.0, 4.9]\n",
    "train_reg3 = [3.1, 7.9, 9.2, 5.0]\n",
    "# y_test_true 代表第模型的真实值\n",
    "y_train_true = [3, 8, 9, 5] \n",
    "\n",
    "test_pre1 = [1.2, 3.2, 2.1, 6.2]\n",
    "test_pre2 = [0.9, 3.1, 2.0, 5.9]\n",
    "test_pre3 = [1.1, 2.9, 2.2, 6.0]\n",
    "\n",
    "# y_test_true 代表第模型的真实值\n",
    "y_test_true = [1, 3, 2, 6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c6984",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_L2 = linear_model.LinearRegression()\n",
    "Stacking_pre = Stacking_method(\n",
    "    train_reg1,\n",
    "    train_reg2,\n",
    "    train_reg3,\n",
    "    y_train_true,\n",
    "    test_pre1,\n",
    "    test_pre2,\n",
    "    test_pre3,\n",
    "    model_L2\n",
    ")\n",
    "print('Stacking_pre MAE:', metrics.mean_absolute_error(y_test_true, Stacking_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068e3f26",
   "metadata": {},
   "source": [
    "可以发现，模型结果相对于之前有进一步提升。我们需要注意的一点是，对于第二层 Stacking 的模型不宜选取的过于复杂，这样会导致模型在训练集上过拟合，从而使得在测试集上并不能达到很好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8cf46",
   "metadata": {},
   "source": [
    "## 分类模型融合\n",
    "\n",
    "对于分类，同样的可以使用融合方法，比如简单投票、Stacking..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d9b3f",
   "metadata": {},
   "source": [
    "### Voting 投票机制\n",
    "\n",
    "Voting 即投票机制，分为 **软投票** 和 **硬投票** 两种，其原理采用少数服从多数的思想。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269da48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "硬投票：对多个模型直接进行投票，不区分模型结果的相对重要性，最终投票数最多的类为最终被预测的类。\n",
    "\"\"\"\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "clf1 = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=3, min_child_weight=2, subsample=0.7, colsample_bytree=0.6, objective='binary:logistic')\n",
    "clf2 = RandomForestClassifier(n_estimators=50, max_depth=1, min_sample_split=4, min_sample_leaf=63, oob_score=True)\n",
    "clf3 = SVC(C=0.1)\n",
    "\n",
    "# 硬投票\n",
    "eclf = VotingClassifier(estimators=[('xgb', clf1), ('rf', clf2), ('svc', clf3)], voting='hard')\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, x, y, cv=5, scoring='accuracy')\n",
    "    print('Accuracy: %0.2f (+/- %0.2f) [%s]' % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ba013",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "软投票：和硬投票原理相同，增加了设置权重的功能，可以为不同模型设置不同权重，进而区别模型不同的重要性。\n",
    "\"\"\"\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "clf1 = XGBClassifier(linear_rate=0.1, n_estimators=150, max_depth=3, min_child_weight=2, subsample=0.8, colsample_bytree=0.8, objective='binary:logistic')\n",
    "clf2 = RandomForestClassifier(n_estimators=50, max_depth=1, min_sample_split=4, min_sample_leaf=63, oob_score=True)\n",
    "\n",
    "# 软投票\n",
    "eclf = VotingClassifier(estimators=[('xgb', clf1), ('rf', clf2), ('svc', clf3)], voting='soft', weights=[2, 1, 1])\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, x, y, cv=5, scoring='accuracy')\n",
    "    print('Accuracy: %0.2f (+/- %0.2f) [%s]' % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba4c51",
   "metadata": {},
   "source": [
    "### 分类的 Stacking/Blending 融合\n",
    "\n",
    "stacking 是一种分层模型集成框架。\n",
    "\n",
    "> 以两层为例，第一层由多个基学习器组成，其输入为原始训练集；第二层的模型则是以第一层基学习器的输出作为训练集进行再训练，从而获取完整的 stacking 模型，stacking 两层模型都使用了全部的训练数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5-Fold Stacking\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# 创建训练的数据集\n",
    "data_0 = iris.data\n",
    "data = data_0[:100, :]\n",
    "\n",
    "target_0 = iris.target\n",
    "target = target_0[:100]\n",
    "\n",
    "# 模型融合中使用到的各个单模型\n",
    "clfs = [\n",
    "    LogisticRegression(solver='lbfgs'),\n",
    "    RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "    ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "    ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
    "    GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)\n",
    "]\n",
    "\n",
    "# 切分一部分数据作为测试集\n",
    "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)\n",
    "\n",
    "dataset_blend_train = np.zores((X.shape[0], len(clfs)))\n",
    "dataset_blend_test = np.zores((X_predict.shape[0], len(clfs)))\n",
    "\n",
    "# 5-折 stacking\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits)\n",
    "skf = skf.split(X, y)\n",
    "\n",
    "for j, clf in enumerate(clfs):\n",
    "    # 依次训练各个单模型\n",
    "    dataset_blend_test_j = np.zores((X_predict.shape[0], 5))\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        # 5-Fold 交叉训练，使用第 i 个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第 i 部分的新特征\n",
    "        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:, 1]\n",
    "        dataset_blend_train[test, j] = y_submission\n",
    "        dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 1]\n",
    "    # 对于测试集，直接用这 k 个模型的预测值均值作为新的特征。\n",
    "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "    print('Val Auc Score: %f' % roc_auc_score(y_predict, dataset_blend_test[:, j]))\n",
    "\n",
    "clf = LogisticRegression(solve='lbfgs')\n",
    "clf.fit(dataset_blend_train, y)\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
    "\n",
    "print('Val Auc Score of Stacking: %f' % (roc_auc_score(y_predict, y_submission)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0ed787",
   "metadata": {},
   "source": [
    "Blending，其实和 Stacking 是一种类似的多层模型融合的形式。\n",
    "\n",
    "> 其主要思路是把原始的训练集先分成两部分，比如 70% 的数据作为新的训练集，剩下 30% 的数据作为测试集。\n",
    "\n",
    "> 在第一层，我们在这 70% 的数据上训练多个模型，然后去预测那 30% 数据的 label，同时也预测测试集的 label。\n",
    "\n",
    "> 在第二层，我们就直接用这 30% 数据在第一层预测的结果作为新特征继续训练，然后用测试集第一层预测的label做特征，用第二层训练的模型做进一步预测。\n",
    "\n",
    "其优点在于：\n",
    "\n",
    "- 比 stacking 简单（因为不用进行 k 次的交叉验证来获得 stacker feature）\n",
    "- 避开了一个信息泄漏问题：generlizers 和 stacker 使用了不一样的数据集\n",
    "\n",
    "其缺点在于：\n",
    "\n",
    "- 使用了很少的数据（第二阶段的只使用 blender 只使用 training set 10% 的量）\n",
    "- blender 可能会过拟合\n",
    "- stacking 使用多次的交叉验证会比较稳健"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07362ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Blending\n",
    "\"\"\"\n",
    "\n",
    "# 创建训练的数据集\n",
    "data_0 = iris.data\n",
    "data = data_0[:100,:]\n",
    "\n",
    "target_0 = iris.target\n",
    "target = target_0[:100]\n",
    "\n",
    "# 模型融合中使用到的各个单模型\n",
    "clfs = [\n",
    "    LogisticRegression(solver='lbfgs'),\n",
    "    RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "    RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
    "    ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "    #ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
    "    GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)\n",
    "]\n",
    "\n",
    "#切分一部分数据作为测试集\n",
    "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)\n",
    "\n",
    "#切分训练数据集为d1,d2两部分\n",
    "X_d1, X_d2, y_d1, y_d2 = train_test_split(X, y, test_size=0.5, random_state=2020)\n",
    "dataset_d1 = np.zeros((X_d2.shape[0], len(clfs)))\n",
    "dataset_d2 = np.zeros((X_predict.shape[0], len(clfs)))\n",
    " \n",
    "for j, clf in enumerate(clfs):\n",
    "    #依次训练各个单模型\n",
    "    clf.fit(X_d1, y_d1)\n",
    "    y_submission = clf.predict_proba(X_d2)[:, 1]\n",
    "    dataset_d1[:, j] = y_submission\n",
    "    #对于测试集，直接用这k个模型的预测值作为新的特征。\n",
    "    dataset_d2[:, j] = clf.predict_proba(X_predict)[:, 1]\n",
    "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_d2[:, j]))\n",
    "\n",
    "#融合使用的模型\n",
    "clf = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)\n",
    "clf.fit(dataset_d1, y_d2)\n",
    "y_submission = clf.predict_proba(dataset_d2)[:, 1]\n",
    "print(\"Val auc Score of Blending: %f\" % (roc_auc_score(y_predict, y_submission)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5332ea",
   "metadata": {},
   "source": [
    "参考博客：[https://blog.csdn.net/Noob_daniel/article/details/76087829](https://blog.csdn.net/Noob_daniel/article/details/76087829)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf513b4c",
   "metadata": {},
   "source": [
    "### 分类的 Stacking 融合（利用 mlxtend）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn..ensemble import RandomForestClassifier\n",
    "from sklearn.classifier import StackingClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.plotting import plot_learning_curves\n",
    "from sklearn.plotting import plot_decision_regions\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 以 python 自带的鸢尾花数据集为例\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr)\n",
    "\n",
    "label= ['KNN', 'Random Forest', 'Naive Bayes', 'Stacking Classifier']\n",
    "clf_list = [clf1, clf2, clf3, sclf]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0, 1], repeat=2)\n",
    "\n",
    "clf_cv_mean = []\n",
    "clf_cv_std = []\n",
    "for clf, label, grd in zip(clf_list, label, grid):\n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print('Accuracy: %.2f (+/- %.2f) [%s]' % (scores.mean(), scores.std(), label))\n",
    "    clf_cv_mean.append(scores.mean())\n",
    "    clf_cv.std.append(scores.std())\n",
    "\n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf)\n",
    "    plt.title(label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4670833",
   "metadata": {},
   "source": [
    "可以发现，基模型用 KNN、Random Forest, Naive Bayes，然后在这个基础上次级模型加一个 LogisticRegressionLogisticReg，模型测试效果有着很好的提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc87bcc",
   "metadata": {},
   "source": [
    "## 一些其他方法\n",
    "\n",
    "将特征放进模型中预测，并将预测结果变化并作为新的特征加入原有特征中，再经过模型预测结果（Stacking 变化）\n",
    "\n",
    "*可以反复预测多次将结果加入最后的特征中*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ensemble_add_feature(train, test, target, clfs):\n",
    "    \n",
    "    # n_folds = 5\n",
    "    # skf = list(StratifiedKFold(y, n_folds=n_folds))\n",
    "\n",
    "    train_ = np.zeros((train.shape[0], len(clfs * 2)))\n",
    "    test_ = np.zeros((test.shape[0], len(clfs * 2)))\n",
    "\n",
    "    for j, clf in enumerate(clfs):\n",
    "        \"\"\"依次训练各个单模型\"\"\"\n",
    "        # print(j, clf)\n",
    "        \"\"\"使用第 1 部分作为预测，第 2 部分来训练模型，获得其预测的输出作为第 2 部分的新特征。\"\"\"\n",
    "        # X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "\n",
    "        clf.fit(train, target)\n",
    "        y_train = clf.predict(train)\n",
    "        y_test = clf.predict(test)\n",
    "\n",
    "        ## 新特征生成\n",
    "        train_[:, j * 2] = y_train ** 2\n",
    "        test_[:, j * 2] = y_test ** 2\n",
    "        train_[:, j + 1] = np.exp(y_train)\n",
    "        test_[:, j + 1] = np.exp(y_test)\n",
    "        # print('Val Auc Score: %f' % r2_score(y_predict, dataset_d2[:, j]))\n",
    "        print('Method ', j)\n",
    "    \n",
    "    train_ = pd.DataFrame(train_)\n",
    "    test = pd.DataFrame(test_)\n",
    "\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdab50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "data_0 = iris.data\n",
    "data = data_0[:100, :]\n",
    "\n",
    "target_0 = iris.target\n",
    "target = target_0[:100]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.3)\n",
    "x_train = pd.DataFrame(x_train)\n",
    "x_test = pd.DataFrame(x_test)\n",
    "\n",
    "# 模型融合中使用到的各个单模型\n",
    "clfs = [\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "    ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
    "    ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
    "    GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)\n",
    "]\n",
    "\n",
    "New_train, New_test = Ensemble_add_feature(x_train, x_test, clfs)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "# clf = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)\n",
    "clf.fit(New_train, y_train)\n",
    "y_emb = clf.predict_proba(New_test)[:, 1]\n",
    "\n",
    "print('Val Auc Score of Stacking: %f' % (roc_auc_score(y_test, y_emb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281241d",
   "metadata": {},
   "source": [
    "## 本赛题示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158bb8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import itertools\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA, FastICA, FactorAnalysis, SparsePCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# from mlxtend.classifier import StackingClassifier\n",
    "# from mlxtend.plotting import plot_learning_curves, plot_decision_regions\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "def get_project_path(*paths):\n",
    "    \"\"\"获取项目路径的统一方法\"\"\"\n",
    "    try:\n",
    "        current_dir = os.path.dirname(os.path.dirname(__file__))\n",
    "        project_path = os.path.dirname(current_dir)\n",
    "        return os.path.join(project_path, *paths)\n",
    "    except NameError:\n",
    "        project_path = os.getcwd()\n",
    "        return os.path.join(project_path, *paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据读取\n",
    "Train_data = pd.read_csv(get_project_path('data', 'used_car_train_20200313.csv'), sep=' ')\n",
    "Test_data = pd.read_csv(get_project_path('data', 'used_car_testB_20200421.csv'), sep=' ')\n",
    "\n",
    "print(Train_data.shape)\n",
    "print(Test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e61ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19973d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = Train_data.select_dtypes(exclude='object').columns\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e8dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in numerical_cols if col not in ['SaleID', 'name', 'regDate', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd984452",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = Train_data[feature_cols]\n",
    "Y_data = Train_data['price']\n",
    "\n",
    "X_test = TestB_data[feature_cols]\n",
    "\n",
    "print('X train shape:',X_data.shape)\n",
    "print('X test shape:',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sta_inf(data):\n",
    "    print('_min', np.min(data))\n",
    "    print('_max', np.max(data))\n",
    "    print('_mean', np.mean(data))\n",
    "    print('_ptp', np.ptp(data))\n",
    "    print('_std', np.std(data))\n",
    "    print('_var', np.var(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67044c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sta of label:')\n",
    "Sta_inf(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd3c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.fillna(-1)\n",
    "X_test = X_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc99124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_lr(x_train, y_train):\n",
    "    reg_model = linear_model.LinearRegression()\n",
    "    reg_model.fit(x_train, y_train)\n",
    "\n",
    "    return reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_ridge(x_train, y_train):\n",
    "    reg_model = linear_model.Ridge(alpha=0.8) # alphas = range(1, 100, 5)\n",
    "    reg_model.fit(x_train, y_train)\n",
    "\n",
    "    return reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_lasso(x_train, y_train):\n",
    "    reg_model = linear_model.LassoCV()\n",
    "    reg_model.fit(x_train, y_train)\n",
    "\n",
    "    return reg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdfa52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_gbdt(x_train, y_train):\n",
    "    estimator = GradientBoostingRegressor(loss='ls', subsample=0.85, max_depth=5, n_estimators=100)\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.05, 0.08, 0.1, 0.2]\n",
    "    }\n",
    "    gbdt = GridSearchCV(estimator, param_grid, cv=3)\n",
    "    gbdt.fit(x_train, y_train)\n",
    "    print(gbdt.best_params_)\n",
    "    # print(gbdt.best_estimator_)\n",
    "\n",
    "    return gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553184dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_xgb(x_train, y_train):\n",
    "    model = xgb.XGBRegressor(n_estimators=120, learning_rate=0.08, gamma=0, subsample=0.8, colsample_bytree=0.9, max_depth=5)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_lgb(x_train, y_train):\n",
    "    estimator = lgb.LGBMRegressor(num_leaves=63, n_estimators=100)\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1]\n",
    "    }\n",
    "    gbm = GridSearchCV(estimator, param_grid)\n",
    "\n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32421a9",
   "metadata": {},
   "source": [
    "### XGBoost 的五折交叉回归验证实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## xgb\n",
    "xgr = xgb.XGBRegressor(n_estimators=120, learning_rate=0.1, subsample=0.8, colsample_bytree=0.9, max_depth=7)\n",
    "\n",
    "scores_train = []\n",
    "scores = []\n",
    "\n",
    "## 5-折交叉验证方式\n",
    "sk = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "for train_ind, val_ind in sk.split(X_data, Y_data):\n",
    "    train_x = X_data.iloc[train_ind].values\n",
    "    train_y = Y_data.iloc[train_ind]\n",
    "    val_x = X_data.iloc[val_ind].values\n",
    "    val_y = Y_data.iloc[val_ind]\n",
    "\n",
    "    xgr.fit(train_x, train_y)\n",
    "    pred_train_xgb = xgr.predict(train_x)\n",
    "    pred_xgb = xgr.predict(val_x)\n",
    "\n",
    "    score_train = mean_absolute_error(train_y, pred_train_xgb)\n",
    "    scores_train.append(score_train)\n",
    "    score = mean_absolute_error(val_y, pred_xgb)\n",
    "    scores.append(score)\n",
    "\n",
    "print('Train mae:', np.mean(scores_train))\n",
    "print('Val mae:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc7dca9",
   "metadata": {},
   "source": [
    "### 划分数据集，并用多种方法训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38082051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build-your-own-ai (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
