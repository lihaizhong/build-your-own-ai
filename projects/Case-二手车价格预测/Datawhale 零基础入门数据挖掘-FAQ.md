# 学习赛 FAQ 汇总

## 数据探索分析

**Q1：怎么看出这两个类别特征严重倾斜？例如在 Train_data\['seller'].value_counts() 中，需要一个一个特征来查看偏移是否严重吗？**

可以通过查询绘图分布图来进行判断。例如通过 pandas_profiling 里面的直方图来进行整体性的观察。

当有一些值分布很不均匀时，就可以判断特征严重倾斜。在该比赛中，像 seller 和 offerType 的倾斜就非常严重，因此可以考虑直接删除。

**Q2：如果运用数据的偏度和峰度？**

数据的偏度和峰度配合标准错误可以用来检验数据是否服从正态分布，是服从左偏还是右偏。

还可以根据他们之间的比采取合适的处理使之服从正态分布。

**Q3：为何目标变量要尽量符合高斯分布，是因为有很多算法的前提假设是数据符合正态分布，例如线性回归里面最小二次法的一个前提假设就是数据符合正态分布，这样理解对吗？**

是的，可以这样理解。

## 特征工程

**Q4：整个比赛流程，对结果提升最大的部分是什么，大概占用多少时间？**

一般来说特征工程花费的时间比较多，后面的模型和优化部分通常都是有一定套路的。

**Q5：XGBoost 处理分类特征时，要做 one-hot 编码吗？尤其是对于汽车品牌这种重要的特征，但是 one-hot 编码后特征维度却很高，导致运行速度超级慢，这是正常的吗？还是说要分别进行一次编码和一次不编码？**

决策树模型不推荐对离散特征进行 one-hot 编码。主要原因有两个：

1）会产生样本切分不平衡问题。

本来特征是红的白的绿的，现在变成了是否是红的，是否是白的，是否是绿的。

只有少量样本为 1，大量样本为 0.这种特征的危害是：

- 本来节点的划分增益还可以，但是拆分后的特征，占总样本的比例小的特征，所以无论增益多大，乘以该比例之后会很小
- 占比例达的特征其增益也几乎为 0，影响模型学习

2）影响决策树学习。

决策树依赖的是数据的统计信息，one-hot 编码会把数据切分到零散的小空间上。

在这些零散的小空间上，统计信息是不准确的，并且围绕小部分数据展开，有过拟合倾向。

以上两个问题的本质在于，特征的预测能力被人为的拆分成多分，每一份与其他特征竞争最优划分节点时都会失败，所以特征的重要性会比实际值低。

如果类别特征比较多的话，可以去使用 CatBoost；如果想用 one-hot 编码试验的话可以使用类别数最小的。

**Q6：提取 brand 的统计特征的部分，如果只对训练集提取特征，而不对测试集提取特征，这不就是会导致训练集和测试集的特征保持不一致了吗？模型预测的时候不会受影响吗？**

在训练集上提取的统计特征，其实是用到了测试集上去。

因此，在这一过程中使用了 merge 的操作。该操作是在 brand 上进行拼接。

也就是说，只要测试集有 brand，那么就能够把这个统计特征拼接到上面。

## 数据建模

**Q7：这道题适合用 DeepLearning 解吗？看 Kaggle 很多 Top 的方案都是 DNN 和 XGBoost/LightGBM/CatBoost 加一起做模型架构再分开跑分模型融合。**

不适合。通常不涉及图像和 NLP 的问题会用传统 ML 方法来做，DL 的优势主要还是在于特征上。

**Q8：如何将规则引入模型？**

如果指的是引入先验规则的话，可以尝试用生成方法。

## 模型评估

**Q9：EDA 通常会进行异常值分析，一般为了模型效果，会剔除掉异常值。那如果测试集或者带预测的数据本身就包含异常值的情况呢？**

假设 test set 与 train set 是同分布的话，那么主要是看比例。

比例比较小的可以忽略，如果感觉比例比较大或者离群点信息比较重要的话，可以使用生成式的方法来做，可以有效解决离群点问题。
