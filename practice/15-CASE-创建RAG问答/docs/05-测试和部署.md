# RAGé—®ç­”ç³»ç»Ÿ - æµ‹è¯•å’Œéƒ¨ç½²

## æµ‹è¯•ç­–ç•¥

### æµ‹è¯•æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æµ‹è¯•é‡‘å­—å¡”                            â”‚
â”‚                                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚ E2Eæµ‹è¯•  â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                 â”‚  é›†æˆæµ‹è¯•      â”‚                       â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚            â”‚     å•å…ƒæµ‹è¯•        â”‚                      â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚        â”‚       æ€§èƒ½æµ‹è¯•            â”‚                    â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æµ‹è¯•ç±»å‹

| æµ‹è¯•ç±»å‹ | è¦†ç›–èŒƒå›´ | æ‰§è¡Œé¢‘ç‡ | å·¥å…· |
|---------|---------|---------|------|
| å•å…ƒæµ‹è¯• | å•ä¸ªå‡½æ•°/ç±» | æ¯æ¬¡æäº¤ | pytest |
| é›†æˆæµ‹è¯• | æ¨¡å—äº¤äº’ | æ¯æ—¥æ„å»º | pytest |
| åŠŸèƒ½æµ‹è¯• | å®Œæ•´åŠŸèƒ½ | æ¯å‘¨ | æ‰‹åŠ¨/è‡ªåŠ¨åŒ– |
| æ€§èƒ½æµ‹è¯• | ç³»ç»Ÿæ€§èƒ½ | æ¯æ¬¡å‘å¸ƒ | locust |
| E2Eæµ‹è¯• | ç”¨æˆ·åœºæ™¯ | æ¯æ¬¡å‘å¸ƒ | selenium |

## å•å…ƒæµ‹è¯•

### æµ‹è¯•æ–‡ä»¶ç»“æ„

```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_pdf_processor.py      # PDFå¤„ç†æµ‹è¯•
â”‚   â”œâ”€â”€ test_deepseek_integration.py # APIé›†æˆæµ‹è¯•
â”‚   â””â”€â”€ test_rag_system.py          # RAGç³»ç»Ÿæµ‹è¯•
â”œâ”€â”€ integration/
â”‚   â””â”€â”€ test_rag_pipeline.py        # é›†æˆæµ‹è¯•
â””â”€â”€ fixtures/
    â””â”€â”€ sample.pdf                  # æµ‹è¯•æ•°æ®
```

### PDFProcessorå•å…ƒæµ‹è¯•

```python
# tests/unit/test_pdf_processor.py
import pytest
from pathlib import Path
from pdf_processor import PDFProcessor

class TestPDFProcessor:
    """PDFProcessorå•å…ƒæµ‹è¯•"""
    
    @pytest.fixture
    def sample_pdf_path(self):
        """æµ‹è¯•PDFæ–‡ä»¶è·¯å¾„"""
        return Path(__file__).parent.parent / "fixtures" / "sample.pdf"
    
    @pytest.fixture
    def processor(self, sample_pdf_path):
        """åˆ›å»ºPDFProcessorå®ä¾‹"""
        return PDFProcessor(str(sample_pdf_path))
    
    def test_init(self, processor, sample_pdf_path):
        """æµ‹è¯•åˆå§‹åŒ–"""
        assert processor.pdf_path == str(sample_pdf_path)
        assert processor.loader is not None
    
    def test_load_and_process(self, processor):
        """æµ‹è¯•æ–‡æ¡£åŠ è½½å’Œå¤„ç†"""
        documents = processor.load_and_process()
        
        # éªŒè¯è¿”å›ç±»å‹
        assert isinstance(documents, list)
        assert len(documents) > 0
        
        # éªŒè¯æ–‡æ¡£ç»“æ„
        for doc in documents:
            assert hasattr(doc, 'page_content')
            assert hasattr(doc, 'metadata')
            assert 'page_number' in doc.metadata
            assert 'source' in doc.metadata
    
    def test_get_document_stats(self, processor):
        """æµ‹è¯•æ–‡æ¡£ç»Ÿè®¡"""
        stats = processor.get_document_stats()
        
        # éªŒè¯è¿”å›ç»“æ„
        assert isinstance(stats, dict)
        assert 'total_documents' in stats
        assert 'total_pages' in stats
        assert 'total_characters' in stats
        assert 'pdf_file' in stats
        
        # éªŒè¯æ•°æ®ç±»å‹
        assert isinstance(stats['total_documents'], int)
        assert isinstance(stats['total_pages'], int)
        assert stats['total_documents'] > 0
    
    def test_file_not_found(self):
        """æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨çš„æƒ…å†µ"""
        with pytest.raises(FileNotFoundError):
            PDFProcessor("nonexistent.pdf")
```

### DashScopeIntegrationå•å…ƒæµ‹è¯•

```python
# tests/unit/test_deepseek_integration.py
import pytest
from unittest.mock import Mock, patch
from deepseek_integration import DashScopeIntegration

class TestDashScopeIntegration:
    """DashScopeIntegrationå•å…ƒæµ‹è¯•"""
    
    @pytest.fixture
    def mock_env(self, monkeypatch):
        """æ¨¡æ‹Ÿç¯å¢ƒå˜é‡"""
        monkeypatch.setenv('DASHSCOPE_API_KEY', 'test-api-key')
    
    @pytest.fixture
    def integration(self, mock_env):
        """åˆ›å»ºé›†æˆå®ä¾‹"""
        return DashScopeIntegration()
    
    def test_init_success(self, mock_env):
        """æµ‹è¯•æˆåŠŸåˆå§‹åŒ–"""
        integration = DashScopeIntegration()
        assert integration.api_key == 'test-api-key'
    
    def test_init_missing_api_key(self, monkeypatch):
        """æµ‹è¯•ç¼ºå°‘APIå¯†é’¥"""
        monkeypatch.delenv('DASHSCOPE_API_KEY', raising=False)
        with pytest.raises(ValueError, match="è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY"):
            DashScopeIntegration()
    
    @patch('deepseek_integration.ChatTongyi')
    def test_get_llm(self, mock_chat, integration):
        """æµ‹è¯•è·å–LLM"""
        mock_llm = Mock()
        mock_chat.return_value = mock_llm
        
        llm = integration.get_llm(model_name="qwen-turbo", temperature=0.0)
        
        mock_chat.assert_called_once_with(
            model="qwen-turbo",
            api_key='test-api-key',
            temperature=0.0
        )
        assert llm == mock_llm
    
    @patch('deepseek_integration.DashScopeEmbeddings')
    def test_get_embeddings(self, mock_embeddings, integration):
        """æµ‹è¯•è·å–åµŒå…¥æ¨¡å‹"""
        mock_emb = Mock()
        mock_embeddings.return_value = mock_emb
        
        embeddings = integration.get_embeddings()
        
        mock_embeddings.assert_called_once()
        assert embeddings == mock_emb
    
    def test_get_config_info(self, integration):
        """æµ‹è¯•é…ç½®ä¿¡æ¯"""
        info = integration.get_config_info()
        
        assert isinstance(info, dict)
        assert info['dashscope_api_key_set'] is True
        assert info['using_dashscope_llm'] is True
```

### RAGç³»ç»Ÿå•å…ƒæµ‹è¯•

```python
# tests/unit/test_rag_system.py
import pytest
from unittest.mock import Mock, patch, MagicMock
from langchain_core.documents import Document

class TestRAGSystem:
    """RAGç³»ç»Ÿå•å…ƒæµ‹è¯•"""
    
    @pytest.fixture
    def mock_documents(self):
        """æ¨¡æ‹Ÿæ–‡æ¡£åˆ—è¡¨"""
        return [
            Document(
                page_content="äº§å“ç»ç†éœ€è¦å…·å¤‡æ ¸å¿ƒèƒ½åŠ›",
                metadata={'page': 0, 'page_number': 0, 'source': 'test.pdf'}
            ),
            Document(
                page_content="ç”¨æˆ·éœ€æ±‚åˆ†ææ˜¯é‡è¦æŠ€èƒ½",
                metadata={'page': 1, 'page_number': 1, 'source': 'test.pdf'}
            )
        ]
    
    @pytest.fixture
    def mock_rag_system(self, mock_documents):
        """æ¨¡æ‹ŸRAGç³»ç»Ÿ"""
        mock_llm = Mock()
        mock_llm.invoke.return_value = Mock(content="æµ‹è¯•å›ç­”")
        
        mock_retriever = Mock()
        mock_retriever.invoke.return_value = mock_documents
        
        return {
            'llm': mock_llm,
            'retriever': mock_retriever,
            'vector_store': Mock()
        }
    
    def test_query_rag_system_success(self, mock_rag_system):
        """æµ‹è¯•æŸ¥è¯¢æˆåŠŸ"""
        from main import query_rag_system
        
        result = query_rag_system(mock_rag_system, "æµ‹è¯•é—®é¢˜")
        
        assert 'result' in result
        assert 'source_documents' in result
        assert result['result'] == "æµ‹è¯•å›ç­”"
        assert len(result['source_documents']) == 2
    
    def test_query_rag_system_no_documents(self, mock_rag_system):
        """æµ‹è¯•æ— ç›¸å…³æ–‡æ¡£"""
        from main import query_rag_system
        
        mock_rag_system['retriever'].invoke.return_value = []
        
        result = query_rag_system(mock_rag_system, "æµ‹è¯•é—®é¢˜")
        
        assert "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£" in result['result']
        assert len(result['source_documents']) == 0
    
    def test_format_source_documents(self, mock_documents):
        """æµ‹è¯•æ ¼å¼åŒ–æºæ–‡æ¡£"""
        from main import format_source_documents
        
        formatted = format_source_documents(mock_documents)
        
        assert len(formatted) == 2
        assert formatted[0]['page'] == 0
        assert formatted[0]['source'] == 'test.pdf'
```

## é›†æˆæµ‹è¯•

### ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•

```python
# tests/integration/test_rag_pipeline.py
import pytest
from pathlib import Path
from pdf_processor import PDFProcessor
from deepseek_integration import get_embeddings, get_dashscope_llm
from langchain_community.vectorstores.faiss import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter

class TestRAGPipeline:
    """RAGæµæ°´çº¿é›†æˆæµ‹è¯•"""
    
    @pytest.fixture
    def pdf_path(self):
        """æµ‹è¯•PDFè·¯å¾„"""
        return Path(__file__).parent.parent / "fixtures" / "sample.pdf"
    
    @pytest.fixture
    def rag_components(self, pdf_path):
        """åˆ›å»ºRAGç»„ä»¶"""
        # å¤„ç†PDF
        processor = PDFProcessor(str(pdf_path))
        documents = processor.load_and_process()
        
        # åˆ†å‰²æ–‡æ¡£
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50
        )
        split_docs = text_splitter.split_documents(documents)
        
        return {
            'documents': split_docs,
            'embeddings': get_embeddings(),
            'llm': get_dashscope_llm()
        }
    
    @pytest.mark.integration
    def test_full_pipeline(self, rag_components):
        """æµ‹è¯•å®Œæ•´æµæ°´çº¿"""
        # åˆ›å»ºå‘é‡å­˜å‚¨
        vector_store = FAISS.from_documents(
            rag_components['documents'],
            rag_components['embeddings']
        )
        
        # åˆ›å»ºæ£€ç´¢å™¨
        retriever = vector_store.as_retriever(search_kwargs={"k": 2})
        
        # æ‰§è¡Œæ£€ç´¢
        question = "æµ‹è¯•é—®é¢˜"
        docs = retriever.invoke(question)
        
        # éªŒè¯ç»“æœ
        assert len(docs) > 0
        assert all(hasattr(doc, 'page_content') for doc in docs)
        
        # ç”Ÿæˆå›ç­”
        context = "\n".join([doc.page_content for doc in docs])
        response = rag_components['llm'].invoke(f"åŸºäºä»¥ä¸‹å†…å®¹å›ç­”: {context}\né—®é¢˜: {question}")
        
        assert response is not None
        assert hasattr(response, 'content')
    
    @pytest.mark.integration
    def test_vector_store_persistence(self, rag_components, tmp_path):
        """æµ‹è¯•å‘é‡å­˜å‚¨æŒä¹…åŒ–"""
        # åˆ›å»ºå¹¶ä¿å­˜
        vector_store = FAISS.from_documents(
            rag_components['documents'],
            rag_components['embeddings']
        )
        save_path = str(tmp_path / "faiss_index")
        vector_store.save_local(save_path)
        
        # åŠ è½½å¹¶éªŒè¯
        loaded_store = FAISS.load_local(
            save_path,
            rag_components['embeddings']
        )
        
        assert loaded_store is not None
```

### æµ‹è¯•é…ç½®

```python
# pytest.ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
markers =
    unit: å•å…ƒæµ‹è¯•
    integration: é›†æˆæµ‹è¯•
    slow: æ…¢é€Ÿæµ‹è¯•
```

## åŠŸèƒ½æµ‹è¯•

### ç³»ç»ŸåŠŸèƒ½æµ‹è¯•è„šæœ¬

```python
# test_system.py
"""
RAGç³»ç»ŸåŠŸèƒ½æµ‹è¯•è„šæœ¬
"""
import sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), 'code'))

from pdf_processor import PDFProcessor
from deepseek_integration import get_integration_info, get_embeddings, get_dashscope_llm


def test_pdf_processing():
    """æµ‹è¯•PDFå¤„ç†"""
    print("=" * 60)
    print("æµ‹è¯•PDFå¤„ç†åŠŸèƒ½")
    print("=" * 60)
    
    script_dir = os.path.dirname(os.path.abspath(__file__))
    pdf_path = os.path.join(script_dir, "data/AIäº§å“ç»ç†é¢è¯•é¢˜65é“.pdf")
    
    if not os.path.exists(pdf_path):
        print(f"é”™è¯¯: PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        return False
    
    try:
        processor = PDFProcessor(pdf_path=pdf_path)
        stats = processor.get_document_stats()
        print("PDFæ–‡æ¡£ç»Ÿè®¡:")
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        documents = processor.load_and_process()
        print(f"\næˆåŠŸå¤„ç† {len(documents)} ä¸ªæ–‡æ¡£å—")
        
        # æ˜¾ç¤ºå‰3ä¸ªæ–‡æ¡£çš„é¡µç ä¿¡æ¯
        print("\nå‰3ä¸ªæ–‡æ¡£ç¤ºä¾‹:")
        for i, doc in enumerate(documents[:3], 1):
            page_num = doc.metadata.get('page_number', 'æœªçŸ¥')
            content_preview = doc.page_content[:100] + "..."
            print(f"{i}. é¡µç : {page_num}, å†…å®¹é¢„è§ˆ: {content_preview}")
        
        return True
        
    except Exception as e:
        print(f"PDFå¤„ç†æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_api_integration():
    """æµ‹è¯•APIé›†æˆ"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•APIé›†æˆåŠŸèƒ½")
    print("=" * 60)
    
    try:
        info = get_integration_info()
        print("APIé…ç½®ä¿¡æ¯:")
        for key, value in info.items():
            status = "âœ“" if value else "âœ—"
            print(f"  {status} {key}: {value}")
        
        # æµ‹è¯•åµŒå…¥æ¨¡å‹
        print("\næµ‹è¯•DashScopeåµŒå…¥æ¨¡å‹...")
        embeddings = get_embeddings()
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
        test_embedding = embeddings.embed_query(test_text)
        print(f"åµŒå…¥æ¨¡å‹æµ‹è¯•æˆåŠŸï¼Œç”Ÿæˆçš„åµŒå…¥å‘é‡ç»´åº¦: {len(test_embedding)}")
        
        # æµ‹è¯•LLM
        print("\næµ‹è¯•DashScope LLMæ¨¡å‹...")
        llm = get_dashscope_llm()
        test_prompt = "ä½ å¥½ï¼Œè¯·ç®€è¦ä»‹ç»ä¸€ä¸‹è‡ªå·±"
        test_response = llm.invoke(test_prompt)
        response_text = test_response.content if hasattr(test_response, 'content') else str(test_response)
        print(f"LLMæ¨¡å‹æµ‹è¯•æˆåŠŸï¼Œå“åº”: {response_text[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"APIé›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("RAGç³»ç»ŸåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    results = {
        'PDFå¤„ç†': test_pdf_processing(),
        'APIé›†æˆ': test_api_integration()
    }
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    all_passed = True
    for test_name, result in results.items():
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{test_name}: {status}")
        if not result:
            all_passed = False
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼RAGç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªã€‚")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜ã€‚")
    
    print("=" * 60)


if __name__ == "__main__":
    main()
```

## æ€§èƒ½æµ‹è¯•

### æ€§èƒ½æµ‹è¯•è„šæœ¬

```python
# tests/performance/test_performance.py
import pytest
import time
from main import create_complete_rag_system, query_rag_system

class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""
    
    @pytest.fixture(scope="class")
    def rag_system(self):
        """åˆ›å»ºRAGç³»ç»Ÿï¼ˆç±»çº§åˆ«å…±äº«ï¼‰"""
        return create_complete_rag_system()
    
    def test_initialization_time(self):
        """æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–æ—¶é—´"""
        start = time.time()
        rag_system = create_complete_rag_system()
        elapsed = time.time() - start
        
        print(f"\nç³»ç»Ÿåˆå§‹åŒ–æ—¶é—´: {elapsed:.2f}ç§’")
        assert elapsed < 60  # åº”è¯¥åœ¨60ç§’å†…å®Œæˆ
    
    def test_query_latency(self, rag_system):
        """æµ‹è¯•æŸ¥è¯¢å»¶è¿Ÿ"""
        questions = [
            "äº§å“ç»ç†éœ€è¦å…·å¤‡å“ªäº›æ ¸å¿ƒèƒ½åŠ›ï¼Ÿ",
            "å¦‚ä½•è¿›è¡Œç”¨æˆ·éœ€æ±‚åˆ†æï¼Ÿ",
            "äº§å“è®¾è®¡çš„åŸºæœ¬åŸåˆ™æ˜¯ä»€ä¹ˆï¼Ÿ"
        ]
        
        latencies = []
        for question in questions:
            start = time.time()
            result = query_rag_system(rag_system, question)
            elapsed = time.time() - start
            latencies.append(elapsed)
            print(f"é—®é¢˜: {question[:20]}... å»¶è¿Ÿ: {elapsed:.2f}ç§’")
        
        avg_latency = sum(latencies) / len(latencies)
        print(f"\nå¹³å‡æŸ¥è¯¢å»¶è¿Ÿ: {avg_latency:.2f}ç§’")
        assert avg_latency < 10  # å¹³å‡å»¶è¿Ÿåº”å°äº10ç§’
    
    def test_retrieval_latency(self, rag_system):
        """æµ‹è¯•æ£€ç´¢å»¶è¿Ÿ"""
        question = "æµ‹è¯•é—®é¢˜"
        
        latencies = []
        for _ in range(10):
            start = time.time()
            docs = rag_system['retriever'].invoke(question)
            elapsed = time.time() - start
            latencies.append(elapsed)
        
        avg_latency = sum(latencies) / len(latencies)
        print(f"\nå¹³å‡æ£€ç´¢å»¶è¿Ÿ: {avg_latency*1000:.2f}æ¯«ç§’")
        assert avg_latency < 0.5  # æ£€ç´¢å»¶è¿Ÿåº”å°äº500æ¯«ç§’
```

### æ€§èƒ½åŸºå‡†

```python
# tests/performance/benchmarks.py
"""æ€§èƒ½åŸºå‡†æµ‹è¯•"""
import time
import statistics

def benchmark_retrieval(rag_system, questions, iterations=10):
    """æ£€ç´¢æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    latencies = []
    
    for _ in range(iterations):
        for question in questions:
            start = time.time()
            rag_system['retriever'].invoke(question)
            latencies.append(time.time() - start)
    
    return {
        'mean': statistics.mean(latencies),
        'median': statistics.median(latencies),
        'stdev': statistics.stdev(latencies) if len(latencies) > 1 else 0,
        'min': min(latencies),
        'max': max(latencies)
    }

def benchmark_generation(rag_system, questions, iterations=5):
    """ç”Ÿæˆæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    latencies = []
    
    for _ in range(iterations):
        for question in questions:
            start = time.time()
            query_rag_system(rag_system, question)
            latencies.append(time.time() - start)
    
    return {
        'mean': statistics.mean(latencies),
        'median': statistics.median(latencies),
        'min': min(latencies),
        'max': max(latencies)
    }
```

## éƒ¨ç½²ç­–ç•¥

### å¼€å‘ç¯å¢ƒéƒ¨ç½²

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  rag-app:
    build:
      context: .
      dockerfile: Dockerfile.dev
    volumes:
      - .:/app
      - ~/.cache:/root/.cache
    environment:
      - DASHSCOPE_API_KEY=${DASHSCOPE_API_KEY}
    ports:
      - "8000:8000"
    command: uv run python code/main.py --mode interactive
```

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### Dockerfile

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…uv
RUN pip install uv

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY pyproject.toml uv.lock ./

# å®‰è£…ä¾èµ–
RUN uv sync --frozen

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY code/ ./code/
COPY data/ ./data/

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONUNBUFFERED=1

# è¿è¡Œåº”ç”¨
CMD ["uv", "run", "python", "code/main.py"]
```

#### Docker Composeç”Ÿäº§é…ç½®

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  rag-app:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - DASHSCOPE_API_KEY=${DASHSCOPE_API_KEY}
      - LOG_LEVEL=INFO
    volumes:
      - faiss-data:/app/faiss_index
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  faiss-data:
```

### Kuberneteséƒ¨ç½²

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rag-qa-system
  labels:
    app: rag-qa
spec:
  replicas: 2
  selector:
    matchLabels:
      app: rag-qa
  template:
    metadata:
      labels:
        app: rag-qa
    spec:
      containers:
      - name: rag-app
        image: rag-qa:latest
        ports:
        - containerPort: 8000
        env:
        - name: DASHSCOPE_API_KEY
          valueFrom:
            secretKeyRef:
              name: rag-secrets
              key: dashscope-api-key
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: rag-qa-service
spec:
  selector:
    app: rag-qa
  ports:
  - port: 80
    targetPort: 8000
  type: LoadBalancer
```

## ç›‘æ§å’Œæ—¥å¿—

### æ—¥å¿—é…ç½®

```python
# logging_config.py
import logging
import sys
from loguru import logger

def setup_logging(log_level="INFO"):
    """é…ç½®æ—¥å¿—"""
    # ç§»é™¤é»˜è®¤å¤„ç†å™¨
    logger.remove()
    
    # æ·»åŠ æ§åˆ¶å°å¤„ç†å™¨
    logger.add(
        sys.stdout,
        level=log_level,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>"
    )
    
    # æ·»åŠ æ–‡ä»¶å¤„ç†å™¨
    logger.add(
        "logs/rag_system_{time:YYYY-MM-DD}.log",
        rotation="00:00",
        retention="7 days",
        level="DEBUG",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}"
    )
    
    return logger
```

### æ€§èƒ½ç›‘æ§

```python
# monitoring.py
from prometheus_client import Counter, Histogram, Gauge
import time

# å®šä¹‰æŒ‡æ ‡
QUERY_COUNT = Counter('rag_queries_total', 'Total number of queries')
QUERY_LATENCY = Histogram('rag_query_latency_seconds', 'Query latency in seconds')
RETRIEVAL_LATENCY = Histogram('rag_retrieval_latency_seconds', 'Retrieval latency')
ACTIVE_CONNECTIONS = Gauge('rag_active_connections', 'Active connections')

def track_query(func):
    """æŸ¥è¯¢è¿½è¸ªè£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        QUERY_COUNT.inc()
        start = time.time()
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            QUERY_LATENCY.observe(time.time() - start)
    return wrapper
```

## CI/CDæµæ°´çº¿

### GitHub Actionsé…ç½®

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install uv
      run: pip install uv
    
    - name: Install dependencies
      run: uv sync
    
    - name: Run unit tests
      run: uv run pytest tests/unit -v --cov=code
    
    - name: Run integration tests
      env:
        DASHSCOPE_API_KEY: ${{ secrets.DASHSCOPE_API_KEY }}
      run: uv run pytest tests/integration -v -m integration
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: docker build -t rag-qa:${{ github.sha }} .
    
    - name: Push to registry
      run: |
        docker tag rag-qa:${{ github.sha }} registry.example.com/rag-qa:latest
        docker push registry.example.com/rag-qa:latest
```

## éƒ¨ç½²éªŒè¯

### å¥åº·æ£€æŸ¥ç«¯ç‚¹

```python
# health.py
from fastapi import FastAPI
from datetime import datetime

app = FastAPI()

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/ready")
async def readiness_check():
    """å°±ç»ªæ£€æŸ¥"""
    # æ£€æŸ¥APIè¿æ¥
    try:
        from deepseek_integration import get_integration_info
        info = get_integration_info()
        if not info.get('dashscope_api_key_set'):
            return {"status": "not ready", "reason": "API key not set"}
        return {"status": "ready"}
    except Exception as e:
        return {"status": "not ready", "reason": str(e)}
```

### éƒ¨ç½²éªŒè¯è„šæœ¬

```python
# scripts/verify_deployment.py
"""éƒ¨ç½²éªŒè¯è„šæœ¬"""
import requests
import time

def verify_health(base_url):
    """éªŒè¯å¥åº·çŠ¶æ€"""
    response = requests.get(f"{base_url}/health")
    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "healthy"
    print("âœ“ å¥åº·æ£€æŸ¥é€šè¿‡")

def verify_readiness(base_url):
    """éªŒè¯å°±ç»ªçŠ¶æ€"""
    response = requests.get(f"{base_url}/ready")
    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "ready"
    print("âœ“ å°±ç»ªæ£€æŸ¥é€šè¿‡")

def verify_query(base_url):
    """éªŒè¯æŸ¥è¯¢åŠŸèƒ½"""
    response = requests.post(
        f"{base_url}/query",
        json={"question": "æµ‹è¯•é—®é¢˜"}
    )
    assert response.status_code == 200
    data = response.json()
    assert "result" in data
    print("âœ“ æŸ¥è¯¢åŠŸèƒ½éªŒè¯é€šè¿‡")

def main():
    base_url = "http://localhost:8000"
    
    print("å¼€å§‹éƒ¨ç½²éªŒè¯...")
    verify_health(base_url)
    verify_readiness(base_url)
    verify_query(base_url)
    print("\nğŸ‰ éƒ¨ç½²éªŒè¯å®Œæˆï¼")

if __name__ == "__main__":
    main()
```

---

*æœ€åæ›´æ–°: 2026å¹´2æœˆ15æ—¥*
*æ–‡æ¡£ç‰ˆæœ¬: v1.0*
*DevOpså›¢é˜Ÿ: build-your-own-aié¡¹ç›®*
