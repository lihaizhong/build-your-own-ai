# 大模型原理与API使用 - 测试和部署

## 测试策略

### 1. API测试

#### 基础连接测试

```python
"""
API连接测试 - 验证API密钥和网络连接
"""

import os
import pytest
from dotenv import load_dotenv
import dashscope
from dashscope import Generation

# 加载环境变量
load_dotenv()
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")


class TestAPIConnection:
    """API连接测试"""
    
    def test_api_key_configured(self):
        """测试API密钥是否已配置"""
        api_key = os.getenv("DASHSCOPE_API_KEY")
        assert api_key is not None, "DASHSCOPE_API_KEY 未配置"
        assert len(api_key) > 0, "DASHSCOPE_API_KEY 为空"
    
    def test_basic_call(self):
        """测试基础API调用"""
        response = Generation.call(
            model="qwen-turbo",
            messages=[{"role": "user", "content": "你好"}],
            result_format="message"
        )
        
        assert response.status_code == 200, f"API调用失败: {response.message}"
        assert response.output is not None
        assert len(response.output.choices) > 0
    
    def test_model_availability(self):
        """测试模型可用性"""
        models = ["qwen-turbo", "qwen-plus", "deepseek-v3"]
        
        for model in models:
            response = Generation.call(
                model=model,
                messages=[{"role": "user", "content": "测试"}],
                result_format="message"
            )
            assert response.status_code == 200, f"模型 {model} 不可用"


class TestAPIResponse:
    """API响应测试"""
    
    def test_response_structure(self):
        """测试响应结构"""
        response = Generation.call(
            model="qwen-turbo",
            messages=[{"role": "user", "content": "你好"}],
            result_format="message"
        )
        
        # 检查响应结构
        assert hasattr(response, 'status_code')
        assert hasattr(response, 'output')
        assert hasattr(response.output, 'choices')
        
        # 检查消息结构
        message = response.output.choices[0].message
        assert hasattr(message, 'role')
        assert hasattr(message, 'content')
    
    def test_finish_reason(self):
        """测试完成原因"""
        response = Generation.call(
            model="qwen-turbo",
            messages=[{"role": "user", "content": "说一个字"}],
            result_format="message"
        )
        
        finish_reason = response.output.choices[0].finish_reason
        assert finish_reason in ['stop', 'length', 'content_filter']
    
    def test_token_usage(self):
        """测试Token使用统计"""
        response = Generation.call(
            model="qwen-turbo",
            messages=[{"role": "user", "content": "你好"}],
            result_format="message"
        )
        
        assert hasattr(response, 'usage')
        assert response.usage.input_tokens > 0
        assert response.usage.output_tokens > 0
```

### 2. 功能测试

#### 情感分析测试

```python
"""
情感分析功能测试
"""

import pytest
from code.情感分析_Qwen import get_response


class TestSentimentAnalysis:
    """情感分析测试"""
    
    @pytest.fixture
    def system_prompt(self):
        return "你是一个情感分析助手。请判断用户评论的情感倾向，只回复'正向'、'负向'或'中性'。"
    
    def test_positive_sentiment(self, system_prompt):
        """测试正向情感"""
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "这个产品太棒了，非常喜欢！"}
        ]
        
        response = get_response(messages)
        result = response.output.choices[0].message.content
        
        assert "正向" in result or "正面" in result or "积极" in result
    
    def test_negative_sentiment(self, system_prompt):
        """测试负向情感"""
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "质量太差了，浪费钱！"}
        ]
        
        response = get_response(messages)
        result = response.output.choices[0].message.content
        
        assert "负向" in result or "负面" in result or "消极" in result
    
    def test_neutral_sentiment(self, system_prompt):
        """测试中性情感"""
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "还行吧，没什么特别的。"}
        ]
        
        response = get_response(messages)
        result = response.output.choices[0].message.content
        
        assert "中性" in result or "中立" in result
```

#### Function Calling测试

```python
"""
Function Calling功能测试
"""

import pytest
import json
import dashscope
from dashscope import Generation


class TestFunctionCalling:
    """Function Calling测试"""
    
    @pytest.fixture
    def weather_function(self):
        return {
            "name": "get_weather",
            "description": "获取城市天气信息",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "城市名称"}
                },
                "required": ["city"]
            }
        }
    
    def test_function_call_triggered(self, weather_function):
        """测试函数调用触发"""
        response = Generation.call(
            model="qwen-max",
            messages=[{"role": "user", "content": "北京天气怎么样？"}],
            functions=[weather_function],
            result_format="message"
        )
        
        message = response.output.choices[0].message
        
        # 检查是否触发函数调用
        assert hasattr(message, 'function_call') or hasattr(message, 'tool_calls')
    
    def test_function_arguments_extraction(self, weather_function):
        """测试参数提取"""
        response = Generation.call(
            model="qwen-max",
            messages=[{"role": "user", "content": "上海今天天气如何？"}],
            functions=[weather_function],
            result_format="message"
        )
        
        message = response.output.choices[0].message
        
        if hasattr(message, 'function_call'):
            arguments = json.loads(message.function_call.arguments)
            assert "city" in arguments
            assert "上海" in arguments["city"] or "shanghai" in arguments["city"].lower()
    
    def test_function_result_integration(self, weather_function):
        """测试结果整合"""
        messages = [
            {"role": "user", "content": "北京天气怎么样？"},
            {"role": "assistant", "content": "", "function_call": {
                "name": "get_weather",
                "arguments": '{"city": "北京"}'
            }},
            {"role": "function", "name": "get_weather", "content": '{"temp": 25, "weather": "晴"}'}
        ]
        
        response = Generation.call(
            model="qwen-max",
            messages=messages,
            result_format="message"
        )
        
        final_message = response.output.choices[0].message
        assert final_message.content is not None
        assert len(final_message.content) > 0
```

### 3. 性能测试

#### 响应时间测试

```python
"""
性能测试 - 响应时间
"""

import time
import pytest
import statistics
import dashscope
from dashscope import Generation


class TestPerformance:
    """性能测试"""
    
    def test_single_call_latency(self):
        """测试单次调用延迟"""
        latencies = []
        
        for _ in range(10):
            start = time.time()
            response = Generation.call(
                model="qwen-turbo",
                messages=[{"role": "user", "content": "你好"}],
                result_format="message"
            )
            end = time.time()
            
            assert response.status_code == 200
            latencies.append(end - start)
        
        avg_latency = statistics.mean(latencies)
        print(f"\n平均延迟: {avg_latency:.2f}秒")
        print(f"最小延迟: {min(latencies):.2f}秒")
        print(f"最大延迟: {max(latencies):.2f}秒")
        
        # 断言：平均延迟应小于5秒
        assert avg_latency < 5.0
    
    def test_concurrent_calls(self):
        """测试并发调用"""
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        def make_call(i):
            start = time.time()
            response = Generation.call(
                model="qwen-turbo",
                messages=[{"role": "user", "content": f"测试{i}"}],
                result_format="message"
            )
            end = time.time()
            return end - start, response.status_code
        
        latencies = []
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(make_call, i) for i in range(10)]
            for future in as_completed(futures):
                latency, status = future.result()
                assert status == 200
                latencies.append(latency)
        
        print(f"\n并发测试结果:")
        print(f"平均延迟: {statistics.mean(latencies):.2f}秒")
        print(f"成功率: 100%")
    
    def test_token_throughput(self):
        """测试Token吞吐量"""
        # 发送较长文本
        long_text = "这是一段测试文本。" * 100
        
        start = time.time()
        response = Generation.call(
            model="qwen-turbo",
            messages=[{"role": "user", "content": long_text}],
            result_format="message"
        )
        end = time.time()
        
        duration = end - start
        total_tokens = response.usage.input_tokens + response.usage.output_tokens
        throughput = total_tokens / duration
        
        print(f"\nToken吞吐量测试:")
        print(f"总Token数: {total_tokens}")
        print(f"耗时: {duration:.2f}秒")
        print(f"吞吐量: {throughput:.0f} tokens/秒")
```

### 4. 错误处理测试

```python
"""
错误处理测试
"""

import pytest
import dashscope
from dashscope import Generation


class TestErrorHandling:
    """错误处理测试"""
    
    def test_invalid_api_key(self):
        """测试无效API密钥"""
        original_key = dashscope.api_key
        dashscope.api_key = "invalid_key"
        
        try:
            response = Generation.call(
                model="qwen-turbo",
                messages=[{"role": "user", "content": "测试"}],
                result_format="message"
            )
            assert response.status_code != 200
        finally:
            dashscope.api_key = original_key
    
    def test_empty_message(self):
        """测试空消息"""
        response = Generation.call(
            model="qwen-turbo",
            messages=[{"role": "user", "content": ""}],
            result_format="message"
        )
        
        # 应该返回有效响应或明确错误
        assert response.status_code in [200, 400]
    
    def test_invalid_model(self):
        """测试无效模型"""
        response = Generation.call(
            model="invalid-model-name",
            messages=[{"role": "user", "content": "测试"}],
            result_format="message"
        )
        
        assert response.status_code != 200
    
    def test_rate_limit_handling(self):
        """测试速率限制处理"""
        from tenacity import retry, stop_after_attempt, wait_exponential
        
        @retry(
            stop=stop_after_attempt(3),
            wait=wait_exponential(multiplier=1, min=2, max=10)
        )
        def call_with_retry():
            return Generation.call(
                model="qwen-turbo",
                messages=[{"role": "user", "content": "测试"}],
                result_format="message"
            )
        
        # 快速发送多个请求
        for _ in range(5):
            response = call_with_retry()
            assert response.status_code == 200
```

## 部署策略

### 1. 环境配置

#### 开发环境

```bash
# .env.development
DASHSCOPE_API_KEY=your_dev_api_key
AMAP_API_KEY=your_dev_amap_key
LOG_LEVEL=DEBUG
MODEL_DEFAULT=qwen-turbo
```

#### 生产环境

```bash
# .env.production
DASHSCOPE_API_KEY=your_prod_api_key
AMAP_API_KEY=your_prod_amap_key
LOG_LEVEL=INFO
MODEL_DEFAULT=qwen-max
MAX_RETRIES=3
REQUEST_TIMEOUT=30
```

### 2. 配置管理

```python
"""
配置管理模块
"""

import os
from dataclasses import dataclass
from dotenv import load_dotenv


@dataclass
class Config:
    """配置类"""
    dashscope_api_key: str
    amap_api_key: str = ""
    log_level: str = "INFO"
    default_model: str = "qwen-turbo"
    max_retries: int = 3
    request_timeout: int = 30
    
    @classmethod
    def from_env(cls, env_file: str = ".env"):
        """从环境变量加载配置"""
        load_dotenv(env_file)
        
        return cls(
            dashscope_api_key=os.getenv("DASHSCOPE_API_KEY", ""),
            amap_api_key=os.getenv("AMAP_API_KEY", ""),
            log_level=os.getenv("LOG_LEVEL", "INFO"),
            default_model=os.getenv("MODEL_DEFAULT", "qwen-turbo"),
            max_retries=int(os.getenv("MAX_RETRIES", "3")),
            request_timeout=int(os.getenv("REQUEST_TIMEOUT", "30"))
        )
    
    def validate(self):
        """验证配置"""
        if not self.dashscope_api_key:
            raise ValueError("DASHSCOPE_API_KEY 未配置")
        
        if self.max_retries < 1:
            raise ValueError("MAX_RETRIES 必须大于0")


# 使用示例
config = Config.from_env()
config.validate()
```

### 3. 日志配置

```python
"""
日志配置模块
"""

import logging
import sys
from pathlib import Path


def setup_logging(log_level: str = "INFO", log_file: str = None):
    """配置日志"""
    
    # 日志格式
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # 控制台处理器
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    
    # 日志处理器列表
    handlers = [console_handler]
    
    # 文件处理器（可选）
    if log_file:
        log_path = Path(log_file)
        log_path.parent.mkdir(parents=True, exist_ok=True)
        
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setFormatter(formatter)
        handlers.append(file_handler)
    
    # 配置根日志
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        handlers=handlers
    )
    
    return logging.getLogger(__name__)


# 使用示例
logger = setup_logging(log_level="DEBUG", log_file="logs/app.log")
```

### 4. 健康检查

```python
"""
健康检查模块
"""

import time
import logging
from typing import Dict, Any
import dashscope
from dashscope import Generation

logger = logging.getLogger(__name__)


class HealthChecker:
    """健康检查器"""
    
    def __init__(self, timeout: int = 10):
        self.timeout = timeout
    
    def check_api_connection(self) -> Dict[str, Any]:
        """检查API连接"""
        start = time.time()
        
        try:
            response = Generation.call(
                model="qwen-turbo",
                messages=[{"role": "user", "content": "ping"}],
                result_format="message"
            )
            
            latency = time.time() - start
            
            return {
                "status": "healthy" if response.status_code == 200 else "unhealthy",
                "latency": f"{latency:.2f}s",
                "status_code": response.status_code
            }
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e)
            }
    
    def check_all(self) -> Dict[str, Any]:
        """检查所有服务"""
        return {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "api": self.check_api_connection()
        }


# FastAPI集成示例
from fastapi import FastAPI

app = FastAPI()
health_checker = HealthChecker()


@app.get("/health")
async def health_check():
    """健康检查端点"""
    return health_checker.check_all()
```

### 5. 监控和告警

```python
"""
监控模块
"""

import time
import logging
from collections import defaultdict
from typing import Dict, List
import dashscope
from dashscope import Generation

logger = logging.getLogger(__name__)


class APIMonitor:
    """API监控器"""
    
    def __init__(self):
        self.metrics = defaultdict(list)
        self.alert_thresholds = {
            "latency": 5.0,  # 秒
            "error_rate": 0.1,  # 10%
            "rate_limit": 0.05  # 5%
        }
    
    def record_call(self, model: str, latency: float, status: int):
        """记录API调用"""
        self.metrics[f"{model}_latency"].append(latency)
        self.metrics[f"{model}_status"].append(status)
        
        # 检查是否需要告警
        self._check_alerts(model, latency, status)
    
    def _check_alerts(self, model: str, latency: float, status: int):
        """检查告警条件"""
        # 延迟告警
        if latency > self.alert_thresholds["latency"]:
            logger.warning(f"高延迟告警: {model} 延迟 {latency:.2f}s")
        
        # 错误率告警
        recent_statuses = self.metrics[f"{model}_status"][-100:]
        if len(recent_statuses) >= 10:
            error_rate = sum(1 for s in recent_statuses if s != 200) / len(recent_statuses)
            if error_rate > self.alert_thresholds["error_rate"]:
                logger.warning(f"高错误率告警: {model} 错误率 {error_rate:.1%}")
    
    def get_stats(self, model: str) -> Dict:
        """获取统计信息"""
        latencies = self.metrics[f"{model}_latency"]
        statuses = self.metrics[f"{model}_status"]
        
        if not latencies:
            return {"calls": 0}
        
        return {
            "calls": len(latencies),
            "avg_latency": sum(latencies) / len(latencies),
            "max_latency": max(latencies),
            "min_latency": min(latencies),
            "error_rate": sum(1 for s in statuses if s != 200) / len(statuses)
        }


# 装饰器示例
def monitor_call(monitor: APIMonitor, model: str):
    """监控装饰器"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            start = time.time()
            try:
                result = func(*args, **kwargs)
                status = result.status_code
                return result
            except Exception as e:
                status = 500
                raise
            finally:
                latency = time.time() - start
                monitor.record_call(model, latency, status)
        return wrapper
    return decorator
```

### 6. 部署清单

#### 部署前检查

```markdown
## 部署检查清单

### 环境配置
- [ ] Python 3.11+ 已安装
- [ ] 依赖包已安装 (pip install -r requirements.txt)
- [ ] 环境变量已配置 (.env文件)

### API配置
- [ ] DashScope API Key 已配置且有效
- [ ] 高德API Key 已配置（如需天气功能）
- [ ] API配额充足

### 安全检查
- [ ] API密钥未硬编码在代码中
- [ ] .env文件已添加到.gitignore
- [ ] 日志中不包含敏感信息

### 性能优化
- [ ] 选择合适的模型（turbo/max/plus）
- [ ] 设置合理的超时时间
- [ ] 实现重试机制

### 监控告警
- [ ] 日志系统已配置
- [ ] 健康检查端点可用
- [ ] 告警规则已配置
```

#### Docker部署

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# 安装依赖
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制代码
COPY . .

# 创建日志目录
RUN mkdir -p logs

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')" || exit 1

# 启动命令
CMD ["python", "main.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  api-service:
    build: .
    container_name: llm-api-service
    ports:
      - "8000:8000"
    environment:
      - LOG_LEVEL=INFO
      - MODEL_DEFAULT=qwen-turbo
    volumes:
      - ./logs:/app/logs
    env_file:
      - .env
    restart: unless-stopped
```

---

*最后更新: 2026年2月21日*
*测试和部署版本: v1.0*
*运维团队: DevOps运维组*
