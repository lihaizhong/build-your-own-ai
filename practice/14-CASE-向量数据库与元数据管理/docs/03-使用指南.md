# 向量数据库与元数据管理系统 - 使用指南

## 环境准备

### 1. 系统要求
- **操作系统**: Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **Python版本**: 3.11+
- **内存**: 最小8GB，推荐16GB+
- **存储空间**: 最小5GB，推荐10GB+

### 2. 依赖安装

#### 方式一：使用uv（推荐）
```bash
# 克隆项目
git clone <repository-url>
cd CASE-向量数据库与元数据管理

# 创建虚拟环境
uv venv --python 3.11

# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# 或
.venv\Scripts\activate     # Windows

# 安装依赖
uv sync

# 运行示例
uv run python code/example.py
```

#### 方式二：使用pip
```bash
# 创建虚拟环境
python -m venv .venv

# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# 或
.venv\Scripts\activate     # Windows

# 安装依赖
pip install -r requirements.txt

# 运行示例
python code/example.py
```

## 快速开始

### 1. AI产品经理面试题系统

#### 完整运行流程
```bash
# 1. 激活虚拟环境
source .venv/bin/activate

# 2. 运行面试题系统
uv run python code/ai_interview_qa_system.py
```

#### 预期输出
```
================================================================================
AI产品经理面试题向量数据库系统
================================================================================

加载嵌入模型: paraphrase-multilingual-MiniLM-L12-v2
系统初始化完成，向量维度: 384

================================================================================
解析PDF内容
================================================================================
找到 65 个问题匹配
成功解析 65 个问答对

类别统计:
  个人情况类: 8 个问题
  个人经历类: 12 个问题
  产品素质类: 15 个问题
  经典算法类: 5 个问题
  深度学习类: 6 个问题
  大数据模型类: 4 个问题
  技术基础类: 5 个问题
  工作场景类: 4 个问题
  行业认知类: 6 个问题

================================================================================
生成嵌入向量
================================================================================
正在生成 65 个文本的嵌入向量...
Batches: 100%|████████████████████| 1/1 [00:01<00:00,  1.23s/it]

================================================================================
创建Faiss索引
================================================================================
创建Faiss索引...
Faiss索引创建完成，包含 65 个向量
索引已保存到: /path/to/model/faiss_index.bin

================================================================================
保存元数据到metadata_store
================================================================================
保存元数据到metadata_store:
  - JSON: /path/to/model/metadata.json
  - Pickle: /path/to/model/metadata.pkl
  - 内存: 65 个问答对

================================================================================
保存系统配置
================================================================================
系统配置已保存到: /path/to/model/config.json

================================================================================
系统构建完成！
================================================================================
总问答对数: 65
向量维度: 384
Faiss索引: /path/to/model/faiss_index.bin
元数据: /path/to/model/metadata.json
配置文件: /path/to/model/config.json

================================================================================
测试查询功能
================================================================================

搜索查询: 如何进行自我介绍？
相似度阈值: 0.1
搜索到 5 个候选结果，正在计算相似度...
  候选1: L2距离=1.2345, 相似度=0.4456, 阈值=0.1
  候选2: L2距离=2.3456, 相似度=0.3001, 阈值=0.1
  候选3: L2距离=3.4567, 相似度=0.2248, 阈值=0.1
  候选4: L2距离=4.5678, 相似度=0.1803, 阈值=0.1
  候选5: L2距离=5.6789, 相似度=0.1487, 阈值=0.1
找到 5 个相似结果

搜索结果:
================================================================================

排名: 1
相似度: 0.4456
距离: 1.2345
元数据:
  - ID: qa_000
  - 类别: 个人情况类
  - 问题编号: 一
  - 问题标题: 
问题: 请简要介绍一下自己
答案摘要: 我是一个AI产品经理，专注于大模型应用和智能问答系统...
================================================================================

...
```

### 2. 向量数据库演示系统

#### 运行示例代码
```bash
# 1. 激活虚拟环境
source .venv/bin/activate

# 2. 运行演示程序
uv run python code/example.py
```

#### 预期输出
```
============================================================
向量数据库与元数据管理演示
============================================================
加载嵌入模型: paraphrase-multilingual-MiniLM-L12-v2

集合 'sanguo_documents' 创建成功

成功添加 5 个文档到集合 'sanguo_documents'

============================================================
搜索示例
============================================================

查询: 谁是三国时期的著名人物？
  1. 诸葛亮是三国时期著名的政治家、军事家，被誉为'卧龙'。
     元数据: {'category': '人物', 'period': '三国'}
     相似度: 0.8765
  2. 孙权是三国时期东吴的建立者，继承父兄基业，据守江东。
     元数据: {'category': '人物', 'period': '三国'}
     相似度: 0.8234

查询: 诸葛亮有什么特点？
  1. 诸葛亮是三国时期著名的政治家、军事家，被誉为'卧龙'。
     元数据: {'category': '人物', 'period': '三国'}
     相似度: 0.9123
  2. 三国演义是中国古典四大名著之一，描写了东汉末年到西晋初年的历史。
     元数据: {'category': '文学', 'year': '明代'}
     相似度: 0.6543

查询: 三国演义讲的是什么？
  1. 三国演义是中国古典四大名著之一，描写了东汉末年到西晋初年的历史。
     元数据: {'category': '文学', 'year': '明代'}
     相似度: 0.9456
  2. 曹操是三国时期的重要人物，被称为'治世之能臣，乱世之奸雄'。
     元数据: {'category': '人物', 'period': '三国'}
     相似度: 0.7890

============================================================
演示完成！
============================================================
```

## 交互式使用

### 1. 系统加载和查询

#### 基本使用流程
```python
from code.ai_interview_qa_system import AIInterviewQASystem

# 1. 创建系统实例
system = AIInterviewQASystem()

# 2. 加载已保存的系统
system.load_system()

# 3. 执行查询
results = system.search("如何进行自我介绍？", top_k=5)

# 4. 显示结果
system.display_results(results)

# 5. 导出结果
system.export_results(results, "query_results.json")
```

#### 高级查询配置
```python
# 自定义查询参数
results = system.search(
    query="AI产品经理的核心能力是什么？",
    top_k=10,              # 返回10个结果
    threshold=0.15         # 调整相似度阈值
)

# 获取特定类别结果
category_results = [r for r in results if r['qa_data']['category'] == '产品素质类']
```

### 2. 元数据管理

#### 查看元数据统计
```python
# 查看系统元数据
print(f"总问答对数: {len(system.metadata_store)}")
print(f"向量维度: {system.dimension}")

# 统计类别分布
from collections import Counter
categories = [qa['category'] for qa in system.metadata_store]
category_counts = Counter(categories)
print("类别分布:", dict(category_counts))
```

#### 导出和备份
```python
# 导出完整元数据
import json
with open('backup_metadata.json', 'w', encoding='utf-8') as f:
    json.dump(system.metadata_store, f, ensure_ascii=False, indent=2)

# 导出配置信息
config = {
    'total_qa_pairs': len(system.metadata_store),
    'model_name': system.model_name,
    'dimension': system.dimension,
    'created_at': '2026-01-24'
}
with open('system_config.json', 'w', encoding='utf-8') as f:
    json.dump(config, f, ensure_ascii=False, indent=2)
```

## 常见问题解决

### 1. 内存不足问题

#### 问题现象
```
MemoryError: Unable to allocate array with shape (65, 384) and data type float32
```

#### 解决方案
```python
# 1. 减少批处理大小
def generate_embeddings(self, texts: List[str], batch_size: int = 50):
    embeddings = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        batch_embeddings = self.model.encode(batch)
        embeddings.append(batch_embeddings)
    return np.vstack(embeddings)

# 2. 使用GPU加速
if torch.cuda.is_available():
    self.model = self.model.to('cuda')
```

### 2. 模型加载失败

#### 问题现象
```
OSError: Can't load config for 'paraphrase-multilingual-MiniLM-L12-v2'
```

#### 解决方案
```python
# 1. 检查网络连接
# 2. 使用本地模型
local_model_path = "./local_models/paraphrase-multilingual-MiniLM-L12-v2"
model = SentenceTransformer(local_model_path)

# 3. 替换为其他模型
model = SentenceTransformer("all-MiniLM-L6-v2")  # 更轻量的模型
```

### 3. PDF解析错误

#### 问题现象
```
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 12345
```

#### 解决方案
```python
# 1. 检查PDF编码
try:
    doc = fitz.open(pdf_path)
    pdf_text = ""
    for page in doc:
        pdf_text += page.get_text()
    doc.close()
except UnicodeDecodeError:
    # 尝试其他编码
    doc = fitz.open(pdf_path)
    pdf_text = ""
    for page in doc:
        pdf_text += page.get_text().encode('latin-1', errors='ignore').decode('utf-8')
    doc.close()
```

## 性能调优

### 1. 查询性能优化

#### 索引优化
```python
# 根据数据量选择合适的索引类型
if len(system.metadata_store) < 1000:
    # 小数据集使用暴力搜索
    index = faiss.IndexFlatL2(system.dimension)
elif len(system.metadata_store) < 10000:
    # 中等数据集使用IVF索引
    index = faiss.IndexIVFFlat(system.dimension, 100, faiss.METRIC_L2)
else:
    # 大数据集使用HNSW索引
    index = faiss.IndexHNSWFlat(system.dimension, 32)
```

#### 查询优化
```python
# 批量查询优化
def batch_search(self, queries: List[str], top_k: int = 5):
    query_embeddings = self.model.encode(queries)
    distances, indices = self.index.search(query_embeddings, top_k)
    
    results = []
    for i, (query, (distances_row, indices_row)) in enumerate(zip(queries, zip(distances, indices))):
        query_results = []
        for j, (distance, idx) in enumerate(zip(distances_row, indices_row)):
            if idx < len(self.metadata_store):
                query_results.append({
                    'rank': j + 1,
                    'similarity': 1 / (1 + distance),
                    'qa_data': self.metadata_store[idx]
                })
        results.append(query_results)
    
    return results
```

### 2. 内存优化

#### 缓存策略
```python
class OptimizedSystem:
    def __init__(self):
        self.memory_cache = {}  # 内存缓存
        self.cache_size_limit = 1000  # 缓存大小限制
    
    def get_vector(self, text: str):
        if text in self.memory_cache:
            return self.memory_cache[text]
        
        vector = self.model.encode([text])[0]
        
        # LRU缓存管理
        if len(self.memory_cache) >= self.cache_size_limit:
            # 删除最旧的缓存项
            oldest_key = next(iter(self.memory_cache))
            del self.memory_cache[oldest_key]
        
        self.memory_cache[text] = vector
        return vector
```

## 监控和调试

### 1. 性能监控

#### 系统状态检查
```python
def check_system_status(system):
    print("=== 系统状态检查 ===")
    print(f"向量维度: {system.dimension}")
    print(f"元数据数量: {len(system.metadata_store)}")
    print(f"索引状态: {'已加载' if system.index is not None else '未加载'}")
    
    if system.index is not None:
        print(f"索引大小: {system.index.ntotal}")
        print(f"索引类型: {type(system.index).__name__}")
    
    print(f"模型名称: {system.model_name}")
    print(f"模型维度: {system.model.get_sentence_embedding_dimension()}")
```

#### 查询性能测试
```python
import time

def test_query_performance(system, test_queries: List[str], top_k: int = 5):
    print("=== 查询性能测试 ===")
    
    for query in test_queries:
        start_time = time.time()
        results = system.search(query, top_k=top_k)
        end_time = time.time()
        
        print(f"查询: {query[:50]}...")
        print(f"  响应时间: {(end_time - start_time)*1000:.2f}ms")
        print(f"  返回结果数: {len(results)}")
        print(f"  平均相似度: {np.mean([r['similarity'] for r in results]):.4f}")
        print()
```

### 2. 错误处理和日志

#### 结构化日志
```python
import logging
import sys

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('system.log'),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

def safe_search(system, query: str, top_k: int = 5):
    try:
        logger.info(f"执行查询: {query}")
        results = system.search(query, top_k=top_k)
        logger.info(f"查询完成，返回 {len(results)} 个结果")
        return results
    except Exception as e:
        logger.error(f"查询失败: {str(e)}", exc_info=True)
        return []
```

---

*最后更新: 2026年1月24日*
*使用指南版本: v1.0*
*技术支持: build-your-own-ai项目团队*