# å‘é‡æ•°æ®åº“ä¸å…ƒæ•°æ®ç®¡ç†ç³»ç»Ÿ - æµ‹è¯•å’Œéƒ¨ç½²

## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

#### AIInterviewQASystemç±»æµ‹è¯•

```python
import unittest
import numpy as np
from unittest.mock import Mock, patch
from code.ai_interview_qa_system import AIInterviewQASystem


class TestAIInterviewQASystem(unittest.TestCase):
    """AIInterviewQASystemç±»çš„å•å…ƒæµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.system = AIInterviewQASystem()
        self.test_texts = [
            "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬1",
            "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬2", 
            "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬3"
        ]
    
    def test_initialization(self):
        """æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–"""
        self.assertIsNotNone(self.system.model)
        self.assertEqual(self.system.dimension, 384)
        self.assertEqual(self.system.model_name, "paraphrase-multilingual-MiniLM-L12-v2")
    
    def test_path_management(self):
        """æµ‹è¯•è·¯å¾„ç®¡ç†åŠŸèƒ½"""
        test_path = self.system.get_project_path('test', 'file.txt')
        self.assertIn('test', test_path)
        self.assertIn('file.txt', test_path)
    
    def test_text_cleaning(self):
        """æµ‹è¯•æ–‡æœ¬æ¸…ç†åŠŸèƒ½"""
        dirty_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬...123"
        cleaned = re.sub(r'\.{3,}.*?\d+\s*$', '', dirty_text)
        self.assertEqual(cleaned, "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬")
    
    @patch('code.ai_interview_qa_system.SentenceTransformer')
    def test_embedding_generation(self, mock_model):
        """æµ‹è¯•å‘é‡ç”Ÿæˆ"""
        mock_embeddings = np.random.rand(3, 384).astype(np.float32)
        mock_model.return_value.encode.return_value = mock_embeddings
        
        embeddings = self.system.generate_embeddings(self.test_texts)
        self.assertEqual(embeddings.shape, (3, 384))
        self.assertTrue(np.all(embeddings >= 0))
    
    def test_metadata_storage(self):
        """æµ‹è¯•å…ƒæ•°æ®å­˜å‚¨"""
        test_qa_pairs = [
            {
                "id": "qa_001",
                "category": "æµ‹è¯•ç±»åˆ«",
                "question": "æµ‹è¯•é—®é¢˜",
                "answer": "æµ‹è¯•ç­”æ¡ˆ"
            }
        ]
        
        self.system.save_metadata(test_qa_pairs)
        self.assertEqual(len(self.system.metadata_store), 1)
        self.assertEqual(self.system.metadata_store[0]["id"], "qa_001")
    
    def test_search_functionality(self):
        """æµ‹è¯•æœç´¢åŠŸèƒ½"""
        # å…ˆåˆ›å»ºæµ‹è¯•æ•°æ®
        test_qa_pairs = [
            {
                "id": "qa_001",
                "category": "æµ‹è¯•ç±»åˆ«",
                "question": "å¦‚ä½•è¿›è¡Œè‡ªæˆ‘ä»‹ç»ï¼Ÿ",
                "answer": "è‡ªæˆ‘ä»‹ç»åº”è¯¥åŒ…æ‹¬åŸºæœ¬ä¿¡æ¯ã€å·¥ä½œç»å†å’Œä¼˜åŠ¿"
            }
        ]
        
        self.system.save_metadata(test_qa_pairs)
        self.system.create_faiss_index(
            self.system.generate_embeddings([qa["full_text"] for qa in test_qa_pairs])
        )
        
        # æ‰§è¡Œæœç´¢
        results = self.system.search("è‡ªæˆ‘ä»‹ç»", top_k=1)
        self.assertGreater(len(results), 0)
        self.assertEqual(results[0]["qa_data"]["id"], "qa_001")
    
    def test_config_saving(self):
        """æµ‹è¯•é…ç½®ä¿å­˜"""
        config = {
            'model_name': self.system.model_name,
            'dimension': self.system.dimension,
            'total_qa_pairs': 1,
            'created_at': '2026-01-24'
        }
        
        self.system.save_config(config)
        self.assertTrue(os.path.exists(os.path.join(self.system.model_dir, 'config.json')))


class TestPDFParsing(unittest.TestCase):
    """PDFè§£æåŠŸèƒ½æµ‹è¯•"""
    
    def setUp(self):
        self.system = AIInterviewQASystem()
        self.test_pdf_content = """
        ä¸€ã€ä¸ªäººæƒ…å†µç±»
        (ä¸€)è‡ªæˆ‘ä»‹ç»
        è¯·ç®€è¦ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚
        å‚è€ƒç­”æ¡ˆï¼šæˆ‘æ˜¯ä¸€ä¸ªAIäº§å“ç»ç†ï¼Œä¸“æ³¨äºå¤§æ¨¡å‹åº”ç”¨å’Œæ™ºèƒ½é—®ç­”ç³»ç»Ÿ...
        
        äºŒã€ä¸ªäººç»å†ç±»
        (äºŒ)å·¥ä½œç»å†
        è¯·æè¿°ä¸€ä¸‹ä½ çš„å·¥ä½œç»å†ã€‚
        å‚è€ƒç­”æ¡ˆï¼šæˆ‘æœ‰5å¹´çš„äº§å“ç»ç†ç»éªŒï¼Œä¸“æ³¨äºAIå’Œæœºå™¨å­¦ä¹ äº§å“...
        """
    
    def test_category_parsing(self):
        """æµ‹è¯•ç±»åˆ«è§£æ"""
        qa_pairs = self.system.parse_pdf_content(self.test_pdf_content)
        self.assertGreater(len(qa_pairs), 0)
        
        categories = [qa["category"] for qa in qa_pairs]
        self.assertIn("ä¸ªäººæƒ…å†µç±»", categories)
        self.assertIn("ä¸ªäººç»å†ç±»", categories)
    
    def test_question_extraction(self):
        """æµ‹è¯•é—®é¢˜æå–"""
        qa_pairs = self.system.parse_pdf_content(self.test_pdf_content)
        self.assertGreater(len(qa_pairs), 0)
        
        first_qa = qa_pairs[0]
        self.assertEqual(first_qa["question_number"], "ä¸€")
        self.assertIn("è‡ªæˆ‘ä»‹ç»", first_qa["question"])
    
    def test_answer_extraction(self):
        """æµ‹è¯•ç­”æ¡ˆæå–"""
        qa_pairs = self.system.parse_pdf_content(self.test_pdf_content)
        self.assertGreater(len(qa_pairs), 0)
        
        first_qa = qa_pairs[0]
        self.assertIn("æˆ‘æ˜¯ä¸€ä¸ªAIäº§å“ç»ç†", first_qa["answer"])
        self.assertGreater(len(first_qa["answer"]), 0)


class TestVectorDatabaseDemo(unittest.TestCase):
    """å‘é‡æ•°æ®åº“æ¼”ç¤ºæµ‹è¯•"""
    
    def setUp(self):
        self.demo = VectorDatabaseDemo()
        self.test_documents = [
            "ä¸‰å›½æ¼”ä¹‰æ˜¯ä¸­å›½å¤å…¸å››å¤§åè‘—ä¹‹ä¸€ï¼Œæå†™äº†ä¸œæ±‰æœ«å¹´åˆ°è¥¿æ™‹åˆå¹´çš„å†å²ã€‚",
            "æ›¹æ“æ˜¯ä¸‰å›½æ—¶æœŸçš„é‡è¦äººç‰©ï¼Œè¢«ç§°ä¸º'æ²»ä¸–ä¹‹èƒ½è‡£ï¼Œä¹±ä¸–ä¹‹å¥¸é›„'ã€‚",
            "åˆ˜å¤‡æ˜¯ä¸‰å›½æ—¶æœŸèœ€æ±‰çš„å¼€å›½çš‡å¸ï¼Œä»¥ä»å¾·è‘—ç§°ã€‚",
            "è¯¸è‘›äº®æ˜¯ä¸‰å›½æ—¶æœŸè‘—åçš„æ”¿æ²»å®¶ã€å†›äº‹å®¶ï¼Œè¢«èª‰ä¸º'å§é¾™'ã€‚",
            "å­™æƒæ˜¯ä¸‰å›½æ—¶æœŸä¸œå´çš„å»ºç«‹è€…ï¼Œç»§æ‰¿çˆ¶å…„åŸºä¸šï¼Œæ®å®ˆæ±Ÿä¸œã€‚"
        ]
    
    def test_document_creation(self):
        """æµ‹è¯•æ–‡æ¡£åˆ›å»º"""
        collection = self.demo.create_collection("test_documents")
        self.assertIsNotNone(collection)
    
    def test_document_addition(self):
        """æµ‹è¯•æ–‡æ¡£æ·»åŠ """
        collection = self.demo.create_collection("test_documents")
        self.demo.add_documents(
            collection_name="test_documents",
            documents=self.test_documents,
            metadatas=[{"category": "æµ‹è¯•"}] * len(self.test_documents),
            ids=[f"doc_{i}" for i in range(len(self.test_documents))]
        )
        
        # éªŒè¯æ–‡æ¡£æ·»åŠ æˆåŠŸ
        loaded_collection = self.demo.chroma_client.get_collection("test_documents")
        self.assertEqual(loaded_collection.count(), len(self.test_documents))
    
    def test_search_functionality(self):
        """æµ‹è¯•æœç´¢åŠŸèƒ½"""
        self.demo.add_documents(
            collection_name="sanguo_documents",
            documents=self.test_documents,
            metadatas=[{"category": "æµ‹è¯•"}] * len(self.test_documents),
            ids=[f"doc_{i}" for i in range(len(self.test_documents))]
        )
        
        results = self.demo.search("ä¸‰å›½æ—¶æœŸ", n_results=2)
        self.assertGreater(len(results['documents'][0]), 0)
        self.assertEqual(len(results['metadatas'][0]), len(results['documents'][0]))


if __name__ == '__main__':
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    unittest.main(verbosity=2)
```

### 2. é›†æˆæµ‹è¯•

#### ç«¯åˆ°ç«¯æµ‹è¯•

```python
import pytest
import tempfile
import os
from pathlib import Path


class TestEndToEnd:
    """ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    @pytest.fixture
    def temp_dir(self):
        """åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•"""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield temp_dir
    
    def test_complete_pipeline(self, temp_dir):
        """æµ‹è¯•å®Œæ•´æ•°æ®å¤„ç†ç®¡é“"""
        # åˆ›å»ºæµ‹è¯•PDFæ–‡ä»¶
        test_pdf_path = os.path.join(temp_dir, "test.pdf")
        create_test_pdf(test_pdf_path)
        
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
        original_data_dir = os.environ.get('DATA_DIR', '')
        os.environ['DATA_DIR'] = temp_dir
        
        try:
            # è¿è¡Œå®Œæ•´ç®¡é“
            system = AIInterviewQASystem()
            
            # æ¨¡æ‹ŸPDFè§£æ
            pdf_text = read_test_pdf(test_pdf_path)
            qa_pairs = system.parse_pdf_content(pdf_text)
            
            # ç”Ÿæˆå‘é‡
            texts = [qa['full_text'] for qa in qa_pairs]
            embeddings = system.generate_embeddings(texts)
            
            # åˆ›å»ºç´¢å¼•
            system.create_faiss_index(embeddings)
            
            # ä¿å­˜å…ƒæ•°æ®
            system.save_metadata(qa_pairs)
            
            # éªŒè¯ç»“æœ
            assert len(qa_pairs) > 0
            assert embeddings.shape[0] == len(qa_pairs)
            assert system.index.ntotal == len(qa_pairs)
            assert len(system.metadata_store) == len(qa_pairs)
            
        finally:
            os.environ['DATA_DIR'] = original_data_dir
    
    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        # æµ‹è¯•æ— æ•ˆPDFæ–‡ä»¶
        with pytest.raises(FileNotFoundError):
            system = AIInterviewQASystem()
            system.parse_pdf_content("")
        
        # æµ‹è¯•ç©ºæ–‡æœ¬
        system = AIInterviewQASystem()
        empty_results = system.parse_pdf_content("")
        assert len(empty_results) == 0
        
        # æµ‹è¯•æ— æ•ˆæŸ¥è¯¢
        system.load_system()
        empty_results = system.search("")
        assert len(empty_results) == 0
```

### 3. æ€§èƒ½æµ‹è¯•

#### å‹åŠ›æµ‹è¯•

```python
import time
import numpy as np
from concurrent.futures import ThreadPoolExecutor, as_completed


class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""
    
    def test_vector_generation_performance(self):
        """æµ‹è¯•å‘é‡ç”Ÿæˆæ€§èƒ½"""
        system = AIInterviewQASystem()
        
        # æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°çš„æ€§èƒ½
        batch_sizes = [10, 50, 100, 500, 1000]
        results = {}
        
        for batch_size in batch_sizes:
            test_texts = ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"] * batch_size
            
            start_time = time.time()
            embeddings = system.generate_embeddings(test_texts)
            end_time = time.time()
            
            duration = end_time - start_time
            results[batch_size] = {
                'duration': duration,
                'throughput': batch_size / duration,
                'avg_time_per_text': duration / batch_size
            }
            
            print(f"æ‰¹æ¬¡å¤§å° {batch_size}: {duration:.2f}ç§’, ååé‡: {results[batch_size]['throughput']:.0f} æ–‡æœ¬/ç§’")
        
        # éªŒè¯æ€§èƒ½ç¬¦åˆé¢„æœŸ
        assert results[1000]['avg_time_per_text'] < 0.1  # æ¯ä¸ªæ–‡æœ¬å°äº100ms
    
    def test_search_performance(self):
        """æµ‹è¯•æœç´¢æ€§èƒ½"""
        system = AIInterviewQASystem()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_texts = [f"æµ‹è¯•æ–‡æœ¬ {i}" for i in range(1000)]
        embeddings = system.generate_embeddings(test_texts)
        system.create_faiss_index(embeddings)
        
        # æµ‹è¯•ä¸åŒæŸ¥è¯¢é‡çš„æ€§èƒ½
        query_counts = [1, 10, 50, 100]
        results = {}
        
        for query_count in query_counts:
            test_queries = [f"æµ‹è¯•æŸ¥è¯¢ {i}" for i in range(query_count)]
            
            start_time = time.time()
            for query in test_queries:
                system.search(query, top_k=5)
            end_time = time.time()
            
            duration = end_time - start_time
            results[query_count] = {
                'duration': duration,
                'avg_time_per_query': duration / query_count,
                'queries_per_second': query_count / duration
            }
            
            print(f"æŸ¥è¯¢æ•°é‡ {query_count}: {duration:.2f}ç§’, å¹³å‡æŸ¥è¯¢æ—¶é—´: {results[query_count]['avg_time_per_query']:.3f}ç§’")
        
        # éªŒè¯æ€§èƒ½ç¬¦åˆé¢„æœŸ
        assert results[100]['avg_time_per_query'] < 0.5  # æ¯ä¸ªæŸ¥è¯¢å°äº500ms
    
    def test_concurrent_performance(self):
        """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
        system = AIInterviewQASystem()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_texts = [f"æµ‹è¯•æ–‡æœ¬ {i}" for i in range(100)]
        embeddings = system.generate_embeddings(test_texts)
        system.create_faiss_index(embeddings)
        
        # æµ‹è¯•å¹¶å‘æŸ¥è¯¢
        def search_worker(query):
            return system.search(query, top_k=3)
        
        test_queries = [f"æµ‹è¯•æŸ¥è¯¢ {i}" for i in range(20)]
        
        start_time = time.time()
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(search_worker, query) for query in test_queries]
            results = [future.result() for future in as_completed(futures)]
        end_time = time.time()
        
        duration = end_time - start_time
        print(f"å¹¶å‘æŸ¥è¯¢20ä¸ªï¼Œ4ä¸ªçº¿ç¨‹: {duration:.2f}ç§’, å¹³å‡æŸ¥è¯¢æ—¶é—´: {duration/20:.3f}ç§’")
        
        assert len(results) == 20
```

## éƒ¨ç½²ç­–ç•¥

### 1. å¼€å‘ç¯å¢ƒéƒ¨ç½²

#### Dockerå®¹å™¨åŒ–éƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    make \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å®‰è£…FAISSï¼ˆéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
RUN pip install faiss-cpu

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /app/data /app/model /app/output

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV DATA_DIR=/app/data
ENV MODEL_DIR=/app/model
ENV OUTPUT_DIR=/app/output

# æš´éœ²ç«¯å£ï¼ˆå¦‚æœéœ€è¦WebæœåŠ¡ï¼‰
EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "from code.ai_interview_qa_system import AIInterviewQASystem; print('OK')" || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["uv", "run", "python", "code/ai_interview_qa_system.py"]
```

#### Docker Composeé…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  vector-db-system:
    build: .
    container_name: vector-db-system
    volumes:
      - ./data:/app/data
      - ./model:/app/model
      - ./output:/app/output
    environment:
      - PYTHONUNBUFFERED=1
      - DATA_DIR=/app/data
      - MODEL_DIR=/app/model
      - OUTPUT_DIR=/app/output
    ports:
      - "8000:8000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  redis:
    image: redis:7-alpine
    container_name: vector-db-redis
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    restart: unless-stopped

volumes:
  redis_data:
```

### 2. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### Kuberneteséƒ¨ç½²

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vector-db-system
  labels:
    app: vector-db-system
spec:
  replicas: 3
  selector:
    matchLabels:
      app: vector-db-system
  template:
    metadata:
      labels:
        app: vector-db-system
    spec:
      containers:
      - name: vector-db-system
        image: vector-db-system:latest
        ports:
        - containerPort: 8000
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        - name: DATA_DIR
          value: "/app/data"
        - name: MODEL_DIR
          value: "/app/model"
        - name: OUTPUT_DIR
          value: "/app/output"
        volumeMounts:
        - name: data-volume
          mountPath: /app/data
        - name: model-volume
          mountPath: /app/model
        - name: output-volume
          mountPath: /app/output
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: data-volume
        persistentVolumeClaim:
          claimName: data-pvc
      - name: model-volume
        persistentVolumeClaim:
          claimName: model-pvc
      - name: output-volume
        persistentVolumeClaim:
          claimName: output-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: vector-db-service
spec:
  selector:
    app: vector-db-system
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
```

#### é…ç½®æ–‡ä»¶ç®¡ç†

```yaml
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: vector-db-config
data:
  model_name: "paraphrase-multilingual-MiniLM-L12-v2"
  dimension: "384"
  top_k: "5"
  threshold: "0.1"
  batch_size: "100"
  max_workers: "4"
```

### 3. ç›‘æ§å’Œæ—¥å¿—

#### Prometheusç›‘æ§

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'vector-db-system'
    static_configs:
      - targets: ['vector-db-service:8000']
    metrics_path: '/metrics'
    scrape_interval: 5s
```

#### æ—¥å¿—é…ç½®

```python
# logging_config.py
import logging
import logging.config
import yaml

LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'standard': {
            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        },
        'detailed': {
            'format': '%(asctime)s [%(levelname)s] %(name)s:%(lineno)d: %(message)s'
        },
    },
    'handlers': {
        'console': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'standard',
            'stream': 'ext://sys.stdout'
        },
        'file': {
            'level': 'INFO',
            'class': 'logging.handlers.RotatingFileHandler',
            'formatter': 'detailed',
            'filename': '/app/logs/system.log',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5
        },
        'error_file': {
            'level': 'ERROR',
            'class': 'logging.handlers.RotatingFileHandler',
            'formatter': 'detailed',
            'filename': '/app/logs/error.log',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5
        }
    },
    'loggers': {
        '': {
            'handlers': ['console', 'file', 'error_file'],
            'level': 'INFO',
            'propagate': False
        }
    }
}

def setup_logging():
    logging.config.dictConfig(LOGGING_CONFIG)
```

### 4. CI/CDæµæ°´çº¿

#### GitHub Actionsé…ç½®

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11, 3.12]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 black
    
    - name: Lint with flake8
      run: |
        flake8 code/ --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 code/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: Format check with black
      run: |
        black --check code/
    
    - name: Run tests
      run: |
        pytest tests/ --cov=code --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: |
        docker build -t vector-db-system:${{ github.sha }} .
        docker tag vector-db-system:${{ github.sha }} vector-db-system:latest
    
    - name: Push to registry
      run: |
        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
        docker push vector-db-system:${{ github.sha }}
        docker push vector-db-system:latest

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Deploy to production
      run: |
        # éƒ¨ç½²è„šæœ¬
        kubectl set image deployment/vector-db-system \
          vector-db-system=vector-db-system:${{ github.sha }} \
          -n production
```

## éƒ¨ç½²éªŒè¯

### 1. éƒ¨ç½²åéªŒè¯

```python
# deployment_validator.py
import requests
import time
import logging

logger = logging.getLogger(__name__)

def validate_deployment(base_url: str, timeout: int = 60):
    """éªŒè¯éƒ¨ç½²æ˜¯å¦æˆåŠŸ"""
    
    # 1. å¥åº·æ£€æŸ¥
    health_url = f"{base_url}/health"
    try:
        response = requests.get(health_url, timeout=5)
        if response.status_code == 200:
            logger.info("âœ… å¥åº·æ£€æŸ¥é€šè¿‡")
        else:
            logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥è¶…æ—¶æˆ–å¤±è´¥: {e}")
        return False
    
    # 2. åŠŸèƒ½æµ‹è¯•
    test_queries = [
        "å¦‚ä½•è¿›è¡Œè‡ªæˆ‘ä»‹ç»ï¼Ÿ",
        "AIäº§å“ç»ç†çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]
    
    for query in test_queries:
        search_url = f"{base_url}/search"
        try:
            response = requests.post(search_url, json={"query": query}, timeout=10)
            if response.status_code == 200:
                result = response.json()
                if result.get("results"):
                    logger.info(f"âœ… æŸ¥è¯¢ '{query}' æˆåŠŸ")
                else:
                    logger.warning(f"âš ï¸  æŸ¥è¯¢ '{query}' æ— ç»“æœ")
            else:
                logger.error(f"âŒ æŸ¥è¯¢ '{query}' å¤±è´¥: {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢ '{query}' å¼‚å¸¸: {e}")
            return False
    
    # 3. æ€§èƒ½æµ‹è¯•
    performance_url = f"{base_url}/performance"
    try:
        response = requests.get(performance_url, timeout=10)
        if response.status_code == 200:
            perf_data = response.json()
            if perf_data.get("status") == "ok":
                logger.info("âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡")
                logger.info(f"   å¹³å‡å“åº”æ—¶é—´: {perf_data.get('avg_response_time', 'N/A')}ms")
                logger.info(f"   ååé‡: {perf_data.get('throughput', 'N/A')} queries/sec")
            else:
                logger.error(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {perf_data}")
                return False
        else:
            logger.error(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"âŒ æ€§èƒ½æµ‹è¯•å¼‚å¸¸: {e}")
        return False
    
    logger.info("ğŸ‰ éƒ¨ç½²éªŒè¯å…¨éƒ¨é€šè¿‡")
    return True

def wait_for_deployment(base_url: str, max_wait_time: int = 300):
    """ç­‰å¾…éƒ¨ç½²å®Œæˆ"""
    start_time = time.time()
    
    while time.time() - start_time < max_wait_time:
        if validate_deployment(base_url):
            return True
        logger.info("ç­‰å¾…éƒ¨ç½²å®Œæˆ...")
        time.sleep(10)
    
    logger.error("éƒ¨ç½²éªŒè¯è¶…æ—¶")
    return False
```

### 2. å›æ»šç­–ç•¥

```python
# rollback_manager.py
import logging
import subprocess
from typing import Optional

logger = logging.getLogger(__name__)

class RollbackManager:
    """å›æ»šç®¡ç†å™¨"""
    
    def __init__(self, deployment_name: str, namespace: str = "default"):
        self.deployment_name = deployment_name
        self.namespace = namespace
    
    def create_rollback_point(self, deployment_name: str, namespace: str = "default"):
        """åˆ›å»ºå›æ»šç‚¹"""
        try:
            # è·å–å½“å‰éƒ¨ç½²çš„ç‰ˆæœ¬
            cmd = [
                "kubectl", "get", "deployment", deployment_name,
                "-o", "jsonpath={.spec.template.metadata.labels.version}",
                "-n", namespace
            ]
            result = subprocess.run(cmd, capture_output=True, text=True)
            current_version = result.stdout.strip()
            
            # ä¿å­˜å›æ»šç‚¹ä¿¡æ¯
            rollback_point = {
                "deployment": deployment_name,
                "namespace": namespace,
                "version": current_version,
                "timestamp": time.time()
            }
            
            logger.info(f"âœ… åˆ›å»ºå›æ»šç‚¹: {rollback_point}")
            return rollback_point
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºå›æ»šç‚¹å¤±è´¥: {e}")
            return None
    
    def rollback_to_version(self, version: str, timeout: int = 300):
        """å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬"""
        try:
            # æ‰§è¡Œå›æ»šæ“ä½œ
            cmd = [
                "kubectl", "set", "image", "deployment", self.deployment_name,
                f"{self.deployment_name}={self.deployment_name}:{version}",
                "-n", self.namespace
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                logger.info(f"âœ… å¼€å§‹å›æ»šåˆ°ç‰ˆæœ¬: {version}")
                
                # ç­‰å¾…å›æ»šå®Œæˆ
                if self._wait_for_rollback_completion(timeout):
                    logger.info("âœ… å›æ»šæˆåŠŸ")
                    return True
                else:
                    logger.error("âŒ å›æ»šè¶…æ—¶")
                    return False
            else:
                logger.error(f"âŒ å›æ»šå¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ å›æ»šå¼‚å¸¸: {e}")
            return False
    
    def _wait_for_rollback_completion(self, timeout: int) -> bool:
        """ç­‰å¾…å›æ»šå®Œæˆ"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            try:
                # æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
                cmd = [
                    "kubectl", "get", "deployment", self.deployment_name,
                    "-o", "jsonpath={.status.readyReplicas}",
                    "-n", self.namespace
                ]
                result = subprocess.run(cmd, capture_output=True, text=True)
                
                if result.stdout.strip() == "0":
                    logger.info("âœ… å›æ»šå®Œæˆ")
                    return True
                
                time.sleep(10)
            except Exception as e:
                logger.error(f"âŒ æ£€æŸ¥å›æ»šçŠ¶æ€å¤±è´¥: {e}")
                return False
        
        return False
```

---

*æœ€åæ›´æ–°: 2026å¹´1æœˆ24æ—¥*
*æµ‹è¯•å’Œéƒ¨ç½²ç‰ˆæœ¬: v1.0*
*è¿ç»´å›¢é˜Ÿ: DevOpsè¿ç»´ç»„*