#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Propheté¢„æµ‹æ¨¡å‹ v3.0 - é«˜çº§ä¼˜åŒ–ç‰ˆæœ¬
åŸºäºProphetç®—æ³•çš„ç»¼åˆä¼˜åŒ–ç‰ˆæœ¬ï¼ŒåŒ…å«å¤šé‡ç‰¹å¾å·¥ç¨‹å’Œå‚æ•°è°ƒä¼˜
ç‰ˆæœ¬ç‰¹æ€§ï¼šå¤–éƒ¨å˜é‡é›†æˆã€å¤šé‡å­£èŠ‚æ€§ã€å¼‚å¸¸å€¼å¤„ç†ã€å‚æ•°ä¼˜åŒ–
æ¼”è¿›ï¼šä»v2åŸºç¡€+èŠ‚å‡æ—¥å‡çº§åˆ°ç»¼åˆä¼˜åŒ–ç‰ˆæœ¬
æ ¸å¿ƒåˆ›æ–°ï¼šåˆ©ç‡å›å½’å˜é‡ã€å¼‚å¸¸å€¼æ£€æµ‹ã€æ¨¡å‹å‚æ•°è‡ªåŠ¨è°ƒä¼˜
"""

import pandas as pd
import numpy as np
from prophet import Prophet
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

from sklearn.metrics import mean_absolute_error, mean_squared_error
from scipy import stats
import pickle


def get_project_path(*paths):
    """è·å–é¡¹ç›®è·¯å¾„çš„ç»Ÿä¸€æ–¹æ³•"""
    import os
    try:
        return os.path.join(os.path.dirname(__file__), *paths)
    except NameError:
        return os.path.join(os.getcwd(), *paths)


def load_external_features():
    """åŠ è½½å¤–éƒ¨ç‰¹å¾æ•°æ®ï¼ˆåˆ©ç‡ã€æ”¶ç›Šç‡ç­‰ï¼‰"""
    print("=== åŠ è½½å¤–éƒ¨ç‰¹å¾æ•°æ® ===")
    
    # åŠ è½½è´§å¸åŸºé‡‘æ”¶ç›Šç‡æ•°æ®
    interest_file = get_project_path('..', 'data', 'mfd_day_share_interest.csv')
    interest_df = pd.read_csv(interest_file)
    interest_df['ds'] = pd.to_datetime(interest_df['mfd_date'], format='%Y%m%d')
    interest_df = interest_df[['ds', 'mfd_daily_yield', 'mfd_7daily_yield']].copy()
    
    # åŠ è½½é“¶è¡Œæ‹†å€Ÿåˆ©ç‡æ•°æ®
    shibor_file = get_project_path('..', 'data', 'mfd_bank_shibor.csv')
    shibor_df = pd.read_csv(shibor_file)
    shibor_df['ds'] = pd.to_datetime(shibor_df['mfd_date'], format='%Y%m%d')
    # é€‰æ‹©ä¸»è¦æœŸé™åˆ©ç‡
    shibor_df = shibor_df[['ds', 'Interest_O_N', 'Interest_1_W', 'Interest_1_M']].copy()
    
    print(f"å¤–éƒ¨ç‰¹å¾åŠ è½½å®Œæˆ:")
    print(f"- æ”¶ç›Šç‡æ•°æ®: {len(interest_df)} å¤©")
    print(f"- æ‹†å€Ÿåˆ©ç‡æ•°æ®: {len(shibor_df)} å¤©")
    
    return interest_df, shibor_df


def detect_and_handle_outliers(data, column, method='iqr', threshold=3):
    """æ£€æµ‹å’Œå¤„ç†å¼‚å¸¸å€¼"""
    print(f"=== æ£€æµ‹å’Œå¤„ç†{column}å¼‚å¸¸å€¼ ===")
    
    original_data = data.copy()
    
    if method == 'iqr':
        # ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outlier_mask = (data[column] < lower_bound) | (data[column] > upper_bound)
        
    elif method == 'zscore':
        # ä½¿ç”¨Z-scoreæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
        z_scores = np.abs(stats.zscore(data[column]))
        outlier_mask = z_scores > threshold
    
    outlier_count = outlier_mask.sum()
    outlier_percentage = (outlier_count / len(data)) * 100
    
    print(f"æ£€æµ‹åˆ°å¼‚å¸¸å€¼: {outlier_count} ä¸ª ({outlier_percentage:.1f}%)")
    
    if outlier_count > 0:
        # ä½¿ç”¨ä¸­ä½æ•°æ›¿æ¢å¼‚å¸¸å€¼
        median_value = data[column].median()
        data.loc[outlier_mask, column] = median_value
        
        print(f"å¼‚å¸¸å€¼å¤„ç†å®Œæˆï¼Œä½¿ç”¨ä¸­ä½æ•°({median_value:,.0f})æ›¿æ¢")
    
    return data, outlier_mask


def create_enhanced_features(df, interest_df, shibor_df):
    """åˆ›å»ºå¢å¼ºç‰¹å¾"""
    print("=== åˆ›å»ºå¢å¼ºç‰¹å¾ ===")
    
    # åˆå¹¶å¤–éƒ¨æ•°æ®
    enhanced_df = df.merge(interest_df, on='ds', how='left')
    enhanced_df = enhanced_df.merge(shibor_df, on='ds', how='left')
    
    # å¡«å……ç¼ºå¤±å€¼ï¼ˆä½¿ç”¨å‰å‘å¡«å……ï¼‰
    enhanced_df[['mfd_daily_yield', 'mfd_7daily_yield', 'Interest_O_N', 'Interest_1_W', 'Interest_1_M']] = \
        enhanced_df[['mfd_daily_yield', 'mfd_7daily_yield', 'Interest_O_N', 'Interest_1_W', 'Interest_1_M']].fillna(method='ffill')
    
    # åˆ›å»ºæ»åç‰¹å¾ï¼ˆå‰1-7å¤©ï¼‰
    for lag in range(1, 8):
        enhanced_df[f'y_lag_{lag}'] = enhanced_df['y'].shift(lag)
    
    # åˆ›å»ºæ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
    enhanced_df['y_ma_7'] = enhanced_df['y'].rolling(window=7, min_periods=1).mean()
    enhanced_df['y_ma_30'] = enhanced_df['y'].rolling(window=30, min_periods=1).mean()
    enhanced_df['y_std_7'] = enhanced_df['y'].rolling(window=7, min_periods=1).std()
    
    # åˆ›å»ºè¶‹åŠ¿ç‰¹å¾
    enhanced_df['day_of_year'] = enhanced_df['ds'].dt.dayofyear
    enhanced_df['day_of_month'] = enhanced_df['ds'].dt.day
    enhanced_df['week_of_year'] = enhanced_df['ds'].dt.isocalendar().week
    enhanced_df['is_month_end'] = (enhanced_df['day_of_month'] >= 28).astype(int)
    enhanced_df['is_month_start'] = (enhanced_df['day_of_month'] <= 3).astype(int)
    
    # åˆ›å»ºå‘¨æœ«æ•ˆåº”ç‰¹å¾
    enhanced_df['is_weekend'] = (enhanced_df['ds'].dt.weekday >= 5).astype(int)
    enhanced_df['is_friday'] = (enhanced_df['ds'].dt.weekday == 4).astype(int)
    enhanced_df['is_monday'] = (enhanced_df['ds'].dt.weekday == 0).astype(int)
    
    print(f"å¢å¼ºç‰¹å¾åˆ›å»ºå®Œæˆ: {len(enhanced_df.columns)} ä¸ªç‰¹å¾")
    
    return enhanced_df


def create_china_holidays_v3():
    """åˆ›å»ºv3ç‰ˆæœ¬çš„èŠ‚å‡æ—¥æ•°æ®ï¼ˆæ›´ç²¾ç¡®çš„èŠ‚å‡æ—¥æ•ˆåº”ï¼‰"""
    holidays = []
    
    # ä¸»è¦èŠ‚å‡æ—¥ï¼ˆå¸¦æƒé‡ï¼‰
    main_holidays = [
        # æ˜¥èŠ‚æ•ˆåº”æœ€å¼ºï¼ˆ7å¤©å‡æœŸï¼‰
        {'holiday': 'æ˜¥èŠ‚å‡æœŸ', 'ds': '2013-02-09', 'lower_window': -3, 'upper_window': 4},
        {'holiday': 'æ˜¥èŠ‚å‡æœŸ', 'ds': '2014-01-30', 'lower_window': -3, 'upper_window': 4},
        
        # å›½åº†èŠ‚ï¼ˆ7å¤©ï¼‰
        {'holiday': 'å›½åº†å‡æœŸ', 'ds': '2013-10-01', 'lower_window': 0, 'upper_window': 6},
        {'holiday': 'å›½åº†å‡æœŸ', 'ds': '2014-10-01', 'lower_window': 0, 'upper_window': 6},
        
        # åŠ³åŠ¨èŠ‚ï¼ˆ3å¤©ï¼‰
        {'holiday': 'åŠ³åŠ¨èŠ‚', 'ds': '2013-05-01', 'lower_window': 0, 'upper_window': 2},
        {'holiday': 'åŠ³åŠ¨èŠ‚', 'ds': '2014-05-01', 'lower_window': 0, 'upper_window': 2},
        
        # æ¸…æ˜èŠ‚ï¼ˆ3å¤©ï¼‰
        {'holiday': 'æ¸…æ˜èŠ‚', 'ds': '2013-04-04', 'lower_window': 0, 'upper_window': 2},
        {'holiday': 'æ¸…æ˜èŠ‚', 'ds': '2014-04-05', 'lower_window': 0, 'upper_window': 2},
        
        # ç«¯åˆèŠ‚ï¼ˆ3å¤©ï¼‰
        {'holiday': 'ç«¯åˆèŠ‚', 'ds': '2013-06-12', 'lower_window': 0, 'upper_window': 2},
        {'holiday': 'ç«¯åˆèŠ‚', 'ds': '2014-05-31', 'lower_window': 0, 'upper_window': 2},
        
        # ä¸­ç§‹èŠ‚ï¼ˆ3å¤©ï¼‰
        {'holiday': 'ä¸­ç§‹èŠ‚', 'ds': '2013-09-19', 'lower_window': 0, 'upper_window': 2},
        {'holiday': 'ä¸­ç§‹èŠ‚', 'ds': '2014-09-06', 'lower_window': 0, 'upper_window': 2},
        
        # å…ƒæ—¦
        {'holiday': 'å…ƒæ—¦', 'ds': '2013-01-01', 'lower_window': 0, 'upper_window': 0},
        {'holiday': 'å…ƒæ—¦', 'ds': '2014-01-01', 'lower_window': 0, 'upper_window': 0},
    ]
    
    holidays.extend(main_holidays)
    
    return pd.DataFrame(holidays)


def optimize_prophet_parameters(df):
    """ä¼˜åŒ–Prophetæ¨¡å‹å‚æ•°"""
    print("=== Prophetå‚æ•°ä¼˜åŒ– ===")
    
    # å‚æ•°å€™é€‰å€¼
    param_grid = {
        'changepoint_prior_scale': [0.01, 0.05, 0.1],
        'seasonality_prior_scale': [1, 10, 100],
        'holidays_prior_scale': [1, 10, 100],
        'seasonality_mode': ['additive', 'multiplicative']
    }
    
    best_score = float('inf')
    best_params = None
    
    # ç®€åŒ–çš„ç½‘æ ¼æœç´¢ï¼ˆé¿å…è¿‡é•¿æ—¶é—´ï¼‰
    for changepoint_prior_scale in [0.01, 0.05, 0.1]:
        for seasonality_prior_scale in [1, 10]:
            for seasonality_mode in ['additive', 'multiplicative']:
                try:
                    # åˆ›å»ºæ¨¡å‹
                    model = Prophet(
                        yearly_seasonality=True,
                        weekly_seasonality=True,
                        daily_seasonality=False,
                        seasonality_mode=seasonality_mode,
                        changepoint_prior_scale=changepoint_prior_scale,
                        seasonality_prior_scale=seasonality_prior_scale,
                        holidays_prior_scale=10.0,
                        interval_width=0.95
                    )
                    
                    # è®­ç»ƒæ¨¡å‹
                    model.fit(df.iloc[:-30])  # ä½¿ç”¨é™¤æœ€å30å¤©å¤–çš„æ•°æ®
                    
                    # é¢„æµ‹æœ€å30å¤©
                    future = model.make_future_dataframe(periods=30)
                    forecast = model.predict(future)
                    predictions = forecast['yhat'].iloc[-30:]
                    actual = df['y'].iloc[-30:]
                    
                    # è®¡ç®—MAPE
                    mape = np.mean(np.abs((actual - predictions) / actual)) * 100
                    
                    if mape < best_score:
                        best_score = mape
                        best_params = {
                            'changepoint_prior_scale': changepoint_prior_scale,
                            'seasonality_prior_scale': seasonality_prior_scale,
                            'seasonality_mode': seasonality_mode
                        }
                        
                    print(f"å‚æ•°ç»„åˆæµ‹è¯•: MAPE={mape:.2f}%")
                    
                except Exception as e:
                    print(f"å‚æ•°ç»„åˆæµ‹è¯•å¤±è´¥: {e}")
                    continue
    
    print(f"æœ€ä¼˜å‚æ•°: {best_params}, æœ€ä½³MAPE: {best_score:.2f}%")
    return best_params


def train_optimized_prophet_model(df, model_name, target_column, interest_df, shibor_df):
    """è®­ç»ƒä¼˜åŒ–ç‰ˆProphetæ¨¡å‹"""
    print(f"\n=== è®­ç»ƒ{model_name}ä¼˜åŒ–ç‰ˆProphetæ¨¡å‹ ===")
    
    # æ•°æ®é¢„å¤„ç†
    processed_df, outlier_mask = detect_and_handle_outliers(df, 'y')
    
    # åˆ›å»ºå¢å¼ºç‰¹å¾
    enhanced_df = create_enhanced_features(processed_df, interest_df, shibor_df)
    
    # åˆ›å»ºèŠ‚å‡æ—¥
    holidays_df = create_china_holidays_v3()
    
    # å‚æ•°ä¼˜åŒ–
    best_params = optimize_prophet_parameters(enhanced_df)
    
    # åˆ›å»ºä¼˜åŒ–ç‰ˆProphetæ¨¡å‹
    model = Prophet(
        yearly_seasonality=True,
        weekly_seasonality=True,
        daily_seasonality=False,
        seasonality_mode=best_params['seasonality_mode'],
        changepoint_prior_scale=best_params['changepoint_prior_scale'],
        seasonality_prior_scale=best_params['seasonality_prior_scale'],
        holidays_prior_scale=10.0,
        mcmc_samples=0,
        holidays=holidays_df,
        interval_width=0.95,
        uncertainty_samples=1000
    )
    
    # æ·»åŠ å¤–éƒ¨å›å½’å˜é‡
    if not enhanced_df['mfd_daily_yield'].isna().all():
        model.add_regressor('mfd_daily_yield')
    if not enhanced_df['Interest_O_N'].isna().all():
        model.add_regressor('Interest_O_N')
    
    # æ·»åŠ è‡ªå®šä¹‰å­£èŠ‚æ€§
    model.add_seasonality(name='monthly', period=30.5, fourier_order=5)
    model.add_seasonality(name='quarterly', period=91.25, fourier_order=3)
    
    # è®­ç»ƒæ¨¡å‹
    model.fit(enhanced_df)
    
    # åˆ›å»ºæœªæ¥æ—¥æœŸå¹¶é¢„æµ‹
    future = model.make_future_dataframe(periods=30)
    
    # ä¸ºæœªæ¥æ—¥æœŸæ·»åŠ å¤–éƒ¨ç‰¹å¾ï¼ˆä½¿ç”¨æœ€åå·²çŸ¥å€¼ï¼‰
    for col in ['mfd_daily_yield', 'mfd_7daily_yield', 'Interest_O_N', 'Interest_1_W', 'Interest_1_M']:
        if col in enhanced_df.columns:
            last_value = enhanced_df[col].iloc[-1]
            future[col] = last_value
    
    forecast = model.predict(future)
    
    # ä¿å­˜æ¨¡å‹
    model_path = get_project_path('..', 'model', f'{target_column}_prophet_v3_model.pkl')
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    
    print(f"ä¼˜åŒ–ç‰ˆæ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    print(f"æ¨¡å‹ç‰¹å¾æ•°: {len(enhanced_df.columns)}")
    
    return model, forecast, enhanced_df, outlier_mask


def generate_optimized_predictions(purchase_model, redeem_model, forecast_purchase, forecast_redeem):
    """ç”Ÿæˆä¼˜åŒ–ç‰ˆé¢„æµ‹ç»“æœ"""
    print("\n=== ç”Ÿæˆä¼˜åŒ–ç‰ˆé¢„æµ‹ç»“æœ ===")
    
    # è·å–æœªæ¥30å¤©çš„é¢„æµ‹
    future_predictions = forecast_purchase.tail(30)
    future_redeem = forecast_redeem.tail(30)
    
    # åˆ›å»ºé¢„æµ‹ç»“æœæ•°æ®æ¡†
    predictions = pd.DataFrame({
        'date': future_predictions['ds'],
        'purchase_forecast': future_predictions['yhat'],
        'redeem_forecast': future_redeem['yhat'],
        'purchase_lower': future_predictions['yhat_lower'],
        'purchase_upper': future_predictions['yhat_upper'],
        'redeem_lower': future_redeem['yhat_lower'],
        'redeem_upper': future_redeem['yhat_upper']
    })
    
    # æ·»åŠ æ—¥æœŸç‰¹å¾
    predictions['weekday'] = predictions['date'].dt.dayofweek
    predictions['is_weekend'] = predictions['weekday'].isin([5, 6])
    predictions['is_friday'] = predictions['weekday'] == 4
    predictions['is_monday'] = predictions['weekday'] == 0
    predictions['day_name'] = predictions['date'].dt.day_name()
    
    # è®¡ç®—å‡€æµå…¥
    predictions['net_flow'] = predictions['purchase_forecast'] - predictions['redeem_forecast']
    predictions['net_flow_lower'] = predictions['purchase_lower'] - predictions['redeem_upper']
    predictions['net_flow_upper'] = predictions['purchase_upper'] - predictions['redeem_lower']
    
    # ä¿å­˜ä¼˜åŒ–ç‰ˆé¢„æµ‹ç»“æœï¼ˆè€ƒè¯•æ ¼å¼ï¼‰
    prediction_file = get_project_path('..', 'prediction_result', 'prophet_v3_predictions_201409.csv')
    exam_format = predictions[['date']].copy()
    exam_format['date'] = exam_format['date'].dt.strftime('%Y%m%d')
    exam_format['purchase'] = predictions['purchase_forecast'].round(0).astype(int)
    exam_format['redeem'] = predictions['redeem_forecast'].round(0).astype(int)
    
    exam_format.to_csv(prediction_file, header=False, index=False)
    
    print(f"ä¼˜åŒ–ç‰ˆé¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {prediction_file}")
    
    # ç»Ÿè®¡é¢„æµ‹ç»“æœ
    total_purchase = predictions['purchase_forecast'].sum()
    total_redeem = predictions['redeem_forecast'].sum()
    net_flow = total_purchase - total_redeem
    
    print(f"\nğŸ“Š é¢„æµ‹ç»“æœç»Ÿè®¡:")
    print(f"- æ€»ç”³è´­é¢„æµ‹: Â¥{total_purchase:,.0f}")
    print(f"- æ€»èµå›é¢„æµ‹: Â¥{total_redeem:,.0f}")
    print(f"- å‡€æµå…¥é¢„æµ‹: Â¥{net_flow:,.0f}")
    print(f"- å¹³å‡æ—¥ç”³è´­: Â¥{predictions['purchase_forecast'].mean():,.0f}")
    print(f"- å¹³å‡æ—¥èµå›: Â¥{predictions['redeem_forecast'].mean():,.0f}")
    
    return predictions


def create_optimized_visualization(purchase_df, redeem_df, forecast_purchase, forecast_redeem, predictions):
    """åˆ›å»ºä¼˜åŒ–ç‰ˆå¯è§†åŒ–å›¾è¡¨"""
    print("\n=== ç”Ÿæˆä¼˜åŒ–ç‰ˆå¯è§†åŒ–å›¾è¡¨ ===")
    
    # åˆ›å»ºç»¼åˆåˆ†æå›¾è¡¨
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    fig.suptitle('ä¼˜åŒ–ç‰ˆProphetæ—¶é—´åºåˆ—é¢„æµ‹åˆ†æ (v3.0)', fontsize=16, fontweight='bold')
    
    # 1. ç”³è´­é¢„æµ‹ä¸ç½®ä¿¡åŒºé—´
    ax1 = axes[0, 0]
    future_pred = forecast_purchase.tail(30)
    ax1.plot(purchase_df['ds'], purchase_df['y'], 'b-', alpha=0.7, label='å†å²ç”³è´­æ•°æ®')
    ax1.plot(future_pred['ds'], future_pred['yhat'], 'r-', linewidth=2, label='é¢„æµ‹ç”³è´­é¢')
    ax1.fill_between(future_pred['ds'], future_pred['yhat_lower'], future_pred['yhat_upper'],
                    alpha=0.2, color='red', label='95%ç½®ä¿¡åŒºé—´')
    ax1.set_title('ç”³è´­é‡‘é¢é¢„æµ‹ï¼ˆå«ç½®ä¿¡åŒºé—´ï¼‰')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. èµå›é¢„æµ‹ä¸ç½®ä¿¡åŒºé—´
    ax2 = axes[0, 1]
    future_redeem = forecast_redeem.tail(30)
    ax2.plot(redeem_df['ds'], redeem_df['y'], 'g-', alpha=0.7, label='å†å²èµå›æ•°æ®')
    ax2.plot(future_redeem['ds'], future_redeem['yhat'], 'orange', linewidth=2, label='é¢„æµ‹èµå›é¢')
    ax2.fill_between(future_redeem['ds'], future_redeem['yhat_lower'], future_redeem['yhat_upper'],
                    alpha=0.2, color='orange', label='95%ç½®ä¿¡åŒºé—´')
    ax2.set_title('èµå›é‡‘é¢é¢„æµ‹ï¼ˆå«ç½®ä¿¡åŒºé—´ï¼‰')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. å‡€æµå…¥åˆ†æ
    ax3 = axes[0, 2]
    ax3.plot(predictions['date'], predictions['net_flow'], 'purple', linewidth=2, label='å‡€æµå…¥')
    ax3.fill_between(predictions['date'], predictions['net_flow_lower'], predictions['net_flow_upper'],
                    alpha=0.2, color='purple', label='95%ç½®ä¿¡åŒºé—´')
    ax3.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    ax3.set_title('å‡€æµå…¥é¢„æµ‹åˆ†æ')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. å‘¨æœ«æ•ˆåº”åˆ†æ
    ax4 = axes[1, 0]
    weekend_data = predictions[predictions['is_weekend']]
    workday_data = predictions[~predictions['is_weekend']]
    
    if len(weekend_data) > 0 and len(workday_data) > 0:
        categories = ['å·¥ä½œæ—¥', 'å‘¨æœ«']
        purchase_means = [workday_data['purchase_forecast'].mean(), weekend_data['purchase_forecast'].mean()]
        redeem_means = [workday_data['redeem_forecast'].mean(), weekend_data['redeem_forecast'].mean()]
        
        x = np.arange(len(categories))
        width = 0.35
        
        ax4.bar(x - width/2, purchase_means, width, label='ç”³è´­', alpha=0.8)
        ax4.bar(x + width/2, redeem_means, width, label='èµå›', alpha=0.8)
        ax4.set_title('å·¥ä½œæ—¥ vs å‘¨æœ«æ•ˆåº”')
        ax4.set_ylabel('å¹³å‡é‡‘é¢')
        ax4.set_xticks(x)
        ax4.set_xticklabels(categories)
        ax4.legend()
        ax4.grid(True, alpha=0.3)
    
    # 5. é¢„æµ‹åˆ†å¸ƒåˆ†æ
    ax5 = axes[1, 1]
    ax5.hist(predictions['purchase_forecast'], bins=15, alpha=0.7, label='ç”³è´­é¢„æµ‹', color='red')
    ax5.hist(predictions['redeem_forecast'], bins=15, alpha=0.7, label='èµå›é¢„æµ‹', color='blue')
    ax5.set_title('é¢„æµ‹é‡‘é¢åˆ†å¸ƒ')
    ax5.set_xlabel('é‡‘é¢')
    ax5.set_ylabel('é¢‘æ¬¡')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    
    # 6. æ—¶é—´åºåˆ—åˆ†è§£
    ax6 = axes[1, 2]
    # æ˜¾ç¤ºè¶‹åŠ¿ç»„ä»¶
    trend = forecast_purchase['trend'].iloc[-60:]  # æœ€è¿‘60å¤©
    ax6.plot(trend.index, trend.values, 'green', linewidth=2, label='è¶‹åŠ¿')
    ax6.set_title('é•¿æœŸè¶‹åŠ¿åˆ†æ')
    ax6.set_xlabel('æ—¶é—´')
    ax6.set_ylabel('è¶‹åŠ¿å€¼')
    ax6.legend()
    ax6.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    chart_file = get_project_path('..', 'user_data', 'optimized_prophet_forecast_analysis.png')
    plt.savefig(chart_file, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ä¼˜åŒ–ç‰ˆåˆ†æå›¾è¡¨å·²ä¿å­˜åˆ°: {chart_file}")


def analyze_optimized_model_performance(forecast_purchase, forecast_redeem, purchase_df, redeem_df):
    """åˆ†æä¼˜åŒ–ç‰ˆæ¨¡å‹æ€§èƒ½"""
    print("\n=== ä¼˜åŒ–ç‰ˆæ¨¡å‹æ€§èƒ½åˆ†æ ===")
    
    # åˆ†ç¦»è®­ç»ƒæœŸå’Œé¢„æµ‹æœŸ
    train_size = len(purchase_df)
    test_purchase = forecast_purchase.iloc[:train_size]
    test_redeem = forecast_redeem.iloc[:train_size]
    
    # è®¡ç®—è¯¯å·®æŒ‡æ ‡
    purchase_mae = mean_absolute_error(purchase_df['y'], test_purchase['yhat'])
    purchase_rmse = np.sqrt(mean_squared_error(purchase_df['y'], test_purchase['yhat']))
    purchase_mape = np.mean(np.abs((purchase_df['y'] - test_purchase['yhat']) / purchase_df['y'])) * 100
    
    redeem_mae = mean_absolute_error(redeem_df['y'], test_redeem['yhat'])
    redeem_rmse = np.sqrt(mean_squared_error(redeem_df['y'], test_redeem['yhat']))
    redeem_mape = np.mean(np.abs((redeem_df['y'] - test_redeem['yhat']) / redeem_df['y'])) * 100
    
    # è®¡ç®—é¢„æµ‹ç¨³å®šæ€§ï¼ˆæ–¹å·®ï¼‰
    purchase_residuals = purchase_df['y'] - test_purchase['yhat']
    redeem_residuals = redeem_df['y'] - test_redeem['yhat']
    
    purchase_stability = np.std(purchase_residuals)
    redeem_stability = np.std(redeem_residuals)
    
    print(f"ä¼˜åŒ–ç‰ˆç”³è´­æ¨¡å‹æ€§èƒ½:")
    print(f"  MAE: Â¥{purchase_mae:,.0f}")
    print(f"  RMSE: Â¥{purchase_rmse:,.0f}")
    print(f"  MAPE: {purchase_mape:.2f}%")
    print(f"  ç¨³å®šæ€§(æ ‡å‡†å·®): Â¥{purchase_stability:,.0f}")
    
    print(f"\nä¼˜åŒ–ç‰ˆèµå›æ¨¡å‹æ€§èƒ½:")
    print(f"  MAE: Â¥{redeem_mae:,.0f}")
    print(f"  RMSE: Â¥{redeem_rmse:,.0f}")
    print(f"  MAPE: {redeem_mape:.2f}%")
    print(f"  ç¨³å®šæ€§(æ ‡å‡†å·®): Â¥{redeem_stability:,.0f}")
    
    return {
        'purchase_mae': purchase_mae,
        'purchase_rmse': purchase_rmse,
        'purchase_mape': purchase_mape,
        'purchase_stability': purchase_stability,
        'redeem_mae': redeem_mae,
        'redeem_rmse': redeem_rmse,
        'redeem_mape': redeem_mape,
        'redeem_stability': redeem_stability
    }


def save_detailed_results(predictions, performance):
    """ä¿å­˜è¯¦ç»†ç»“æœ"""
    print("\n=== ä¿å­˜è¯¦ç»†ç»“æœ ===")
    
    # ä¿å­˜è¯¦ç»†é¢„æµ‹ç»“æœ
    detailed_file = get_project_path('..', 'user_data', 'prophet_v3_detailed_201409.csv')
    predictions.to_csv(detailed_file, index=False)
    
    # ä¿å­˜æ€§èƒ½æŒ‡æ ‡
    performance_file = get_project_path('..', 'user_data', 'prophet_v3_performance.csv')
    performance_df = pd.DataFrame([performance])
    performance_df.to_csv(performance_file, index=False)
    
    print(f"è¯¦ç»†é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {detailed_file}")
    print(f"æ€§èƒ½æŒ‡æ ‡å·²ä¿å­˜åˆ°: {performance_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("=== ä¼˜åŒ–ç‰ˆProphetèµ„é‡‘æµå…¥æµå‡ºé¢„æµ‹åˆ†æ ===")
    print("ğŸ¯ æœ¬ç‰ˆæœ¬ç‰¹æ€§: å¤–éƒ¨å˜é‡ + å¼‚å¸¸å€¼å¤„ç† + å‚æ•°ä¼˜åŒ– + å¤šé‡å­£èŠ‚æ€§")
    
    try:
        # 1. åŠ è½½åŸºç¡€æ•°æ®
        data_file = get_project_path('..', 'user_data', 'daily_summary.csv')
        df = pd.read_csv(data_file, header=None, names=['date', 'purchase', 'redeem'])
        df['ds'] = pd.to_datetime(df['date'], format='%Y%m%d')
        
        # 2. åŠ è½½å¤–éƒ¨ç‰¹å¾
        interest_df, shibor_df = load_external_features()
        
        # 3. åˆ›å»ºProphetæ ¼å¼æ•°æ®
        purchase_df = df[['ds', 'purchase']].copy()
        purchase_df.rename(columns={'purchase': 'y'}, inplace=True)
        redeem_df = df[['ds', 'redeem']].copy()
        redeem_df.rename(columns={'redeem': 'y'}, inplace=True)
        
        print(f"\næ•°æ®æ¦‚å†µ:")
        print(f"- æ•°æ®æ—¶é—´èŒƒå›´: {df['ds'].min()} è‡³ {df['ds'].max()}")
        print(f"- æ€»å¤©æ•°: {len(df)} å¤©")
        print(f"- ç”³è´­æ•°æ®å¹³å‡: Â¥{purchase_df['y'].mean():,.0f}")
        print(f"- èµå›æ•°æ®å¹³å‡: Â¥{redeem_df['y'].mean():,.0f}")
        
        # 4. è®­ç»ƒä¼˜åŒ–ç‰ˆæ¨¡å‹
        global purchase_model, redeem_model
        purchase_model, forecast_purchase, purchase_enhanced, purchase_outliers = \
            train_optimized_prophet_model(purchase_df, "ç”³è´­", "purchase", interest_df, shibor_df)
        
        redeem_model, forecast_redeem, redeem_enhanced, redeem_outliers = \
            train_optimized_prophet_model(redeem_df, "èµå›", "redeem", interest_df, shibor_df)
        
        # 5. ç”Ÿæˆä¼˜åŒ–ç‰ˆé¢„æµ‹
        predictions = generate_optimized_predictions(purchase_model, redeem_model, forecast_purchase, forecast_redeem)
        
        # 6. åˆ›å»ºä¼˜åŒ–ç‰ˆå¯è§†åŒ–
        create_optimized_visualization(purchase_df, redeem_df, forecast_purchase, forecast_redeem, predictions)
        
        # 7. åˆ†æä¼˜åŒ–ç‰ˆæ¨¡å‹æ€§èƒ½
        performance = analyze_optimized_model_performance(forecast_purchase, forecast_redeem, purchase_df, redeem_df)
        
        # 8. ä¿å­˜è¯¦ç»†ç»“æœ
        save_detailed_results(predictions, performance)
        
        print(f"\n=== ä¼˜åŒ–ç‰ˆé¢„æµ‹å®Œæˆ ===")
        print(f"âœ… ç»¼åˆä¼˜åŒ–Prophetæ¨¡å‹è®­ç»ƒæˆåŠŸ")
        print(f"ğŸ“Š é¢„æµ‹ç»“æœå·²ä¿å­˜")
        print(f"ğŸ“ˆ å¯æŸ¥çœ‹æ–‡ä»¶:")
        print(f"   - ä¼˜åŒ–ç‰ˆé¢„æµ‹ç»“æœ: prediction_result/prophet_v3_predictions_201409.csv")
        print(f"   - ä¼˜åŒ–ç‰ˆåˆ†æå›¾è¡¨: user_data/optimized_prophet_forecast_analysis.png")
        print(f"   - è¯¦ç»†é¢„æµ‹æ•°æ®: user_data/prophet_v3_detailed_201409.csv")
        print(f"   - æ€§èƒ½æŒ‡æ ‡: user_data/prophet_v3_performance.csv")
        print(f"   - è®­ç»ƒå¥½çš„æ¨¡å‹: model/purchase_prophet_v3_model.pkl")
        print(f"                 model/redeem_prophet_v3_model.pkl")
        
        return True
        
    except Exception as e:
        print(f"ä¼˜åŒ–ç‰ˆé¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    main()
