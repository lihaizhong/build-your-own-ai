# 快速开始指南

## 环境激活

### 激活虚拟环境

```bash
cd /Users/lihaizhong/Documents/Project/build-your-own-x/build-your-own-ai/practice/CASE-三国演义Embedding
source .venv/bin/activate
```

### 验证环境

```bash
# 检查 Python 版本
python --version  # 应该显示 Python 3.11.13

# 运行环境测试
python code/test_environment.py
```

## 基础使用

### 1. 文本 Embedding

```python
from sentence_transformers import SentenceTransformer

# 加载预训练模型（支持中文）
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# 生成文本 Embedding
text = "三国演义是中国古典四大名著之一"
embedding = model.encode(text)

print(f"向量维度: {embedding.shape}")  # (384,)
```

### 2. 中文分词

```python
import jieba

text = "三国演义是中国古典四大名著之一"
words = jieba.lcut(text)

print(f"分词结果: {words}")
# 输出: ['三国演义', '是', '中国', '古典', '四大名著', '之一']
```

### 3. 向量检索

```python
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

# 加载模型
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# 准备文本数据
texts = [
    "三国演义是中国古典四大名著之一",
    "诸葛亮是三国时期蜀汉的丞相",
    "曹操是三国时期魏国的奠基人",
    "关羽是三国时期蜀汉的名将"
]

# 生成 Embedding
embeddings = model.encode(texts)

# 创建 FAISS 索引
dimension = embeddings.shape[1]  # 384
index = faiss.IndexFlatL2(dimension)
index.add(embeddings.astype('float32'))

# 搜索相似文本
query = "谁是中国古代的著名军事家？"
query_embedding = model.encode([query])

k = 2  # 返回最相似的 2 个结果
distances, indices = index.search(query_embedding.astype('float32'), k)

print(f"查询: {query}")
for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
    print(f"排名 {i+1}: {texts[idx]} (距离: {dist:.4f})")
```

### 4. 批量处理

```python
import pandas as pd
from sentence_transformers import SentenceTransformer

# 加载模型
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# 读取数据
df = pd.read_csv('data/sanguoyanyi.csv')

# 批量生成 Embedding
texts = df['text'].tolist()
embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)

# 保存结果
df['embedding'] = embeddings.tolist()
df.to_csv('user_data/embeddings.csv', index=False)
```

## 常用命令

### 安装新依赖

```bash
# 添加依赖
uv add 包名

# 同步依赖
uv sync
```

### 运行脚本

```bash
# 使用虚拟环境运行
python code/your_script.py

# 或使用 uv run
uv run python code/your_script.py
```

### Jupyter Notebook

```bash
# 启动 Jupyter Notebook
jupyter notebook

# 或使用 JupyterLab
jupyter lab
```

## 推荐的 Embedding 模型

### 中文支持模型

1. **paraphrase-multilingual-MiniLM-L12-v2** (推荐)
   - 维度: 384
   - 速度: 快
   - 语言: 多语言（包括中文）
   - 适用: 通用文本相似度

2. **shibing624/text2vec-base-chinese**
   - 维度: 768
   - 速度: 中等
   - 语言: 中文优化
   - 适用: 中文文本相似度

3. **sentence-transformers/paraphrase-multilingual-mpnet-base-v2**
   - 维度: 768
   - 速度: 慢
   - 语言: 多语言（包括中文）
   - 适用: 高精度需求

### 加载自定义模型

```python
from sentence_transformers import SentenceTransformer

# 从 Hugging Face 加载
model = SentenceTransformer('shibing624/text2vec-base-chinese')

# 从本地加载
model = SentenceTransformer('path/to/local/model')
```

## 常见问题

### Q: 如何处理大量文本？

A: 使用批量处理和进度条：

```python
embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)
```

### Q: 如何保存和加载 Embedding？

A: 使用 numpy 或 pandas：

```python
import numpy as np
import pandas as pd

# 保存
np.save('user_data/embeddings.npy', embeddings)

# 加载
embeddings = np.load('user_data/embeddings.npy')
```

### Q: 如何优化 FAISS 搜索性能？

A: 使用更高效的索引：

```python
# 使用 IVF 索引（适合大规模数据）
quantizer = faiss.IndexFlatL2(dimension)
index = faiss.IndexIVFFlat(quantizer, dimension, 100)
index.train(embeddings.astype('float32'))
index.add(embeddings.astype('float32'))
```

## 下一步

1. 准备三国演义文本数据
2. 实现完整的 Embedding 流程
3. 构建向量检索系统
4. 添加可视化分析
5. 实现问答系统

---

*最后更新: 2026年1月19日*