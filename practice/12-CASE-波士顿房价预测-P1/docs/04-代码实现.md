# 波士顿房价预测系统 - 代码实现详解

## 核心代码结构

### 1. 项目路径管理模块

```python
import os
from pathlib import Path

def get_project_path(*paths: str) -> str:
    """获取项目路径的统一方法"""
    try:
        current_dir = Path(__file__).parent
        project_dir = current_dir.parent
        return project_dir.joinpath(*paths)
    except NameError:
        return Path.cwd().joinpath(*paths)
```

**功能特点：**
- **统一路径管理**: 提供项目路径的标准化获取方法
- **容错处理**: 处理不同运行环境下的路径差异
- **灵活扩展**: 支持任意层级的路径构建

## 数据预处理模块详解

### 1. 数据加载实现

```python
# data_preprocessing.py

import pandas as pd
import numpy as np

def load_boston_data():
    """
    加载波士顿房价数据集
    
    Returns:
        pd.DataFrame: 包含特征和目标变量的数据框
    """
    data_path = get_project_path('data', 'housing.csv')
    df = pd.read_csv(data_path)
    
    print(f"数据加载成功，形状: {df.shape}")
    print(f"列名: {df.columns.tolist()}")
    
    return df
```

**技术要点：**
- **自动路径处理**: 使用相对路径自动定位数据文件
- **数据验证**: 加载后立即验证数据形状和列名
- **错误提示**: 提供清晰的加载状态反馈

### 2. 数据质量检查

```python
def check_data_quality(df):
    """
    检查数据质量
    
    Args:
        df (pd.DataFrame): 输入数据框
        
    Returns:
        dict: 数据质量报告
    """
    report = {
        'shape': df.shape,
        'columns': df.columns.tolist(),
        'missing_values': df.isnull().sum().to_dict(),
        'missing_percentage': (df.isnull().sum() / len(df) * 100).to_dict(),
        'duplicates': df.duplicated().sum(),
        'dtypes': df.dtypes.to_dict(),
        'statistics': df.describe().to_dict()
    }
    
    # 打印质量报告摘要
    print("=" * 60)
    print("数据质量报告")
    print("=" * 60)
    print(f"数据形状: {report['shape']}")
    print(f"缺失值总数: {sum(report['missing_values'].values())}")
    print(f"重复行数: {report['duplicates']}")
    
    return report
```

**检查内容：**
- **数据形状**: 行数和列数
- **缺失值**: 各列缺失值数量和比例
- **重复值**: 重复行数量
- **数据类型**: 各列数据类型
- **基本统计**: 均值、标准差、最值等

### 3. 缺失值处理

```python
def handle_missing_values(df, strategy='mean'):
    """
    处理缺失值
    
    Args:
        df (pd.DataFrame): 输入数据框
        strategy (str): 处理策略 ('mean', 'median', 'mode', 'drop')
        
    Returns:
        pd.DataFrame: 处理后的数据框
    """
    df_processed = df.copy()
    
    # 获取数值列
    numeric_cols = df_processed.select_dtypes(include=[np.number]).columns
    
    for col in numeric_cols:
        if df_processed[col].isnull().sum() > 0:
            if strategy == 'mean':
                df_processed[col].fillna(df_processed[col].mean(), inplace=True)
            elif strategy == 'median':
                df_processed[col].fillna(df_processed[col].median(), inplace=True)
            elif strategy == 'mode':
                df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)
    
    if strategy == 'drop':
        df_processed = df_processed.dropna()
    
    print(f"缺失值处理完成，策略: {strategy}")
    print(f"处理后缺失值: {df_processed.isnull().sum().sum()}")
    
    return df_processed
```

**处理策略：**
- **mean**: 使用均值填充
- **median**: 使用中位数填充
- **mode**: 使用众数填充
- **drop**: 直接删除缺失值

### 4. 异常值检测

```python
def detect_outliers(df, method='iqr'):
    """
    检测异常值
    
    Args:
        df (pd.DataFrame): 输入数据框
        method (str): 异常值检测方法 ('iqr', 'zscore')
        
    Returns:
        dict: 异常值信息
    """
    outliers_info = {}
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    for col in numeric_cols:
        if method == 'iqr':
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]
            
        elif method == 'zscore':
            from scipy import stats
            z_scores = np.abs(stats.zscore(df[col]))
            outliers = df[col][z_scores > 3]
        
        outliers_info[col] = {
            'count': len(outliers),
            'percentage': len(outliers) / len(df) * 100,
            'values': outliers.tolist() if len(outliers) < 10 else 'Too many to display'
        }
    
    return outliers_info
```

**检测方法：**
- **IQR方法**: 基于四分位距检测异常值
- **Z-score方法**: 基于标准差检测异常值

## 特征工程模块详解

### 1. 多项式特征创建

```python
# feature_engineering.py

from sklearn.preprocessing import PolynomialFeatures

def create_polynomial_features(X, degree=2):
    """
    创建多项式特征
    
    Args:
        X (pd.DataFrame): 原始特征
        degree (int): 多项式度数
        
    Returns:
        pd.DataFrame: 包含多项式特征的数据框
    """
    poly = PolynomialFeatures(degree=degree, include_bias=False)
    X_poly = poly.fit_transform(X)
    
    # 生成特征名称
    feature_names = poly.get_feature_names_out(X.columns)
    
    df_poly = pd.DataFrame(X_poly, columns=feature_names)
    
    print(f"多项式特征创建完成:")
    print(f"  原始特征数: {X.shape[1]}")
    print(f"  多项式特征数: {df_poly.shape[1]}")
    
    return df_poly, poly
```

**特征扩展：**
- **二次项**: x², y², z²...
- **交叉项**: xy, xz, yz...
- **高次项**: 支持任意次数

### 2. 特征相关性分析

```python
def feature_correlation_analysis(df, target_col='MEDV'):
    """
    特征相关性分析
    
    Args:
        df (pd.DataFrame): 输入数据框
        target_col (str): 目标变量列名
        
    Returns:
        pd.DataFrame: 相关性矩阵
    """
    # 计算相关性矩阵
    corr_matrix = df.corr()
    
    # 与目标变量的相关性排序
    target_corr = corr_matrix[target_col].drop(target_col).sort_values(
        key=abs, ascending=False
    )
    
    print("与目标变量的相关性（按绝对值排序）:")
    print(target_corr)
    
    return corr_matrix, target_corr
```

**分析输出：**
- **完整相关性矩阵**: 所有特征间的相关性
- **目标相关性排序**: 与房价最相关的特征

### 3. 特征选择

```python
from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression

def select_features_univariate(X, y, k=10, method='f_regression'):
    """
    单变量特征选择
    
    Args:
        X (pd.DataFrame): 特征数据
        y (pd.Series): 目标变量
        k (int): 选择特征数量
        method (str): 选择方法 ('f_regression', 'mutual_info')
        
    Returns:
        pd.DataFrame: 选择的特征
    """
    if method == 'f_regression':
        selector = SelectKBest(score_func=f_regression, k=k)
    elif method == 'mutual_info':
        selector = SelectKBest(score_func=mutual_info_regression, k=k)
    
    X_selected = selector.fit_transform(X, y)
    
    # 获取选择的特征名
    selected_features = X.columns[selector.get_support()].tolist()
    
    # 获取特征得分
    scores = pd.DataFrame({
        'feature': X.columns,
        'score': selector.scores_
    }).sort_values('score', ascending=False)
    
    print(f"选择的 {k} 个特征: {selected_features}")
    
    return pd.DataFrame(X_selected, columns=selected_features), selected_features, scores
```

**选择方法：**
- **f_regression**: F检验回归
- **mutual_info**: 互信息回归

### 4. 特征标准化

```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler

def scale_features(X, method='standard'):
    """
    特征标准化
    
    Args:
        X (pd.DataFrame): 原始特征
        method (str): 标准化方法 ('standard', 'robust', 'minmax')
        
    Returns:
        pd.DataFrame: 标准化后的特征
    """
    scalers = {
        'standard': StandardScaler(),
        'minmax': MinMaxScaler(),
        'robust': RobustScaler()
    }
    
    scaler = scalers[method]
    X_scaled = scaler.fit_transform(X)
    
    df_scaled = pd.DataFrame(X_scaled, columns=X.columns)
    
    print(f"特征标准化完成，方法: {method}")
    
    return df_scaled, scaler
```

**标准化方法：**
- **standard**: 均值0，标准差1
- **minmax**: 缩放到[0, 1]范围
- **robust**: 基于中位数，对异常值鲁棒

## ModelTrainer类核心实现

### 1. 类初始化

```python
# model_training.py

from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split, cross_val_score
import joblib

class ModelTrainer:
    """模型训练器类"""
    
    def __init__(self):
        self.models = {}
        self.best_model = None
        self.best_model_name = None
        self.model_scores = {}
        self.scaler = None
```

### 2. 模型初始化

```python
def initialize_models(self):
    """初始化各种机器学习模型"""
    # 线性模型
    self.models['linear_regression'] = LinearRegression()
    self.models['ridge'] = Ridge(alpha=1.0, random_state=42)
    self.models['lasso'] = Lasso(alpha=1.0, random_state=42)
    
    # 集成学习模型
    self.models['random_forest'] = RandomForestRegressor(
        n_estimators=100, 
        random_state=42,
        n_jobs=-1
    )
    self.models['gradient_boosting'] = GradientBoostingRegressor(
        n_estimators=100, 
        learning_rate=0.1,
        max_depth=3,
        random_state=42
    )
    
    # 支持向量机
    self.models['svr'] = SVR(kernel='rbf', C=1.0, epsilon=0.1)
    
    # 神经网络
    self.models['neural_network'] = MLPRegressor(
        hidden_layer_sizes=(100, 50),
        activation='relu',
        solver='adam',
        max_iter=1000,
        random_state=42
    )
    
    print(f"已初始化 {len(self.models)} 个模型:")
    for name in self.models:
        print(f"  - {name}: {self.models[name].__class__.__name__}")
```

### 3. 模型训练

```python
def train_all_models(self, X_train, y_train):
    """训练所有模型"""
    print("=" * 60)
    print("开始训练所有模型")
    print("=" * 60)
    
    for name, model in self.models.items():
        print(f"\n训练模型: {name}")
        model.fit(X_train, y_train)
        print(f"  ✓ {name} 训练完成")
    
    print("\n所有模型训练完成！")

def train_single_model(self, model, X_train, y_train, model_name):
    """
    训练单个模型
    
    Args:
        model: 机器学习模型
        X_train: 训练特征
        y_train: 训练目标
        model_name: 模型名称
    """
    print(f"训练模型: {model_name}")
    model.fit(X_train, y_train)
    print(f"  ✓ {model_name} 训练完成")
    return model
```

### 4. 交叉验证

```python
def cross_validation(self, model, X, y, cv=5):
    """
    交叉验证
    
    Args:
        model: 机器学习模型
        X: 特征数据
        y: 目标数据
        cv: 交叉验证折数
        
    Returns:
        dict: 交叉验证结果
    """
    # 使用负MSE作为评分
    scores = cross_val_score(
        model, X, y, 
        cv=cv, 
        scoring='neg_mean_squared_error',
        n_jobs=-1
    )
    
    # 转换为RMSE
    rmse_scores = np.sqrt(-scores)
    
    results = {
        'mean_rmse': rmse_scores.mean(),
        'std_rmse': rmse_scores.std(),
        'all_scores': rmse_scores
    }
    
    print(f"交叉验证结果 (RMSE):")
    print(f"  均值: {results['mean_rmse']:.4f}")
    print(f"  标准差: {results['std_rmse']:.4f}")
    
    return results
```

### 5. 模型评估

```python
def evaluate_models(self, X_test, y_test):
    """
    评估所有模型
    
    Args:
        X_test: 测试特征
        y_test: 测试目标
        
    Returns:
        dict: 模型评估结果
    """
    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
    
    print("=" * 60)
    print("模型评估结果")
    print("=" * 60)
    
    for name, model in self.models.items():
        y_pred = model.predict(X_test)
        
        metrics = {
            'MAE': mean_absolute_error(y_test, y_pred),
            'MSE': mean_squared_error(y_test, y_pred),
            'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),
            'R2': r2_score(y_test, y_pred)
        }
        
        self.model_scores[name] = metrics
        
        print(f"\n{name}:")
        print(f"  MAE:  {metrics['MAE']:.4f}")
        print(f"  RMSE: {metrics['RMSE']:.4f}")
        print(f"  R²:   {metrics['R2']:.4f}")
    
    return self.model_scores
```

### 6. 最佳模型选择

```python
def select_best_model(self, metric='RMSE'):
    """选择最佳模型"""
    if not self.model_scores:
        print("请先评估模型！")
        return None
    
    # 根据指标选择最佳模型
    if metric in ['MAE', 'MSE', 'RMSE']:
        # 越小越好
        best_name = min(self.model_scores, key=lambda x: self.model_scores[x][metric])
    else:
        # 越大越好（如R²）
        best_name = max(self.model_scores, key=lambda x: self.model_scores[x][metric])
    
    self.best_model_name = best_name
    self.best_model = self.models[best_name]
    
    print("=" * 60)
    print(f"最佳模型: {best_name}")
    print("=" * 60)
    print(f"选择指标: {metric}")
    print(f"指标值: {self.model_scores[best_name][metric]:.4f}")
    
    return self.best_model
```

### 7. 模型保存与加载

```python
def save_models(self, save_dir='model/'):
    """
    保存训练好的模型
    
    Args:
        save_dir: 模型保存目录
    """
    import os
    os.makedirs(save_dir, exist_ok=True)
    
    # 保存所有模型
    for name, model in self.models.items():
        filepath = os.path.join(save_dir, f'{name}.pkl')
        joblib.dump(model, filepath)
        print(f"保存模型: {filepath}")
    
    # 保存最佳模型
    if self.best_model:
        joblib.dump(self.best_model, os.path.join(save_dir, 'best_model.pkl'))
        joblib.dump(self.best_model_name, os.path.join(save_dir, 'best_model_name.pkl'))
        print(f"保存最佳模型: {self.best_model_name}")
    
    # 保存标准化器
    if self.scaler:
        joblib.dump(self.scaler, os.path.join(save_dir, 'standard_scaler.pkl'))
        print("保存标准化器")
    
    print("\n所有模型保存完成！")

def load_models(self, load_dir='model/'):
    """
    加载训练好的模型
    
    Args:
        load_dir: 模型加载目录
    """
    import os
    
    # 加载所有模型
    model_names = ['linear_regression', 'ridge', 'lasso', 'random_forest', 
                   'gradient_boosting', 'svr', 'neural_network']
    
    for name in model_names:
        filepath = os.path.join(load_dir, f'{name}.pkl')
        if os.path.exists(filepath):
            self.models[name] = joblib.load(filepath)
            print(f"加载模型: {name}")
    
    # 加载最佳模型
    best_model_path = os.path.join(load_dir, 'best_model.pkl')
    if os.path.exists(best_model_path):
        self.best_model = joblib.load(best_model_path)
        self.best_model_name = joblib.load(
            os.path.join(load_dir, 'best_model_name.pkl')
        )
        print(f"加载最佳模型: {self.best_model_name}")
    
    # 加载标准化器
    scaler_path = os.path.join(load_dir, 'standard_scaler.pkl')
    if os.path.exists(scaler_path):
        self.scaler = joblib.load(scaler_path)
        print("加载标准化器")
```

## ModelEvaluator类详解

### 1. 类初始化

```python
# model_evaluation.py

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import (
    mean_absolute_error, 
    mean_squared_error, 
    r2_score, 
    explained_variance_score
)

class ModelEvaluator:
    """模型评估器类"""
    
    def __init__(self):
        self.evaluation_results = {}
```

### 2. 指标计算

```python
def calculate_metrics(self, y_true, y_pred, model_name):
    """
    计算评估指标
    
    Args:
        y_true: 真实值
        y_pred: 预测值
        model_name: 模型名称
        
    Returns:
        dict: 评估指标
    """
    metrics = {
        'MAE': mean_absolute_error(y_true, y_pred),
        'MSE': mean_squared_error(y_true, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'R2': r2_score(y_true, y_pred),
        'Explained_Variance': explained_variance_score(y_true, y_pred)
    }
    
    self.evaluation_results[model_name] = metrics
    return metrics
```

### 3. 可视化方法

```python
def plot_predictions_vs_actual(self, y_true, y_pred, model_name, save_path=None):
    """绘制预测值vs实际值散点图"""
    plt.figure(figsize=(10, 8))
    plt.scatter(y_true, y_pred, alpha=0.6)
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
    plt.xlabel('实际房价', fontsize=12)
    plt.ylabel('预测房价', fontsize=12)
    plt.title(f'{model_name} - 预测值 vs 实际值', fontsize=14)
    plt.grid(True, alpha=0.3)
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()

def plot_residuals(self, y_true, y_pred, model_name, save_path=None):
    """绘制残差图"""
    residuals = y_true - y_pred
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # 残差散点图
    axes[0].scatter(y_pred, residuals, alpha=0.6)
    axes[0].axhline(y=0, color='r', linestyle='--')
    axes[0].set_xlabel('预测值', fontsize=12)
    axes[0].set_ylabel('残差', fontsize=12)
    axes[0].set_title(f'{model_name} - 残差散点图', fontsize=14)
    axes[0].grid(True, alpha=0.3)
    
    # 残差直方图
    axes[1].hist(residuals, bins=30, alpha=0.7, edgecolor='black')
    axes[1].set_xlabel('残差', fontsize=12)
    axes[1].set_ylabel('频次', fontsize=12)
    axes[1].set_title(f'{model_name} - 残差分布', fontsize=14)
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()
```

### 4. 模型对比

```python
def compare_models(self, save_path=None):
    """对比所有模型的性能"""
    if not self.evaluation_results:
        print("没有评估结果可比较")
        return None
    
    df_results = pd.DataFrame(self.evaluation_results).T
    
    # 创建对比图表
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # MAE对比
    axes[0, 0].bar(df_results.index, df_results['MAE'], color='steelblue')
    axes[0, 0].set_title('平均绝对误差 (MAE)', fontsize=14)
    axes[0, 0].set_ylabel('MAE', fontsize=12)
    axes[0, 0].tick_params(axis='x', rotation=45)
    
    # RMSE对比
    axes[0, 1].bar(df_results.index, df_results['RMSE'], color='coral')
    axes[0, 1].set_title('均方根误差 (RMSE)', fontsize=14)
    axes[0, 1].set_ylabel('RMSE', fontsize=12)
    axes[0, 1].tick_params(axis='x', rotation=45)
    
    # R²对比
    axes[1, 0].bar(df_results.index, df_results['R2'], color='seagreen')
    axes[1, 0].set_title('决定系数 (R²)', fontsize=14)
    axes[1, 0].set_ylabel('R²', fontsize=12)
    axes[1, 0].tick_params(axis='x', rotation=45)
    
    # 解释方差对比
    axes[1, 1].bar(df_results.index, df_results['Explained_Variance'], color='mediumpurple')
    axes[1, 1].set_title('解释方差', fontsize=14)
    axes[1, 1].set_ylabel('Explained Variance', fontsize=12)
    axes[1, 1].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    return df_results
```

## HousePricePredictor类详解

### 1. 类初始化

```python
# prediction.py

import pandas as pd
import numpy as np
import joblib

class HousePricePredictor:
    """房价预测器类"""
    
    def __init__(self, model_dir='model/'):
        """
        初始化预测器
        
        Args:
            model_dir: 模型文件目录
        """
        self.model_dir = model_dir
        self.models = {}
        self.scalers = {}
        self.best_model_name = None
```

### 2. 模型加载

```python
def load_models(self):
    """加载所有训练好的模型"""
    model_files = {
        'linear_regression': 'linear_regression.pkl',
        'ridge': 'ridge.pkl',
        'lasso': 'lasso.pkl',
        'random_forest': 'random_forest.pkl',
        'gradient_boosting': 'gradient_boosting.pkl',
        'svr': 'svr.pkl',
        'neural_network': 'neural_network.pkl'
    }
    
    for model_name, filename in model_files.items():
        try:
            filepath = f"{self.model_dir}{filename}"
            self.models[model_name] = joblib.load(filepath)
            print(f"成功加载模型: {model_name}")
        except FileNotFoundError:
            print(f"模型文件不存在: {filename}")

def load_best_model(self):
    """加载最佳模型"""
    try:
        self.best_model_name = joblib.load(f"{self.model_dir}best_model_name.pkl")
        self.models['best'] = joblib.load(f"{self.model_dir}best_model.pkl")
        print(f"成功加载最佳模型: {self.best_model_name}")
    except FileNotFoundError:
        print("最佳模型文件不存在")
```

### 3. 预测方法

```python
def predict_single(self, features, model_name=None, use_best=True):
    """
    单个样本预测
    
    Args:
        features: 特征数组 (1D array)
        model_name: 指定模型名称
        use_best: 是否使用最佳模型
        
    Returns:
        float: 预测的房价
    """
    # 转换为2D数组
    if features.ndim == 1:
        features = features.reshape(1, -1)
    
    # 选择模型
    if model_name:
        model = self.models[model_name]
    elif use_best and 'best' in self.models:
        model = self.models['best']
    else:
        raise ValueError("没有可用的模型进行预测")
    
    # 预处理和预测
    features_processed = self.preprocess_input(features)
    prediction = model.predict(features_processed)[0]
    
    return prediction

def predict_batch(self, X, model_name=None, use_best=True):
    """
    批量预测
    
    Args:
        X: 特征数据 (2D array 或 DataFrame)
        model_name: 指定模型名称
        use_best: 是否使用最佳模型
        
    Returns:
        np.array: 预测结果数组
    """
    # 选择模型
    if model_name:
        model = self.models[model_name]
    elif use_best and 'best' in self.models:
        model = self.models['best']
    else:
        raise ValueError("没有可用的模型进行预测")
    
    # 预处理和预测
    features_processed = self.preprocess_input(X)
    predictions = model.predict(features_processed)
    
    return predictions
```

---

*最后更新: 2026年2月15日*
*代码实现版本: v1.0*
*开发团队: AI系统开发组*
