# 波士顿房价预测系统 - 使用指南

## 环境准备

### 1. 系统要求
- **操作系统**: Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **Python版本**: 3.11+
- **内存**: 最小4GB，推荐8GB+
- **存储空间**: 最小1GB，推荐2GB+

### 2. 依赖安装

#### 方式一：使用uv（推荐）
```bash
# 进入项目目录
cd practice/12-CASE-波士顿房价预测-P1

# 创建虚拟环境
uv venv --python 3.11

# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# 或
.venv\Scripts\activate     # Windows

# 安装依赖
uv sync

# 运行模型训练
uv run python code/model_training.py
```

#### 方式二：使用pip
```bash
# 创建虚拟环境
python -m venv .venv

# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# 或
.venv\Scripts\activate     # Windows

# 安装依赖
pip install numpy pandas scikit-learn matplotlib joblib

# 运行模型训练
python code/model_training.py
```

## 快速开始

### 1. 完整训练流程

#### 步骤1：数据预处理
```bash
# 进入项目目录
cd practice/12-CASE-波士顿房价预测-P1

# 激活虚拟环境
source .venv/bin/activate

# 运行数据预处理
uv run python code/data_preprocessing.py
```

#### 步骤2：特征工程
```bash
# 运行特征工程
uv run python code/feature_engineering.py
```

#### 步骤3：模型训练
```bash
# 运行模型训练
uv run python code/model_training.py
```

#### 步骤4：模型评估
```bash
# 运行模型评估
uv run python code/model_evaluation.py
```

#### 步骤5：房价预测
```bash
# 运行预测
uv run python code/prediction.py
```

### 2. 预期输出

#### 数据预处理输出
```
================================================================================
波士顿房价数据预处理
================================================================================

加载数据...
数据形状: (506, 14)

数据质量检查:
  - 缺失值: 0
  - 重复值: 0
  - 数据类型: 全部为数值型

特征统计:
       CRIM      ZN   INDUS    CHAS     NOX     RM    AGE    DIS    RAD    TAX  PTRATIO      B   LSTAT   MEDV
count  506.0   506.0   506.0   506.0   506.0   506.0  506.0  506.0  506.0  506.0    506.0  506.0   506.0  506.0
mean     3.6    11.4    11.1     0.1     0.6     6.3   68.6    3.8    9.5  408.2     18.5  356.7    12.7   22.5
std      8.6    23.3     6.9     0.3     0.1     0.7   28.1    2.1    8.7  168.5      2.2   91.3     7.1    9.2

数据预处理完成！
```

#### 模型训练输出
```
================================================================================
模型训练
================================================================================

初始化模型...
  - linear_regression: LinearRegression
  - ridge: Ridge
  - lasso: Lasso
  - random_forest: RandomForestRegressor
  - gradient_boosting: GradientBoostingRegressor
  - svr: SVR
  - neural_network: MLPRegressor

训练模型...

模型评估结果:
  linear_regression:
    MAE: 3.1891
    RMSE: 4.6872
    R²: 0.7112

  ridge:
    MAE: 3.1845
    RMSE: 4.6756
    R²: 0.7128

  random_forest:
    MAE: 2.4521
    RMSE: 3.4562
    R²: 0.8456

  gradient_boosting:
    MAE: 2.3145
    RMSE: 3.2345
    R²: 0.8678

最佳模型: gradient_boosting
模型已保存到: model/best_model.pkl
```

#### 预测输出
```
================================================================================
房价预测
================================================================================

加载模型...
成功加载最佳模型: gradient_boosting

示例输入特征:
  CRIM: 0.00632
  ZN: 18.0
  INDUS: 2.31
  CHAS: 0.0
  NOX: 0.538
  RM: 6.575
  AGE: 65.2
  DIS: 4.0900
  RAD: 1.0
  TAX: 296.0
  PTRATIO: 15.3
  B: 396.90
  LSTAT: 4.98

预测房价: $24.52k
```

## 交互式使用

### 1. 数据加载和探索

#### 加载数据
```python
import pandas as pd
import numpy as np

# 加载波士顿房价数据
df = pd.read_csv('data/housing.csv')

# 查看数据基本信息
print(df.info())
print(df.describe())

# 查看前几行数据
print(df.head())
```

#### 数据探索
```python
import matplotlib.pyplot as plt
import seaborn as sns

# 特征分布
df.hist(figsize=(15, 10))
plt.tight_layout()
plt.show()

# 相关性热力图
plt.figure(figsize=(12, 10))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('特征相关性矩阵')
plt.show()

# 目标变量分布
plt.figure(figsize=(8, 6))
sns.histplot(df['MEDV'], bins=30, kde=True)
plt.title('房价分布')
plt.xlabel('房价（千美元）')
plt.show()
```

### 2. 特征工程

#### 创建多项式特征
```python
from sklearn.preprocessing import PolynomialFeatures

# 选择重要特征
important_features = ['RM', 'LSTAT', 'PTRATIO']
X_selected = df[important_features]

# 创建二次多项式特征
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X_selected)

print(f"原始特征数: {X_selected.shape[1]}")
print(f"多项式特征数: {X_poly.shape[1]}")
```

#### 特征选择
```python
from sklearn.feature_selection import SelectKBest, f_regression

# 选择最佳特征
X = df.drop('MEDV', axis=1)
y = df['MEDV']

selector = SelectKBest(score_func=f_regression, k=5)
X_selected = selector.fit_transform(X, y)

# 查看选择的特征
selected_features = X.columns[selector.get_support()].tolist()
print(f"选择的特征: {selected_features}")
```

### 3. 模型训练

#### 单模型训练
```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor

# 数据分割
X = df.drop('MEDV', axis=1)
y = df['MEDV']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 训练梯度提升模型
model = GradientBoostingRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    random_state=42
)
model.fit(X_train, y_train)

# 预测
y_pred = model.predict(X_test)
```

#### 交叉验证
```python
from sklearn.model_selection import cross_val_score

# 5折交叉验证
cv_scores = cross_val_score(
    model, X, y, cv=5, scoring='neg_mean_squared_error'
)

# 计算RMSE
rmse_scores = np.sqrt(-cv_scores)
print(f"交叉验证RMSE: {rmse_scores.mean():.4f} (+/- {rmse_scores.std():.4f})")
```

### 4. 模型评估

#### 计算评估指标
```python
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# 计算指标
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"MAE: {mae:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"R²: {r2:.4f}")
```

#### 可视化评估
```python
# 预测值vs实际值
plt.figure(figsize=(10, 8))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('实际房价')
plt.ylabel('预测房价')
plt.title('预测值 vs 实际值')
plt.grid(True, alpha=0.3)
plt.show()

# 残差图
residuals = y_test - y_pred
plt.figure(figsize=(10, 6))
plt.scatter(y_pred, residuals, alpha=0.6)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('预测值')
plt.ylabel('残差')
plt.title('残差分布图')
plt.grid(True, alpha=0.3)
plt.show()
```

### 5. 房价预测

#### 单样本预测
```python
import joblib

# 加载训练好的模型
model = joblib.load('model/best_model.pkl')
scaler = joblib.load('model/standard_scaler.pkl')

# 创建样本输入
sample_features = np.array([
    0.00632,  # CRIM
    18.0,     # ZN
    2.31,     # INDUS
    0.0,      # CHAS
    0.538,    # NOX
    6.575,    # RM
    65.2,     # AGE
    4.0900,   # DIS
    1.0,      # RAD
    296.0,    # TAX
    15.3,     # PTRATIO
    396.90,   # B
    4.98      # LSTAT
]).reshape(1, -1)

# 标准化
sample_scaled = scaler.transform(sample_features)

# 预测
predicted_price = model.predict(sample_scaled)[0]
print(f"预测房价: ${predicted_price*1000:.2f}")
```

#### 批量预测
```python
# 批量预测
new_data = pd.DataFrame({
    'CRIM': [0.1, 0.5, 1.0],
    'ZN': [20, 0, 12],
    'INDUS': [5, 10, 8],
    'CHAS': [0, 0, 1],
    'NOX': [0.5, 0.6, 0.5],
    'RM': [6, 5, 7],
    'AGE': [30, 80, 40],
    'DIS': [5, 2, 4],
    'RAD': [1, 5, 3],
    'TAX': [300, 400, 350],
    'PTRATIO': [15, 20, 18],
    'B': [390, 380, 395],
    'LSTAT': [5, 15, 8]
})

# 标准化
new_data_scaled = scaler.transform(new_data)

# 预测
predictions = model.predict(new_data_scaled)
for i, pred in enumerate(predictions):
    print(f"样本{i+1} 预测房价: ${pred*1000:.2f}")
```

## 常见问题解决

### 1. 数据加载问题

#### 问题现象
```
FileNotFoundError: housing.csv not found
```

#### 解决方案
```python
import os

# 检查当前工作目录
print(f"当前目录: {os.getcwd()}")

# 使用绝对路径
data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'housing.csv')
df = pd.read_csv(data_path)
```

### 2. 内存不足问题

#### 问题现象
```
MemoryError: Unable to allocate array
```

#### 解决方案
```python
# 减少数据精度
df = df.astype('float32')

# 分批处理大数据
def process_in_batches(df, batch_size=100):
    results = []
    for i in range(0, len(df), batch_size):
        batch = df.iloc[i:i+batch_size]
        result = process_batch(batch)
        results.append(result)
    return pd.concat(results)
```

### 3. 模型过拟合

#### 问题现象
```
训练集R²很高，测试集R²很低
```

#### 解决方案
```python
# 1. 使用正则化
from sklearn.linear_model import Ridge
ridge_model = Ridge(alpha=10.0)

# 2. 减少树深度
from sklearn.ensemble import RandomForestRegressor
rf_model = RandomForestRegressor(max_depth=5)

# 3. 增加最小样本数
rf_model = RandomForestRegressor(min_samples_split=10, min_samples_leaf=5)
```

### 4. 特征缩放问题

#### 问题现象
```
某些特征对模型影响过大
```

#### 解决方案
```python
from sklearn.preprocessing import StandardScaler

# 标准化所有特征
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 保存scaler用于预测
joblib.dump(scaler, 'model/scaler.pkl')
```

## 性能调优

### 1. 超参数调优

#### GridSearchCV
```python
from sklearn.model_selection import GridSearchCV

# 定义参数网格
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2]
}

# 网格搜索
grid_search = GridSearchCV(
    GradientBoostingRegressor(random_state=42),
    param_grid,
    cv=5,
    scoring='neg_mean_squared_error',
    n_jobs=-1
)
grid_search.fit(X_train, y_train)

print(f"最佳参数: {grid_search.best_params_}")
print(f"最佳分数: {np.sqrt(-grid_search.best_score_):.4f}")
```

#### RandomizedSearchCV
```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# 定义参数分布
param_distributions = {
    'n_estimators': randint(50, 300),
    'max_depth': randint(3, 10),
    'learning_rate': uniform(0.01, 0.3)
}

# 随机搜索
random_search = RandomizedSearchCV(
    GradientBoostingRegressor(random_state=42),
    param_distributions,
    n_iter=50,
    cv=5,
    scoring='neg_mean_squared_error',
    n_jobs=-1,
    random_state=42
)
random_search.fit(X_train, y_train)
```

### 2. 特征工程优化

```python
# 特征重要性分析
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print(feature_importance)

# 选择重要特征
top_features = feature_importance.head(5)['feature'].tolist()
X_selected = X[top_features]
```

## 监控和调试

### 1. 模型性能监控

```python
import time

def monitor_prediction(model, X, n_predictions=100):
    """监控预测性能"""
    start_time = time.time()
    
    for _ in range(n_predictions):
        model.predict(X[:1])
    
    end_time = time.time()
    avg_time = (end_time - start_time) / n_predictions * 1000
    
    print(f"平均预测时间: {avg_time:.2f}ms")
    return avg_time
```

### 2. 错误处理和日志

```python
import logging

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def safe_predict(model, features):
    """安全的预测函数"""
    try:
        logger.info("开始预测")
        prediction = model.predict(features)
        logger.info(f"预测完成: {prediction}")
        return prediction
    except Exception as e:
        logger.error(f"预测失败: {str(e)}")
        return None
```

---

*最后更新: 2026年2月15日*
*使用指南版本: v1.0*
*技术支持: build-your-own-ai项目团队*
