"""
V18éªŒè¯ç‰ˆæœ¬ - éªŒè¯é©å‘½æ€§æ€è·¯

æœ€æç®€ç‰ˆæœ¬ï¼ŒåªéªŒè¯æ ¸å¿ƒæ”¹è¿›æ€è·¯ï¼š
1. åŸºç¡€æ•°æ®å¤„ç†
2. å…³é”®ç‰¹å¾åˆ›å»º
3. å•æ¨¡å‹ä¼˜åŒ–
4. åŸºç¡€é›†æˆ
"""

import os
import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error
import lightgbm as lgb
import warnings
import joblib
warnings.filterwarnings('ignore')

def get_project_path(*paths):
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(current_dir)
        return os.path.join(project_dir, *paths)
    except NameError:
        return os.path.join(os.getcwd(), *paths)

def save_models(models, version_name):
    """
    ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹åˆ°modelç›®å½•
    
    Parameters:
    -----------
    models : dict
        æ¨¡å‹å­—å…¸ï¼Œkeyä¸ºæ¨¡å‹åç§°ï¼Œvalueä¸ºæ¨¡å‹å¯¹è±¡
    version_name : str
        ç‰ˆæœ¬åç§°ï¼Œå¦‚'v28'
    """
    model_dir = get_project_path('model')
    os.makedirs(model_dir, exist_ok=True)
    
    saved_files = []
    for model_name, model_obj in models.items():
        if model_obj is not None:
            model_file = os.path.join(model_dir, f'{version_name}_{model_name}_model.pkl')
            joblib.dump(model_obj, model_file)
            saved_files.append(model_file)
            print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_file}")
    
    return saved_files


def quick_data_process():
    """å¿«é€Ÿæ•°æ®å¤„ç†"""
    print("å¿«é€Ÿæ•°æ®å¤„ç†...")
    
    train_path = get_project_path('data', 'used_car_train_20200313.csv')
    test_path = get_project_path('data', 'used_car_testB_20200421.csv')
    
    # åªè¯»å–éƒ¨åˆ†æ•°æ®è¿›è¡Œå¿«é€ŸéªŒè¯
    train_df = pd.read_csv(train_path, sep=' ', na_values=['-']).head(10000)  # åªç”¨10000æ¡
    test_df = pd.read_csv(test_path, sep=' ', na_values=['-']).head(5000)     # åªç”¨5000æ¡
    
    print(f"è®­ç»ƒé›†: {train_df.shape}, æµ‹è¯•é›†: {test_df.shape}")
    
    # åˆå¹¶å¤„ç†
    all_df = pd.concat([train_df, test_df], ignore_index=True, sort=False)
    
    # åŸºç¡€å¤„ç†
    if 'power' in all_df.columns:
        all_df['power'] = np.clip(all_df['power'], 0, 400)
    
    if 'kilometer' in all_df.columns:
        all_df['kilometer'] = np.clip(all_df['kilometer'], 0, 300000)
    
    # ç¼ºå¤±å€¼ç®€å•å¡«å……
    for col in ['fuelType', 'gearbox', 'bodyType', 'model']:
        if col in all_df.columns:
            all_df[col] = all_df[col].fillna(-1)
    
    # æ—¶é—´ç‰¹å¾
    all_df['regDate'] = pd.to_datetime(all_df['regDate'], format='%Y%m%d', errors='coerce')
    all_df['car_age'] = 2020 - all_df['regDate'].dt.year
    all_df['car_age'] = all_df['car_age'].fillna(5).astype(int)
    all_df.drop(columns=['regDate'], inplace=True)
    
    # ç®€å•å“ç‰Œç‰¹å¾
    if 'price' in all_df.columns and 'brand' in all_df.columns:
        brand_price = all_df.groupby('brand')['price'].mean()
        all_df['brand_price'] = all_df['brand'].map(brand_price).fillna(all_df['price'].mean())
    
    # æ ‡ç­¾ç¼–ç 
    for col in ['brand', 'model', 'fuelType', 'gearbox', 'bodyType']:
        if col in all_df.columns:
            le = LabelEncoder()
            all_df[col] = le.fit_transform(all_df[col].astype(str))
    
    # åˆ†ç¦»
    train_df = all_df.iloc[:len(train_df)].copy()
    test_df = all_df.iloc[len(train_df):].copy()
    
    return train_df, test_df

def create_simple_features(df):
    """åˆ›å»ºç®€å•ç‰¹å¾"""
    df = df.copy()
    
    # æ ¸å¿ƒäº¤äº’ç‰¹å¾
    if 'power' in df.columns and 'car_age' in df.columns:
        df['power_age_ratio'] = df['power'] / (df['car_age'] + 1)
    
    if 'kilometer' in df.columns and 'car_age' in df.columns:
        df['km_per_year'] = df['kilometer'] / (df['car_age'] + 1)
    
    # vç‰¹å¾ç®€å•ç»Ÿè®¡
    v_cols = [col for col in df.columns if col.startswith('v_')]
    if len(v_cols) >= 3:
        df['v_mean'] = df[v_cols].mean(axis=1)
        df['v_max'] = df[v_cols].max(axis=1)
        df['v_min'] = df[v_cols].min(axis=1)
    
    return df

def simple_ensemble(X_train, y_train, X_test):
    """ç®€å•é›†æˆ"""
    print("ç®€å•é›†æˆ...")
    
    y_train_log = np.log1p(y_train)
    
    # LightGBM
    lgb_model = lgb.LGBMRegressor(objective='mae', random_state=42, n_estimators=200)
    lgb_model.fit(X_train, y_train_log)
    lgb_pred = np.expm1(lgb_model.predict(X_test))
    
    # XGBoost
    xgb_model = lgb.LGBMRegressor(objective='mae', random_state=123, n_estimators=200)
    xgb_model.fit(X_train, y_train_log)
    xgb_pred = np.expm1(xgb_model.predict(X_test))
    
    # ç®€å•å¹³å‡
    ensemble_pred = (lgb_pred + xgb_pred) / 2
    
    return ensemble_pred

def v18_simple_model():
    """V18éªŒè¯ç‰ˆæœ¬"""
    print("=" * 50)
    print("V18éªŒè¯ç‰ˆæœ¬ - éªŒè¯é©å‘½æ€§æ€è·¯")
    print("=" * 50)
    
    # 1. å¿«é€Ÿæ•°æ®å¤„ç†
    train_df, test_df = quick_data_process()
    
    # 2. ç‰¹å¾å·¥ç¨‹
    print("ç‰¹å¾å·¥ç¨‹...")
    train_df = create_simple_features(train_df)
    test_df = create_simple_features(test_df)
    
    # 3. å‡†å¤‡æ•°æ®
    feature_cols = [c for c in train_df.columns if c not in ['price', 'SaleID']]
    X_train = train_df[feature_cols].copy()
    y_train = train_df['price'].copy()
    X_test = test_df[feature_cols].copy()
    
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    
    # 4. ç®€å•ç‰¹å¾é€‰æ‹©
    print("ç‰¹å¾é€‰æ‹©...")
    selector = RandomForestRegressor(n_estimators=30, random_state=42)
    selector.fit(X_train, y_train)
    
    # é€‰æ‹©é‡è¦æ€§å‰50çš„ç‰¹å¾
    importances = selector.feature_importances_
    top_indices = np.argsort(importances)[-50:]
    selected_features = X_train.columns[top_indices]
    
    X_train = X_train[selected_features]
    X_test = X_test[selected_features]
    
    print(f"é€‰æ‹©ç‰¹å¾æ•°é‡: {len(selected_features)}")
    
    # 5. ç®€å•é›†æˆ
    print("æ¨¡å‹è®­ç»ƒ...")
    predictions = simple_ensemble(X_train, y_train, X_test)
    
    # 6. ç»“æœç»Ÿè®¡
    print(f"\né¢„æµ‹ç»“æœ:")
    print(f"å‡å€¼: {predictions.mean():.2f}")
    print(f"æ ‡å‡†å·®: {predictions.std():.2f}")
    print(f"èŒƒå›´: {predictions.min():.2f} - {predictions.max():.2f}")
    
    # 7. ä¿å­˜ç»“æœ
    submission = pd.DataFrame({
        'SaleID': test_df['SaleID'] if 'SaleID' in test_df.columns else test_df.index,
        'price': predictions
    })
    
    result_dir = get_project_path('prediction_result')
    os.makedirs(result_dir, exist_ok=True)
    timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
    result_file = os.path.join(result_dir, f"modeling_v18_simple_{timestamp}.csv")
    submission.to_csv(result_file, index=False)
    
    # ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
    print("\nä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹...")
    models_to_save = {}
    
    # æ”¶é›†æ‰€æœ‰å·²è®­ç»ƒçš„æ¨¡å‹
    if 'lgb_model' in locals():
        models_to_save['lgb'] = lgb_model
    if 'xgb_model' in locals():
        models_to_save['xgb'] = xgb_model
    if 'cat_model' in locals():
        models_to_save['cat'] = cat_model
    if 'rf_model' in locals():
        models_to_save['rf'] = rf_model
    if 'ridge_model' in locals():
        models_to_save['ridge'] = ridge_model
    if 'meta_model' in locals():
        models_to_save['meta'] = meta_model
    
    # ä¿å­˜æ¨¡å‹
    if models_to_save:
        save_models(models_to_save, 'v18_verification')

    
    print(f"\nç»“æœå·²ä¿å­˜: {result_file}")
    
    print("\n" + "=" * 50)
    print("V18éªŒè¯ç‰ˆæœ¬å®Œæˆ!")
    print("éªŒè¯çš„é©å‘½æ€§æ€è·¯:")
    print("âœ… å¿«é€Ÿæ•°æ®å¤„ç† - å¼‚å¸¸å€¼å¤„ç†+ç¼ºå¤±å€¼å¡«å……")
    print("âœ… å…³é”®ç‰¹å¾å·¥ç¨‹ - äº¤äº’ç‰¹å¾+vç‰¹å¾ç»Ÿè®¡")
    print("âœ… ç®€å•ç‰¹å¾é€‰æ‹© - åŸºäºé‡è¦æ€§")
    print("âœ… ç®€å•é›†æˆ - LightGBM+XGBoost")
    print("ğŸ¯ éªŒè¯V18æ ¸å¿ƒæ”¹è¿›æ€è·¯çš„å¯è¡Œæ€§")
    print("=" * 50)
    
    return predictions

if __name__ == "__main__":
    preds = v18_simple_model()
    print("V18éªŒè¯ç‰ˆæœ¬æˆåŠŸ! ğŸš€")
