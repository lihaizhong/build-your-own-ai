{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 钢铁缺陷检测分析\n",
    "\n",
    "## 项目概述\n",
    "\n",
    "这是一个专注于钢铁缺陷检测的计算机视觉项目，基于深度学习技术对钢铁表面缺陷进行自动识别和分类。\n",
    "\n",
    "### 项目目标\n",
    "- 实现钢铁表面缺陷的自动检测和分类\n",
    "- 提高缺陷检测的准确率和召回率\n",
    "- 优化模型推理速度，满足实时检测需求\n",
    "- 开发可部署的缺陷检测系统原型\n",
    "\n",
    "### 技术栈\n",
    "- **深度学习框架**: PyTorch\n",
    "- **图像处理**: OpenCV, PIL\n",
    "- **数据处理**: Pandas, NumPy\n",
    "- **可视化**: Matplotlib, Seaborn\n",
    "\n",
    "## 1. 环境设置和数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境设置完成!\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 设置matplotlib中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans', 'Arial', 'sans-serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境设置完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据探索性分析 (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据目录结构:\n",
      "  /root/CASE-钢铁缺陷检测-P1/data/train/IMAGES: 1400 张图像\n",
      "  /root/CASE-钢铁缺陷检测-P1/data/test/IMAGES: 400 张图像\n",
      "  /root/CASE-钢铁缺陷检测-P1/data/validation/IMAGES: 目录不存在\n"
     ]
    }
   ],
   "source": [
    "# 数据路径设置\n",
    "data_dir = \"/root/CASE-钢铁缺陷检测-P1/data/\"\n",
    "train_dir = os.path.join(data_dir, \"train\", \"IMAGES\")\n",
    "test_dir = os.path.join(data_dir, \"test\", \"IMAGES\")\n",
    "val_dir = os.path.join(data_dir, \"validation\", \"IMAGES\")\n",
    "\n",
    "# 检查数据目录结构\n",
    "def check_data_structure():\n",
    "    print(\"数据目录结构:\")\n",
    "    for dir_path in [train_dir, test_dir, val_dir]:\n",
    "        if os.path.exists(dir_path):\n",
    "            num_images = len([f for f in os.listdir(dir_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "            print(f\"  {dir_path}: {num_images} 张图像\")\n",
    "        else:\n",
    "            print(f\"  {dir_path}: 目录不存在\")\n",
    "\n",
    "check_data_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据预处理和增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据预处理管道定义完成!\n"
     ]
    }
   ],
   "source": [
    "# 定义数据增强和预处理\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"数据预处理管道定义完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 自定义数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集类定义完成!\n"
     ]
    }
   ],
   "source": [
    "class SteelDefectDataset(Dataset):\n",
    "    \"\"\"钢铁缺陷检测数据集类\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 假设数据目录结构: data_dir/class_name/image.jpg\n",
    "        if os.path.exists(data_dir):\n",
    "            for class_name in os.listdir(data_dir):\n",
    "                class_dir = os.path.join(data_dir, class_name)\n",
    "                if os.path.isdir(class_dir):\n",
    "                    for img_name in os.listdir(class_dir):\n",
    "                        if img_name.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                            self.image_paths.append(os.path.join(class_dir, img_name))\n",
    "                            self.labels.append(class_name)\n",
    "        \n",
    "        # 创建标签映射\n",
    "        self.classes = sorted(list(set(self.labels)))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.idx_to_class = {idx: cls for cls, idx in self.class_to_idx.items()}\n",
    "        \n",
    "        # 将标签转换为索引\n",
    "        self.label_indices = [self.class_to_idx[label] for label in self.labels]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.label_indices[idx]\n",
    "        \n",
    "        # 加载图像\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def get_class_distribution(self):\n",
    "        \"\"\"获取类别分布\"\"\"\n",
    "        from collections import Counter\n",
    "        return Counter(self.labels)\n",
    "\n",
    "print(\"数据集类定义完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CNN基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数量: 51,606,854\n"
     ]
    }
   ],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    \"\"\"自定义CNN模型\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=6):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # 卷积层\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # 池化层\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 512)  # 224/2/2/2 = 28\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # 激活函数和Dropout\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 卷积层1\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        \n",
    "        # 卷积层2\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        \n",
    "        # 卷积层3\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        \n",
    "        # 展平\n",
    "        x = x.view(-1, 128 * 28 * 28)\n",
    "        \n",
    "        # 全连接层\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# 测试模型\n",
    "model = CNNModel(num_classes=6)\n",
    "print(f\"模型参数量: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练函数定义完成!\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, device='cuda'):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100. * correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_accs': val_accs\n",
    "    }\n",
    "\n",
    "print(\"训练函数定义完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评估函数定义完成!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    \"\"\"评估模型性能\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # 计算评估指标\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "print(\"评估函数定义完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 可视化工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可视化工具定义完成!\n"
     ]
    }
   ],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"绘制训练历史\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # 损失曲线\n",
    "    axes[0].plot(history['train_losses'], label='训练损失')\n",
    "    axes[0].plot(history['val_losses'], label='验证损失')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('训练和验证损失曲线')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 准确率曲线\n",
    "    axes[1].plot(history['train_accs'], label='训练准确率')\n",
    "    axes[1].plot(history['val_accs'], label='验证准确率')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('训练和验证准确率曲线')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('user_data/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"绘制混淆矩阵\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('预测标签')\n",
    "    plt.ylabel('真实标签')\n",
    "    plt.title('混淆矩阵')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_result/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"可视化工具定义完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 主训练流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "模型和优化器设置完成!\n",
      "注意: 需要实际数据才能运行训练流程\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"主训练流程\"\"\"\n",
    "    \n",
    "    # 设置设备\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"使用设备: {device}\")\n",
    "    \n",
    "    # 创建数据集（这里需要实际数据）\n",
    "    # train_dataset = SteelDefectDataset(train_dir, transform=train_transform)\n",
    "    # val_dataset = SteelDefectDataset(val_dir, transform=val_transform)\n",
    "    # test_dataset = SteelDefectDataset(test_dir, transform=val_transform)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    # test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # 创建模型\n",
    "    model = CNNModel(num_classes=6)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    print(\"模型和优化器设置完成!\")\n",
    "    print(\"注意: 需要实际数据才能运行训练流程\")\n",
    "    \n",
    "    return model, criterion, optimizer\n",
    "\n",
    "# 运行主流程\n",
    "model, criterion, optimizer = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 保存和加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型保存和加载函数定义完成!\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, path='model/cnn_v1_model.pth'):\n",
    "    \"\"\"保存模型\"\"\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_architecture': model.__class__.__name__\n",
    "    }, path)\n",
    "    print(f\"模型已保存到: {path}\")\n",
    "\n",
    "def load_model(path='model/cnn_v1_model.pth', model_class=CNNModel, num_classes=6):\n",
    "    \"\"\"加载模型\"\"\"\n",
    "    checkpoint = torch.load(path, map_location='cpu')\n",
    "    model = model_class(num_classes=num_classes)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"模型已从 {path} 加载\")\n",
    "    return model\n",
    "\n",
    "print(\"模型保存和加载函数定义完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 预测和结果保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果保存函数定义完成!\n"
     ]
    }
   ],
   "source": [
    "def save_predictions(predictions, labels, image_paths, class_names, save_path='prediction_result/test_predictions.csv'):\n",
    "    \"\"\"保存预测结果\"\"\"\n",
    "    results = []\n",
    "    for i, (pred, true_label, img_path) in enumerate(zip(predictions, labels, image_paths)):\n",
    "        results.append({\n",
    "            'image_id': i,\n",
    "            'image_path': img_path,\n",
    "            'true_label': class_names[true_label],\n",
    "            'predicted_label': class_names[pred],\n",
    "            'is_correct': pred == true_label\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"预测结果已保存到: {save_path}\")\n",
    "    return df\n",
    "\n",
    "def save_metrics(metrics, save_path='prediction_result/performance_metrics.csv'):\n",
    "    \"\"\"保存性能指标\"\"\"\n",
    "    metrics_df = pd.DataFrame([{\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'f1_score': metrics['f1_score']\n",
    "    }])\n",
    "    metrics_df.to_csv(save_path, index=False)\n",
    "    print(f\"性能指标已保存到: {save_path}\")\n",
    "\n",
    "print(\"结果保存函数定义完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 总结和下一步计划"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "钢铁缺陷检测项目框架搭建完成!\n",
      "\n",
      "下一步计划:\n",
      "1. 准备钢铁缺陷数据集\n",
      "2. 运行数据预处理和增强\n",
      "3. 训练CNN基础模型\n",
      "4. 评估模型性能\n",
      "5. 尝试ResNet和EfficientNet等先进模型\n",
      "6. 优化模型参数和超参数\n",
      "7. 部署模型进行实时检测\n"
     ]
    }
   ],
   "source": [
    "print(\"钢铁缺陷检测项目框架搭建完成!\")\n",
    "print(\"\\n下一步计划:\")\n",
    "print(\"1. 准备钢铁缺陷数据集\")\n",
    "print(\"2. 运行数据预处理和增强\")\n",
    "print(\"3. 训练CNN基础模型\")\n",
    "print(\"4. 评估模型性能\")\n",
    "print(\"5. 尝试ResNet和EfficientNet等先进模型\")\n",
    "print(\"6. 优化模型参数和超参数\")\n",
    "print(\"7. 部署模型进行实时检测\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
