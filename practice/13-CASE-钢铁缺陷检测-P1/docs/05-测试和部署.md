# é’¢é“ç¼ºé™·æ£€æµ‹ç³»ç»Ÿ - æµ‹è¯•å’Œéƒ¨ç½²

## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

#### SteelDefectTrainerç±»æµ‹è¯•

```python
import unittest
import torch
from pathlib import Path
from unittest.mock import Mock, patch
from code.train_yolov11 import SteelDefectTrainer


class TestSteelDefectTrainer(unittest.TestCase):
    """SteelDefectTrainerç±»çš„å•å…ƒæµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.config_path = "config/training_config.yaml"
        self.trainer = SteelDefectTrainer(self.config_path)
    
    def test_initialization(self):
        """æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–"""
        self.assertIsNotNone(self.trainer.config)
        self.assertEqual(self.trainer.config.get("imgsz"), 200)
        self.assertEqual(self.trainer.config.get("model"), "yolo11n.pt")
    
    def test_config_loading(self):
        """æµ‹è¯•é…ç½®åŠ è½½"""
        config = self.trainer.load_config()
        self.assertIsInstance(config, dict)
        self.assertIn("epochs", config)
        self.assertIn("batch_size", config)
    
    def test_seed_setting(self):
        """æµ‹è¯•éšæœºç§å­è®¾ç½®"""
        import random
        import numpy as np
        
        self.trainer.set_seed(42)
        
        # éªŒè¯éšæœºç§å­æ˜¯å¦è®¾ç½®æ­£ç¡®
        self.assertEqual(random.randint(0, 100), random.randint(0, 100))
    
    def test_device_setting(self):
        """æµ‹è¯•è®¾å¤‡è®¾ç½®"""
        device = self.trainer.set_device()
        self.assertIsInstance(device, torch.device)
    
    def test_default_config(self):
        """æµ‹è¯•é»˜è®¤é…ç½®"""
        default_config = self.trainer.get_default_config()
        
        self.assertEqual(default_config["epochs"], 200)
        self.assertEqual(default_config["imgsz"], 200)
        self.assertEqual(default_config["batch_size"], 16)
        self.assertEqual(default_config["lr0"], 0.001)


class TestDataConverter(unittest.TestCase):
    """æ•°æ®è½¬æ¢åŠŸèƒ½æµ‹è¯•"""
    
    def setUp(self):
        self.converter = SteelDefectConverter("data")
    
    def test_class_mapping(self):
        """æµ‹è¯•ç±»åˆ«æ˜ å°„"""
        expected_classes = {
            "rolled-in_scale": 0,
            "patches": 1,
            "scratches": 2,
            "inclusion": 3,
            "crazing": 4,
            "pitted_surface": 5
        }
        self.assertEqual(self.converter.class_map, expected_classes)
    
    def test_coordinate_conversion(self):
        """æµ‹è¯•åæ ‡è½¬æ¢"""
        # æµ‹è¯•VOCåˆ°YOLOåæ ‡è½¬æ¢
        width, height = 200, 200
        xmin, ymin, xmax, ymax = 50, 50, 150, 100
        
        # YOLOæ ¼å¼è®¡ç®—
        cx = (xmin + xmax) / 2 / width
        cy = (ymin + ymax) / 2 / height
        w = (xmax - xmin) / width
        h = (ymax - ymin) / height
        
        # éªŒè¯ç»“æœ
        self.assertAlmostEqual(cx, 0.5, places=4)
        self.assertAlmostEqual(cy, 0.375, places=4)
        self.assertAlmostEqual(w, 0.5, places=4)
        self.assertAlmostEqual(h, 0.25, places=4)
    
    def test_train_val_split(self):
        """æµ‹è¯•è®­ç»ƒé›†éªŒè¯é›†åˆ’åˆ†"""
        train_files = [f"file_{i}.xml" for i in range(100)]
        train_split, val_split = self.converter.split_train_val(train_files, 0.2)
        
        self.assertEqual(len(train_split), 80)
        self.assertEqual(len(val_split), 20)


class TestModelInference(unittest.TestCase):
    """æ¨¡å‹æ¨ç†æµ‹è¯•"""
    
    def test_model_loading(self):
        """æµ‹è¯•æ¨¡å‹åŠ è½½"""
        try:
            from ultralytics import YOLO
            model = YOLO("yolo11n.pt")
            self.assertIsNotNone(model)
        except Exception as e:
            self.skipTest(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def test_prediction_output(self):
        """æµ‹è¯•é¢„æµ‹è¾“å‡ºæ ¼å¼"""
        try:
            from ultralytics import YOLO
            import numpy as np
            
            model = YOLO("yolo11n.pt")
            dummy_image = np.random.randint(0, 255, (200, 200, 3), dtype=np.uint8)
            
            results = model.predict(dummy_image, verbose=False)
            
            self.assertEqual(len(results), 1)
            self.assertTrue(hasattr(results[0], 'boxes'))
        except Exception as e:
            self.skipTest(f"é¢„æµ‹æµ‹è¯•å¤±è´¥: {e}")


if __name__ == '__main__':
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    unittest.main(verbosity=2)
```

### 2. é›†æˆæµ‹è¯•

#### ç«¯åˆ°ç«¯æµ‹è¯•

```python
import pytest
import tempfile
import os
from pathlib import Path


class TestEndToEnd:
    """ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    @pytest.fixture
    def temp_dir(self):
        """åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•"""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield temp_dir
    
    def test_complete_pipeline(self, temp_dir):
        """æµ‹è¯•å®Œæ•´æ•°æ®å¤„ç†ç®¡é“"""
        # 1. åˆ›å»ºæµ‹è¯•æ•°æ®
        self.create_test_data(temp_dir)
        
        # 2. æ•°æ®è½¬æ¢
        from code.convert_voc_to_yolo import SteelDefectConverter
        converter = SteelDefectConverter(temp_dir)
        converter.process_dataset(val_ratio=0.2)
        
        # 3. éªŒè¯è½¬æ¢ç»“æœ
        yolo_dir = Path(temp_dir) / "yolo_format"
        assert yolo_dir.exists()
        assert (yolo_dir / "data.yaml").exists()
        
        # 4. è®­ç»ƒæµ‹è¯•
        config = {
            "data_yaml": str(yolo_dir / "data.yaml"),
            "epochs": 5,  # å¿«é€Ÿæµ‹è¯•
            "imgsz": 200,
            "batch_size": 4,
        }
        
        trainer = SteelDefectTrainer()
        trainer.config.update(config)
        
        # 5. éªŒè¯è®­ç»ƒæµç¨‹
        model, results = trainer.train_model()
        assert model is not None
    
    def create_test_data(self, temp_dir):
        """åˆ›å»ºæµ‹è¯•æ•°æ®"""
        # åˆ›å»ºç›®å½•ç»“æ„
        train_images = Path(temp_dir) / "train" / "IMAGES"
        train_annotations = Path(temp_dir) / "train" / "ANNOTATIONS"
        test_images = Path(temp_dir) / "test" / "IMAGES"
        
        for dir_path in [train_images, train_annotations, test_images]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒå’Œæ ‡æ³¨
        for i in range(10):
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            import numpy as np
            from PIL import Image
            
            img = np.random.randint(0, 255, (200, 200), dtype=np.uint8)
            Image.fromarray(img).save(train_images / f"{i}.jpg")
            
            # åˆ›å»ºæµ‹è¯•æ ‡æ³¨
            xml_content = f"""<?xml version="1.0"?>
            <annotation>
                <filename>{i}.jpg</filename>
                <size>
                    <width>200</width>
                    <height>200</height>
                    <depth>1</depth>
                </size>
                <object>
                    <name>rolled-in_scale</name>
                    <bndbox>
                        <xmin>50</xmin>
                        <ymin>50</ymin>
                        <xmax>150</xmax>
                        <ymax>100</ymax>
                    </bndbox>
                </object>
            </annotation>"""
            
            with open(train_annotations / f"{i}.xml", 'w') as f:
                f.write(xml_content)
```

### 3. æ€§èƒ½æµ‹è¯•

#### æ¨ç†æ€§èƒ½æµ‹è¯•

```python
import time
import numpy as np
from ultralytics import YOLO


class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""
    
    def test_inference_speed(self):
        """æµ‹è¯•æ¨ç†é€Ÿåº¦"""
        model = YOLO("yolo11n.pt")
        
        # å‡†å¤‡æµ‹è¯•å›¾åƒ
        test_images = [
            np.random.randint(0, 255, (200, 200, 3), dtype=np.uint8)
            for _ in range(100)
        ]
        
        # é¢„çƒ­
        for _ in range(10):
            model.predict(test_images[0], verbose=False)
        
        # æµ‹è¯•æ¨ç†é€Ÿåº¦
        start_time = time.time()
        for img in test_images:
            model.predict(img, verbose=False)
        end_time = time.time()
        
        total_time = end_time - start_time
        avg_time = total_time / len(test_images)
        fps = len(test_images) / total_time
        
        print(f"\næ¨ç†æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"  æ€»æ—¶é—´: {total_time:.2f}ç§’")
        print(f"  å¹³å‡æ¨ç†æ—¶é—´: {avg_time*1000:.2f}ms")
        print(f"  FPS: {fps:.2f}")
        
        # éªŒè¯æ€§èƒ½è¦æ±‚
        assert fps > 10, "æ¨ç†é€Ÿåº¦ä½äº10 FPS"
    
    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        import psutil
        import gc
        
        process = psutil.Process()
        
        # è®°å½•åˆå§‹å†…å­˜
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # åŠ è½½æ¨¡å‹
        model = YOLO("yolo11n.pt")
        
        # è®°å½•åŠ è½½åå†…å­˜
        loaded_memory = process.memory_info().rss / 1024 / 1024
        
        # æ‰§è¡Œæ¨ç†
        test_image = np.random.randint(0, 255, (200, 200, 3), dtype=np.uint8)
        for _ in range(100):
            model.predict(test_image, verbose=False)
        
        # è®°å½•æ¨ç†åå†…å­˜
        inference_memory = process.memory_info().rss / 1024 / 1024
        
        print(f"\nå†…å­˜ä½¿ç”¨æµ‹è¯•ç»“æœ:")
        print(f"  åˆå§‹å†…å­˜: {initial_memory:.2f} MB")
        print(f"  åŠ è½½æ¨¡å‹å: {loaded_memory:.2f} MB")
        print(f"  æ¨ç†å: {inference_memory:.2f} MB")
        print(f"  æ¨¡å‹å ç”¨: {loaded_memory - initial_memory:.2f} MB")
        
        # æ¸…ç†
        del model
        gc.collect()
    
    def test_model_size(self):
        """æµ‹è¯•æ¨¡å‹å¤§å°"""
        model_path = Path("yolo11n.pt")
        
        if model_path.exists():
            size_mb = model_path.stat().st_size / 1024 / 1024
            print(f"\næ¨¡å‹å¤§å°: {size_mb:.2f} MB")
            assert size_mb < 20, "æ¨¡å‹å¤§å°è¶…è¿‡20MB"
```

## éƒ¨ç½²ç­–ç•¥

### 1. Dockerå®¹å™¨åŒ–éƒ¨ç½²

#### Dockerfile

```dockerfile
# Dockerfile
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å®‰è£…PyTorchå’ŒUltralytics
RUN pip install torch torchvision ultralytics

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /app/data /app/runs /app/output

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV DATA_DIR=/app/data
ENV OUTPUT_DIR=/app/output

# æš´éœ²ç«¯å£ï¼ˆå¦‚æœéœ€è¦WebæœåŠ¡ï¼‰
EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "from ultralytics import YOLO; print('OK')" || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["python", "code/train_yolov11.py", "--config", "config/training_config.yaml"]
```

#### Docker Composeé…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  steel-defect-detection:
    build: .
    container_name: steel-defect-detection
    volumes:
      - ./data:/app/data
      - ./runs:/app/runs
      - ./output:/app/output
    environment:
      - PYTHONUNBUFFERED=1
      - DATA_DIR=/app/data
      - OUTPUT_DIR=/app/output
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # TensorBoardæœåŠ¡ï¼ˆå¯é€‰ï¼‰
  tensorboard:
    image: tensorflow/tensorflow:latest
    container_name: tensorboard
    ports:
      - "6006:6006"
    volumes:
      - ./runs:/logs
    command: tensorboard --logdir=/logs --host=0.0.0.0
    restart: unless-stopped
```

### 2. æ¨¡å‹å¯¼å‡º

#### ONNXå¯¼å‡º

```python
from ultralytics import YOLO

def export_to_onnx(model_path, output_path=None):
    """å¯¼å‡ºæ¨¡å‹ä¸ºONNXæ ¼å¼"""
    model = YOLO(model_path)
    
    # å¯¼å‡ºé…ç½®
    export_args = {
        'format': 'onnx',
        'imgsz': 200,
        'simplify': True,      # ç®€åŒ–æ¨¡å‹
        'opset': 12,           # ONNX opsetç‰ˆæœ¬
        'dynamic': False,      # é™æ€è¾“å…¥å°ºå¯¸
    }
    
    exported_path = model.export(**export_args)
    print(f"æ¨¡å‹å·²å¯¼å‡ºåˆ°: {exported_path}")
    
    return exported_path


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    export_to_onnx("runs/detect/steel_defect_yolo11n_*/weights/best.pt")
```

#### TensorRTå¯¼å‡º

```python
def export_to_tensorrt(model_path, workspace=4):
    """å¯¼å‡ºæ¨¡å‹ä¸ºTensorRTæ ¼å¼"""
    model = YOLO(model_path)
    
    # å¯¼å‡ºé…ç½®
    export_args = {
        'format': 'engine',      # TensorRTæ ¼å¼
        'imgsz': 200,
        'workspace': workspace,  # å·¥ä½œç©ºé—´å¤§å°(GB)
        'simplify': True,
        'fp16': True,            # FP16ç²¾åº¦
    }
    
    exported_path = model.export(**export_args)
    print(f"TensorRTæ¨¡å‹å·²å¯¼å‡ºåˆ°: {exported_path}")
    
    return exported_path
```

### 3. æ¨ç†æœåŠ¡éƒ¨ç½²

#### FastAPIæ¨ç†æœåŠ¡

```python
# api_server.py
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from ultralytics import YOLO
import numpy as np
from PIL import Image
import io

app = FastAPI(title="é’¢é“ç¼ºé™·æ£€æµ‹API")

# å…¨å±€æ¨¡å‹
model = None


@app.on_event("startup")
async def load_model():
    """å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹"""
    global model
    model = YOLO("runs/detect/steel_defect_yolo11n_*/weights/best.pt")
    print("æ¨¡å‹åŠ è½½å®Œæˆ")


@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    """
    é¢„æµ‹æ¥å£
    
    Args:
        file: ä¸Šä¼ çš„å›¾åƒæ–‡ä»¶
    
    Returns:
        æ£€æµ‹ç»“æœ
    """
    # è¯»å–å›¾åƒ
    image_data = await file.read()
    image = Image.open(io.BytesIO(image_data))
    image_array = np.array(image)
    
    # æ‰§è¡Œé¢„æµ‹
    results = model.predict(image_array, conf=0.25)
    
    # è§£æç»“æœ
    detections = []
    for box in results[0].boxes:
        detection = {
            "class_id": int(box.cls[0]),
            "class_name": model.names[int(box.cls[0])],
            "confidence": float(box.conf[0]),
            "bbox": box.xyxy[0].tolist()
        }
        detections.append(detection)
    
    return JSONResponse({
        "success": True,
        "detections": detections,
        "count": len(detections)
    })


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "ok", "model": "loaded"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### å¯åŠ¨æ¨ç†æœåŠ¡

```bash
# å¯åŠ¨APIæœåŠ¡
uvicorn api_server:app --host 0.0.0.0 --port 8000

# æµ‹è¯•API
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@data/test/IMAGES/1400.jpg"
```

### 4. ç›‘æ§å’Œæ—¥å¿—

#### æ—¥å¿—é…ç½®

```python
# logging_config.py
import logging
import logging.config

LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'standard': {
            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        },
        'detailed': {
            'format': '%(asctime)s [%(levelname)s] %(name)s:%(lineno)d: %(message)s'
        },
    },
    'handlers': {
        'console': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'standard',
            'stream': 'ext://sys.stdout'
        },
        'file': {
            'level': 'INFO',
            'class': 'logging.handlers.RotatingFileHandler',
            'formatter': 'detailed',
            'filename': 'logs/app.log',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5
        }
    },
    'loggers': {
        '': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': False
        }
    }
}


def setup_logging():
    logging.config.dictConfig(LOGGING_CONFIG)
```

#### æ€§èƒ½ç›‘æ§

```python
# monitoring.py
import time
from functools import wraps
import logging

logger = logging.getLogger(__name__)


def monitor_performance(func):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            duration = time.time() - start_time
            logger.info(f"{func.__name__} æ‰§è¡Œå®Œæˆ: {duration:.3f}ç§’")
            return result
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"{func.__name__} æ‰§è¡Œå¤±è´¥: {e}, è€—æ—¶: {duration:.3f}ç§’")
            raise
    return wrapper


class PerformanceTracker:
    """æ€§èƒ½è¿½è¸ªå™¨"""
    
    def __init__(self):
        self.metrics = {}
    
    def record(self, name: str, value: float):
        """è®°å½•æŒ‡æ ‡"""
        if name not in self.metrics:
            self.metrics[name] = []
        self.metrics[name].append(value)
    
    def get_stats(self, name: str):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if name not in self.metrics:
            return None
        
        values = self.metrics[name]
        return {
            'mean': np.mean(values),
            'std': np.std(values),
            'min': np.min(values),
            'max': np.max(values),
            'count': len(values)
        }
```

## éƒ¨ç½²éªŒè¯

### 1. éƒ¨ç½²åéªŒè¯è„šæœ¬

```python
# deployment_validator.py
import requests
import time
import logging

logger = logging.getLogger(__name__)


def validate_deployment(base_url: str, timeout: int = 60):
    """éªŒè¯éƒ¨ç½²æ˜¯å¦æˆåŠŸ"""
    
    # 1. å¥åº·æ£€æŸ¥
    health_url = f"{base_url}/health"
    try:
        response = requests.get(health_url, timeout=5)
        if response.status_code == 200:
            logger.info("âœ… å¥åº·æ£€æŸ¥é€šè¿‡")
        else:
            logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥è¶…æ—¶æˆ–å¤±è´¥: {e}")
        return False
    
    # 2. é¢„æµ‹æµ‹è¯•
    test_image_path = "data/test/IMAGES/1400.jpg"
    predict_url = f"{base_url}/predict"
    
    try:
        with open(test_image_path, 'rb') as f:
            files = {'file': f}
            response = requests.post(predict_url, files=files, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            logger.info(f"âœ… é¢„æµ‹æµ‹è¯•é€šè¿‡ï¼Œæ£€æµ‹åˆ° {result['count']} ä¸ªç¼ºé™·")
        else:
            logger.error(f"âŒ é¢„æµ‹æµ‹è¯•å¤±è´¥: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"âŒ é¢„æµ‹æµ‹è¯•å¼‚å¸¸: {e}")
        return False
    
    logger.info("ğŸ‰ éƒ¨ç½²éªŒè¯å…¨éƒ¨é€šè¿‡")
    return True


if __name__ == "__main__":
    validate_deployment("http://localhost:8000")
```

### 2. CI/CDæµæ°´çº¿

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11, 3.12]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install ultralytics opencv-python pillow pytest
    
    - name: Run tests
      run: |
        pytest tests/ -v --cov=code --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: |
        docker build -t steel-defect-detection:${{ github.sha }} .
        docker tag steel-defect-detection:${{ github.sha }} steel-defect-detection:latest
    
    - name: Push to registry
      run: |
        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
        docker push steel-defect-detection:${{ github.sha }}
        docker push steel-defect-detection:latest

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Deploy to production
      run: |
        # éƒ¨ç½²è„šæœ¬
        echo "éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ"
```

## æ¨ç†ä¼˜åŒ–

### 1. æ¨¡å‹é‡åŒ–

```python
def quantize_model(model_path, output_path):
    """æ¨¡å‹é‡åŒ–ï¼ˆFP16/INT8ï¼‰"""
    import torch
    
    # åŠ è½½æ¨¡å‹
    model = YOLO(model_path)
    
    # FP16é‡åŒ–
    model_fp16 = model.model.half()
    
    # ä¿å­˜é‡åŒ–æ¨¡å‹
    torch.save(model_fp16.state_dict(), output_path)
    
    print(f"é‡åŒ–æ¨¡å‹å·²ä¿å­˜åˆ°: {output_path}")
```

### 2. æ‰¹é‡æ¨ç†ä¼˜åŒ–

```python
def batch_inference(model_path, image_dir, batch_size=32):
    """æ‰¹é‡æ¨ç†ä¼˜åŒ–"""
    from pathlib import Path
    from PIL import Image
    import numpy as np
    
    model = YOLO(model_path)
    
    # åŠ è½½æ‰€æœ‰å›¾åƒ
    image_files = list(Path(image_dir).glob("*.jpg"))
    
    results = []
    for i in range(0, len(image_files), batch_size):
        batch_files = image_files[i:i+batch_size]
        batch_images = [np.array(Image.open(f)) for f in batch_files]
        
        # æ‰¹é‡é¢„æµ‹
        batch_results = model.predict(batch_images, verbose=False)
        results.extend(batch_results)
    
    return results
```

---

*æœ€åæ›´æ–°: 2026å¹´2æœˆ14æ—¥*
*æµ‹è¯•å’Œéƒ¨ç½²ç‰ˆæœ¬: v1.0*
*è¿ç»´å›¢é˜Ÿ: DevOpsè¿ç»´ç»„*
