# 迪士尼RAG问答助手 - 代码实现

## 核心代码结构

```
code/
├── __init__.py            # 模块初始化和版本信息
├── config.py              # 配置管理模块
├── utils.py               # 工具函数模块
├── data_processor.py      # 数据处理层（Step1）
├── embedding.py           # 向量化层（Step2）
├── retrieval.py           # 检索层（Step3）
├── generator.py           # 生成层（Step4）
└── main.py                # 主程序入口
```

---

## 配置模块 (config.py)

### Config类设计

```python
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Any, Optional

@dataclass
class Config:
    """配置类 - 管理项目所有配置参数"""
    
    # ========== 路径配置 ==========
    project_root: Path = get_project_root()
    data_dir: Path | None = None
    documents_dir: Path | None = None      # 文档目录
    images_dir: Path | None = None         # 图像目录
    indexes_dir: Path | None = None        # 索引目录
    cache_dir: Path | None = None          # 缓存目录
    output_dir: Path | None = None         # 输出目录
    
    # ========== Embedding配置 ==========
    text_embedding_model: str = "text-embedding-v4"  # 文本模型
    text_embedding_dim: int = 1024                   # 文本向量维度
    image_embedding_dim: int = 512                   # 图像向量维度
    clip_model_name: str = "clip-vit-base-patch32"   # CLIP模型
    
    # ========== FAISS配置 ==========
    index_type: str = "IndexFlatL2"  # 索引类型
    nlist: int = 100                # IVF聚类中心数
    
    # ========== 检索配置 ==========
    top_k: int = 5                  # 返回结果数量
    score_threshold: float = 0.7    # 相似度阈值
    
    # ========== LLM配置 ==========
    llm_model: str = "qwen-max"     # 语言模型
    llm_temperature: float = 0.7    # 温度参数
    llm_max_tokens: int = 2000      # 最大输出长度
    
    # ========== OCR配置 ==========
    tesseract_config: str = "--psm 6"
    ocr_language: str = "chi_sim+eng"
    
    # ========== 关键词配置 ==========
    image_keywords: list | None = None  # 图像触发关键词
    
    def __post_init__(self):
        """初始化路径和默认值"""
        # 设置路径
        if self.data_dir is None:
            self.data_dir = self.project_root / "data"
        if self.documents_dir is None:
            self.documents_dir = self.data_dir / "documents"
        # ... 其他路径初始化
        
        # 设置默认关键词
        if self.image_keywords is None:
            self.image_keywords = ["海报", "图片", "图像", "照片", "截图", "展示"]
        
        # 确保目录存在
        self._ensure_directories()
```

### 配置加载

```python
def load_env_config():
    """从环境变量加载配置"""
    # 从.env文件加载
    from dotenv import load_dotenv
    load_dotenv()
    
    # 更新配置
    config.llm_model = os.environ.get("LLM_MODEL", config.llm_model)
    config.text_embedding_model = os.environ.get(
        "TEXT_EMBEDDING_MODEL", config.text_embedding_model
    )

# 全局配置实例
config = Config()
```

---

## 数据处理层 (data_processor.py)

### 数据类定义

```python
from dataclasses import dataclass
from typing import List, Dict, Any, Optional

@dataclass
class TextChunk:
    """文本块数据类"""
    text: str                         # 文本内容
    source: str                       # 来源文件
    page: Optional[int] = None        # 页码/段落号
    chunk_id: Optional[str] = None    # 唯一标识
    metadata: Optional[Dict[str, Any]] = None  # 元数据
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
        if self.chunk_id is None:
            self.chunk_id = f"{self.source}_{get_timestamp()}"


@dataclass
class ImageData:
    """图像数据类"""
    image_path: Path                  # 图像路径
    ocr_text: str = ""               # OCR文本
    embedding: Optional[List[float]] = None  # 图像向量
    metadata: Optional[Dict[str, Any]] = None  # 元数据
```

### 文档处理器

```python
class DocumentProcessor:
    """文档处理器 - 处理Word和文本文件"""
    
    def __init__(self, documents_dir: Optional[Path] = None):
        self.documents_dir = documents_dir or config.documents_dir
        self.chunks: List[TextChunk] = []
    
    def process_directory(self, directory: Optional[Path] = None) -> List[TextChunk]:
        """处理目录中的所有文档"""
        target_dir = directory or self.documents_dir
        
        # 支持的文件扩展名
        supported_extensions = {'.docx', '.txt', '.md'}
        
        # 查找所有文档文件
        doc_files = [
            f for f in target_dir.rglob('*')
            if f.is_file() and f.suffix.lower() in supported_extensions
        ]
        
        self.chunks = []
        for doc_file in doc_files:
            try:
                chunks = self.process_file(doc_file)
                self.chunks.extend(chunks)
            except Exception as e:
                logger.error(f"处理文件失败 {doc_file.name}: {e}")
        
        return self.chunks
    
    def process_file(self, file_path: Path) -> List[TextChunk]:
        """处理单个文档文件"""
        file_extension = file_path.suffix.lower()
        
        if file_extension == '.docx':
            return self._process_docx(file_path)
        elif file_extension in ['.txt', '.md']:
            return self._process_text_file(file_path)
        else:
            return []
    
    def _process_docx(self, file_path: Path) -> List[TextChunk]:
        """处理Word文档"""
        chunks = []
        doc = Document(file_path)
        file_hash = get_file_hash(file_path)
        
        # 提取段落和表格
        content_parts = []
        for element in doc.element.body:
            if element.tag.endswith('p'):  # 段落
                paragraph = Paragraph(element, doc)
                if paragraph.text.strip():
                    content_parts.append({
                        'type': 'paragraph',
                        'text': paragraph.text
                    })
            elif element.tag.endswith('tbl'):  # 表格
                table = Table(element, doc)
                table_data = self._extract_table_data(table)
                if table_data:
                    table_md = table_to_markdown(table_data)
                    content_parts.append({
                        'type': 'table',
                        'text': table_md
                    })
        
        # 分块处理
        for part in content_parts:
            chunked = self._create_text_chunks(
                part['text'], file_path, 0, file_hash
            )
            chunks.extend(chunked)
        
        return chunks
```

### 图像处理器

```python
class ImageProcessor:
    """图像处理器 - 处理图像和OCR"""
    
    def __init__(self, images_dir: Optional[Path] = None):
        self.images_dir = images_dir or config.images_dir
        self.images: List[ImageData] = []
    
    def process_directory(self, directory: Optional[Path] = None) -> List[ImageData]:
        """处理目录中的所有图像"""
        target_dir = directory or self.images_dir
        
        # 支持的图像扩展名
        supported_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp'}
        
        # 查找所有图像文件
        image_files = [
            f for f in target_dir.rglob('*')
            if f.is_file() and f.suffix.lower() in supported_extensions
        ]
        
        self.images = []
        for image_file in image_files:
            try:
                image_data = self.process_image(image_file)
                self.images.append(image_data)
            except Exception as e:
                logger.error(f"处理图像失败 {image_file.name}: {e}")
        
        return self.images
    
    def process_image(self, image_path: Path) -> ImageData:
        """处理单个图像文件"""
        # OCR提取文本
        ocr_text = self._extract_text_with_ocr(image_path)
        
        image_data = ImageData(
            image_path=image_path,
            ocr_text=ocr_text,
            metadata={
                'file_name': image_path.name,
                'file_size': image_path.stat().st_size,
                'file_hash': get_file_hash(image_path)
            }
        )
        
        return image_data
    
    def _extract_text_with_ocr(self, image_path: Path) -> str:
        """使用Tesseract OCR提取图像中的文本"""
        try:
            image = Image.open(image_path)
            text = pytesseract.image_to_string(
                image,
                lang=config.ocr_language,
                config=config.tesseract_config
            )
            return clean_text(text)
        except Exception as e:
            logger.error(f"OCR识别失败 {image_path.name}: {e}")
            return ""
```

---

## 向量化层 (embedding.py)

### 文本Embedding模型

```python
class TextEmbeddingModel:
    """文本Embedding模型 - 使用DashScope API"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.environ.get("DASHSCOPE_API_KEY")
        if self.api_key:
            dashscope.api_key = self.api_key
        
        self.model_name = config.text_embedding_model
        self.embedding_dim = config.text_embedding_dim
    
    def embed_text(self, text: str) -> List[float]:
        """对单个文本进行向量化"""
        if not text or not text.strip():
            return [0.0] * self.embedding_dim
        
        try:
            resp = TextEmbedding.call(
                model=self.model_name,
                input=text,
                text_type="document"
            )
            
            if resp.status_code == 200:
                return resp.output['embeddings'][0]['embedding']
            else:
                logger.error(f"文本Embedding失败: {resp.message}")
                return [0.0] * self.embedding_dim
                
        except Exception as e:
            logger.error(f"文本Embedding异常: {e}")
            return [0.0] * self.embedding_dim
    
    def embed_texts(self, texts: List[str]) -> List[List[float]]:
        """批量向量化文本"""
        embeddings = []
        for text in texts:
            embedding = self.embed_text(text)
            embeddings.append(embedding)
        return embeddings
    
    def embed_text_chunks(
        self, chunks: List[TextChunk]
    ) -> Tuple[np.ndarray, List[TextChunk]]:
        """对文本块进行向量化"""
        texts = [chunk.text for chunk in chunks]
        embeddings = self.embed_texts(texts)
        
        # 过滤无效embedding
        valid_embeddings = []
        valid_chunks = []
        for i, embedding in enumerate(embeddings):
            if any(v != 0.0 for v in embedding):
                valid_embeddings.append(embedding)
                valid_chunks.append(chunks[i])
        
        return np.array(valid_embeddings, dtype=np.float32), valid_chunks
```

### 图像Embedding模型 (CLIP)

```python
class ImageEmbeddingModel:
    """图像Embedding模型 - 使用CLIP"""
    
    def __init__(self, model_name: Optional[str] = None):
        self.model_name = model_name or config.clip_model_name
        self.embedding_dim = config.image_embedding_dim
        
        # 加载CLIP模型
        self.model = CLIPModel.from_pretrained(f"openai/{self.model_name}")
        self.processor = CLIPProcessor.from_pretrained(f"openai/{self.model_name}")
        
        # 设置评估模式
        self.model.eval()
        
        # 设备选择
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
    
    def embed_image(self, image: Image.Image) -> List[float]:
        """对单个图像进行向量化"""
        try:
            inputs = self.processor(images=image, return_tensors="pt")
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model.get_image_features(**inputs)
                if hasattr(outputs, 'pooler_output'):
                    image_features = outputs.pooler_output
                else:
                    image_features = outputs
            
            # 归一化
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
            
            return image_features.cpu().numpy()[0].tolist()
            
        except Exception as e:
            logger.error(f"图像Embedding异常: {e}")
            return [0.0] * self.embedding_dim
    
    def embed_text_for_image_search(self, text: str) -> List[float]:
        """对文本进行向量化（用于图像搜索 - CLIP跨模态）"""
        try:
            inputs = self.processor(text=[text], return_tensors="pt", padding=True)
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model.get_text_features(**inputs)
                if hasattr(outputs, 'pooler_output'):
                    text_features = outputs.pooler_output
                else:
                    text_features = outputs
            
            # 归一化
            text_features = text_features / text_features.norm(dim=-1, keepdim=True)
            
            return text_features.cpu().numpy()[0].tolist()
            
        except Exception as e:
            logger.error(f"文本Embedding异常: {e}")
            return [0.0] * self.embedding_dim
```

### FAISS索引管理

```python
class FAISSIndex:
    """FAISS索引管理器"""
    
    def __init__(self, embedding_dim: int, index_type: str = "IndexFlatL2"):
        self.embedding_dim = embedding_dim
        self.index_type = index_type
        
        # 创建索引
        if index_type == "IndexFlatL2":
            self.index = faiss.IndexFlatL2(embedding_dim)
        elif index_type == "IndexFlatIP":
            self.index = faiss.IndexFlatIP(embedding_dim)
        elif index_type == "IndexIVFFlat":
            quantizer = faiss.IndexFlatL2(embedding_dim)
            self.index = faiss.IndexIVFFlat(quantizer, embedding_dim, config.nlist)
        
        self.documents = []  # 存储原始文档数据
    
    def add_vectors(self, vectors: np.ndarray, documents: List[Any]):
        """添加向量到索引"""
        if self.index_type == "IndexIVFFlat":
            self.index.train(vectors)
        
        self.index.add(vectors)
        self.documents.extend(documents)
    
    def search(self, query_vector: np.ndarray, k: int = 5) -> List[Tuple[int, float]]:
        """搜索最相似的向量"""
        if self.index.ntotal == 0:
            return []
        
        query_vector = np.array([query_vector], dtype=np.float32)
        distances, indices = self.index.search(query_vector, k)
        
        results = []
        for idx, dist in zip(indices[0], distances[0]):
            if idx != -1:
                results.append((int(idx), float(dist)))
        
        return results
    
    def save(self, index_path: Path, documents_path: Path):
        """保存索引和文档数据"""
        faiss.write_index(self.index, str(index_path))
        save_pickle(self.documents, documents_path)
    
    def load(self, index_path: Path, documents_path: Path):
        """加载索引和文档数据"""
        self.index = faiss.read_index(str(index_path))
        self.documents = load_pickle(documents_path)
```

### 向量存储管理器

```python
class VectorStore:
    """向量存储管理器 - 统一管理文本和图像索引"""
    
    def __init__(self):
        self.text_index: Optional[FAISSIndex] = None
        self.image_index: Optional[FAISSIndex] = None
        self.text_embedding_model: Optional[TextEmbeddingModel] = None
        self.image_embedding_model: Optional[ImageEmbeddingModel] = None
    
    def build_text_index(self, chunks: List[TextChunk]) -> FAISSIndex:
        """构建文本索引"""
        if self.text_embedding_model is None:
            self.text_embedding_model = TextEmbeddingModel()
        
        # 生成向量
        embeddings, valid_chunks = self.text_embedding_model.embed_text_chunks(chunks)
        
        # 创建索引
        self.text_index = FAISSIndex(
            embedding_dim=config.text_embedding_dim,
            index_type=config.index_type
        )
        self.text_index.add_vectors(embeddings, valid_chunks)
        
        return self.text_index
    
    def build_image_index(self, image_data_list: List[ImageData]) -> FAISSIndex:
        """构建图像索引"""
        if self.image_embedding_model is None:
            self.image_embedding_model = ImageEmbeddingModel()
        
        # 生成向量
        embeddings, valid_image_data = self.image_embedding_model.embed_image_data_list(
            image_data_list
        )
        
        # 创建索引
        self.image_index = FAISSIndex(
            embedding_dim=config.image_embedding_dim,
            index_type=config.index_type
        )
        self.image_index.add_vectors(embeddings, valid_image_data)
        
        return self.image_index
    
    def save_indexes(self):
        """保存所有索引"""
        if self.text_index:
            self.text_index.save(
                config.indexes_dir / "text_index.faiss",
                config.indexes_dir / "text_documents.pkl"
            )
        if self.image_index:
            self.image_index.save(
                config.indexes_dir / "image_index.faiss",
                config.indexes_dir / "image_documents.pkl"
            )
    
    def load_indexes(self):
        """加载所有索引"""
        # 加载文本索引
        text_index_path = config.indexes_dir / "text_index.faiss"
        text_docs_path = config.indexes_dir / "text_documents.pkl"
        if text_index_path.exists() and text_docs_path.exists():
            self.text_index = FAISSIndex(config.text_embedding_dim)
            self.text_index.load(text_index_path, text_docs_path)
        
        # 加载图像索引
        image_index_path = config.indexes_dir / "image_index.faiss"
        image_docs_path = config.indexes_dir / "image_documents.pkl"
        if image_index_path.exists() and image_docs_path.exists():
            self.image_index = FAISSIndex(config.image_embedding_dim)
            self.image_index.load(image_index_path, image_docs_path)
```

---

## 检索层 (retrieval.py)

### 检索结果数据类

```python
@dataclass
class RetrievalResult:
    """检索结果数据类"""
    content: str                     # 内容
    source: str                      # 来源
    score: float                     # 相似度分数
    metadata: Dict[str, Any]         # 元数据
    result_type: str = "text"        # 结果类型 (text/image)
    
    def to_dict(self) -> Dict[str, Any]:
        """转换为字典"""
        return {
            "content": self.content,
            "source": self.source,
            "score": self.score,
            "metadata": self.metadata,
            "result_type": self.result_type
        }
```

### 文本检索器

```python
class TextRetriever:
    """文本检索器"""
    
    def __init__(self, vector_store: VectorStore):
        self.vector_store = vector_store
        self.text_index = vector_store.text_index
        self.text_embedding_model = vector_store.text_embedding_model
        
        if self.text_embedding_model is None:
            self.text_embedding_model = TextEmbeddingModel()
    
    def retrieve(
        self, 
        query: str, 
        top_k: Optional[int] = None,
        score_threshold: Optional[float] = None
    ) -> List[RetrievalResult]:
        """检索相关文本"""
        if self.text_index is None or self.text_index.size == 0:
            return []
        
        top_k = top_k or config.top_k
        score_threshold = score_threshold or config.score_threshold
        
        # 生成查询向量
        query_vector = self.text_embedding_model.embed_text(query)
        query_vector_np = np.array(query_vector, dtype=np.float32)
        
        # 搜索
        results = self.text_index.search(query_vector_np, k=top_k)
        
        # 构建结果
        retrieval_results = []
        for idx, distance in results:
            chunk = self.text_index.documents[idx]
            
            # L2距离转相似度
            similarity = 1.0 / (1.0 + distance)
            
            if similarity >= score_threshold:
                result = RetrievalResult(
                    content=chunk.text,
                    source=chunk.source,
                    score=similarity,
                    metadata=chunk.metadata,
                    result_type="text"
                )
                retrieval_results.append(result)
        
        return retrieval_results
```

### 图像检索器

```python
class ImageRetriever:
    """图像检索器"""
    
    def __init__(self, vector_store: VectorStore):
        self.vector_store = vector_store
        self.image_index = vector_store.image_index
        self.image_embedding_model = vector_store.image_embedding_model
        
        if self.image_embedding_model is None:
            self.image_embedding_model = ImageEmbeddingModel()
    
    def retrieve_by_text(
        self, 
        query: str, 
        top_k: Optional[int] = None,
        score_threshold: Optional[float] = None
    ) -> List[RetrievalResult]:
        """通过文本查询检索图像（跨模态检索）"""
        if self.image_index is None or self.image_index.size == 0:
            return []
        
        top_k = top_k or config.top_k
        score_threshold = score_threshold or config.score_threshold
        
        # 使用CLIP文本编码器
        query_vector = self.image_embedding_model.embed_text_for_image_search(query)
        query_vector_np = np.array(query_vector, dtype=np.float32)
        
        # 搜索
        results = self.image_index.search(query_vector_np, k=top_k)
        
        # 构建结果
        retrieval_results = []
        for idx, distance in results:
            image_data = self.image_index.documents[idx]
            similarity = 1.0 / (1.0 + distance)
            
            if similarity >= score_threshold:
                content = image_data.ocr_text or f"图像: {image_data.image_path.name}"
                result = RetrievalResult(
                    content=content,
                    source=str(image_data.image_path),
                    score=similarity,
                    metadata=image_data.metadata,
                    result_type="image"
                )
                retrieval_results.append(result)
        
        return retrieval_results
```

### 混合检索器

```python
class HybridRetriever:
    """混合检索器 - 同时支持文本和图像检索"""
    
    def __init__(self, vector_store: VectorStore):
        self.vector_store = vector_store
        self.text_retriever = TextRetriever(vector_store)
        self.image_retriever = ImageRetriever(vector_store)
        self.image_keywords = config.image_keywords
    
    def _should_trigger_image_search(self, query: str) -> bool:
        """检测是否应该触发图像检索"""
        query_lower = query.lower()
        for keyword in self.image_keywords:
            if keyword.lower() in query_lower:
                return True
        return False
    
    def retrieve(
        self, 
        query: str, 
        top_k: Optional[int] = None,
        score_threshold: Optional[float] = None,
        force_image_search: bool = False
    ) -> Dict[str, List[RetrievalResult]]:
        """混合检索"""
        results = {"text": [], "image": []}
        
        # 文本检索（始终执行）
        text_results = self.text_retriever.retrieve(
            query=query, top_k=top_k, score_threshold=score_threshold
        )
        results["text"] = text_results
        
        # 图像检索（关键词触发或强制）
        if force_image_search or self._should_trigger_image_search(query):
            image_results = self.image_retriever.retrieve_by_text(
                query=query, top_k=top_k, score_threshold=score_threshold
            )
            results["image"] = image_results
        
        return results
```

---

## 生成层 (generator.py)

### 提示词构建器

```python
class PromptBuilder:
    """提示词构建器"""
    
    def __init__(self):
        self.system_prompt = """你是一个专业的迪士尼知识问答助手，能够基于提供的文档和图像信息回答用户的问题。

你的职责：
1. 基于提供的上下文信息准确回答用户问题
2. 如果上下文中没有相关信息，明确说明你不知道
3. 回答要清晰、简洁、准确
4. 对于图像相关信息，可以描述图像内容
5. 保持专业和友好的态度
"""
    
    def build_context(self, results: Dict[str, List[RetrievalResult]]) -> str:
        """构建上下文文本"""
        context_parts = []
        
        # 文本上下文
        if results.get("text"):
            context_parts.append("【相关文档信息】")
            for i, result in enumerate(results["text"], 1):
                context_parts.append(
                    f"文档{i} (来源: {result.source}, 相似度: {result.score:.3f}):\n"
                    f"{result.content}"
                )
        
        # 图像上下文
        if results.get("image"):
            context_parts.append("\n【相关图像信息】")
            for i, result in enumerate(results["image"], 1):
                context_parts.append(
                    f"图像{i} (来源: {result.source}, 相似度: {result.score:.3f}):\n"
                    f"{result.content}"
                )
        
        return "\n".join(context_parts)
    
    def build_stream_prompt(
        self, 
        query: str, 
        results: Dict[str, List[RetrievalResult]]
    ) -> Dict[str, str]:
        """构建流式提示词"""
        context = self.build_context(results)
        if not context:
            context = "没有找到相关的文档或图像信息。"
        
        return {
            "system": self.system_prompt,
            "user": f"""上下文信息：
{context}

用户问题：{query}

请基于以上信息回答用户问题。"""
        }
```

### 答案生成器

```python
class AnswerGenerator:
    """答案生成器"""
    
    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None):
        self.api_key = api_key or os.environ.get("DASHSCOPE_API_KEY")
        self.model = model or config.llm_model
        
        # OpenAI兼容客户端
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )
        
        self.prompt_builder = PromptBuilder()
    
    def generate(
        self, 
        query: str, 
        results: Dict[str, List[RetrievalResult]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> str:
        """生成答案"""
        temperature = temperature or config.llm_temperature
        max_tokens = max_tokens or config.llm_max_tokens
        
        # 构建提示词
        prompt_dict = self.prompt_builder.build_stream_prompt(query, results)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": prompt_dict["system"]},
                    {"role": "user", "content": prompt_dict["user"]}
                ],
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"答案生成失败: {e}")
            return "抱歉，生成答案时出现了错误。"
    
    def generate_stream(
        self, 
        query: str, 
        results: Dict[str, List[RetrievalResult]],
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ):
        """流式生成答案"""
        temperature = temperature or config.llm_temperature
        max_tokens = max_tokens or config.llm_max_tokens
        
        prompt_dict = self.prompt_builder.build_stream_prompt(query, results)
        
        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": prompt_dict["system"]},
                    {"role": "user", "content": prompt_dict["user"]}
                ],
                temperature=temperature,
                max_tokens=max_tokens,
                stream=True
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
                    
        except Exception as e:
            logger.error(f"流式生成失败: {e}")
            yield "抱歉，生成答案时出现了错误。"
```

### RAG管道

```python
class RAGPipeline:
    """RAG流程管道 - 串联检索和生成"""
    
    def __init__(self, retriever: HybridRetriever, generator: Optional[AnswerGenerator] = None):
        self.retriever = retriever
        self.generator = generator or AnswerGenerator()
        self.prompt_builder = PromptBuilder()
    
    def query(
        self, 
        question: str,
        top_k: Optional[int] = None,
        score_threshold: Optional[float] = None,
        return_retrieval_results: bool = False
    ) -> Dict[str, Any]:
        """执行RAG查询"""
        # Step 1: 检索
        retrieval_results = self.retriever.retrieve(
            query=question,
            top_k=top_k,
            score_threshold=score_threshold
        )
        
        # Step 2: 构建上下文
        context = self.prompt_builder.build_context(retrieval_results)
        
        # Step 3: 生成答案
        answer = self.generator.generate(
            query=question,
            results=retrieval_results
        )
        
        result = {
            "answer": answer,
            "context": context,
            "question": question
        }
        
        if return_retrieval_results:
            result["retrieval_results"] = retrieval_results
        
        return result
    
    def query_stream(self, question: str, **kwargs):
        """流式执行RAG查询"""
        retrieval_results = self.retriever.retrieve(query=question, **kwargs)
        
        for chunk in self.generator.generate_stream(
            query=question,
            results=retrieval_results
        ):
            yield chunk
    
    def format_response(self, result: Dict[str, Any]) -> str:
        """格式化响应"""
        formatted = []
        formatted.append(f"问题: {result['question']}")
        formatted.append(f"\n答案:\n{result['answer']}")
        
        if result.get('context') and result['context'].strip():
            formatted.append(f"\n\n参考上下文:\n{result['context']}")
        
        return "\n".join(formatted)
```

---

## 主程序 (main.py)

### 命令行接口

```python
def main():
    """主函数"""
    parser = argparse.ArgumentParser(
        description="Disney RAG问答助手",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('--build', action='store_true', help='构建索引')
    parser.add_argument('--build-text-only', action='store_true', help='仅构建文本索引')
    parser.add_argument('--interactive', '-i', action='store_true', help='交互式问答')
    parser.add_argument('--query', '-q', type=str, help='单次查询')
    
    args = parser.parse_args()
    
    # 加载环境变量
    load_env_config()
    
    # 执行命令
    if args.build:
        build_indexes(skip_images=False)
    elif args.build_text_only:
        build_indexes(skip_images=True)
    elif args.interactive:
        interactive_mode()
    elif args.query:
        single_query(args.query)
    else:
        interactive_mode()  # 默认交互模式
```

### 核心函数

```python
def build_indexes(skip_images: bool = False):
    """构建索引"""
    logger.info("开始构建索引")
    
    vector_store = VectorStore()
    
    # 处理文档
    doc_processor = DocumentProcessor()
    chunks = doc_processor.process_directory()
    if chunks:
        vector_store.build_text_index(chunks)
    
    # 处理图像
    if not skip_images:
        try:
            img_processor = ImageProcessor()
            images = img_processor.process_directory()
            if images:
                vector_store.build_image_index(images)
        except Exception as e:
            logger.warning(f"图像处理失败: {e}")
    
    # 保存索引
    vector_store.save_indexes()
    logger.info("索引构建完成")

def interactive_mode():
    """交互式问答模式"""
    vector_store = VectorStore()
    vector_store.load_indexes()
    
    retriever = HybridRetriever(vector_store)
    generator = AnswerGenerator()
    rag_pipeline = RAGPipeline(retriever, generator)
    
    while True:
        question = input("\n请输入您的问题: ").strip()
        
        if question.lower() in ['quit', 'exit', '退出']:
            break
        
        result = rag_pipeline.query(question, return_retrieval_results=True)
        print(rag_pipeline.format_response(result))
```

---

*最后更新: 2026年2月15日*
*文档版本: v1.0*
