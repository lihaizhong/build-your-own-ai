# Cursorç¼–ç¨‹ä»å…¥é—¨åˆ°ç²¾é€š - æµ‹è¯•å’Œéƒ¨ç½²

## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

#### æ•°æ®å¤„ç†æ¨¡å—æµ‹è¯•

```python
import unittest
import pandas as pd
from pathlib import Path
from unittest.mock import Mock, patch


class TestDataProcessing(unittest.TestCase):
    """æ•°æ®å¤„ç†æ¨¡å—çš„å•å…ƒæµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.test_data_dir = Path("test_data")
        self.test_data_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.create_test_data()
    
    def create_test_data(self):
        """åˆ›å»ºæµ‹è¯•æ•°æ®æ–‡ä»¶"""
        # åˆ›å»ºå‘˜å·¥åŸºæœ¬ä¿¡æ¯æµ‹è¯•æ•°æ®
        employee_data = {
            'å‘˜å·¥ç¼–å·': ['E001', 'E002', 'E003'],
            'å§“å': ['å¼ ä¸‰', 'æå››', 'ç‹äº”'],
            'éƒ¨é—¨': ['æŠ€æœ¯éƒ¨', 'äººäº‹éƒ¨', 'æŠ€æœ¯éƒ¨']
        }
        pd.DataFrame(employee_data).to_excel(
            self.test_data_dir / "å‘˜å·¥åŸºæœ¬ä¿¡æ¯è¡¨.xlsx",
            index=False
        )
        
        # åˆ›å»ºå‘˜å·¥ç»©æ•ˆæµ‹è¯•æ•°æ®
        performance_data = {
            'å‘˜å·¥ç¼–å·': ['E001', 'E002', 'E003'],
            'ç»¼åˆå¾—åˆ†': [85, 90, 78],
            'ç»©æ•ˆç­‰çº§': ['B', 'A', 'C']
        }
        pd.DataFrame(performance_data).to_excel(
            self.test_data_dir / "å‘˜å·¥ç»©æ•ˆè¡¨.xlsx",
            index=False
        )
    
    def test_read_excel(self):
        """æµ‹è¯•Excelè¯»å–åŠŸèƒ½"""
        from code.è¯»å–å‘˜å·¥ä¿¡æ¯è¡¨ import read_employee_excel
        
        # ä¿®æ”¹è·¯å¾„ä¸ºæµ‹è¯•ç›®å½•
        result = read_employee_excel()
        
        self.assertIsNotNone(result)
        self.assertIn('å‘˜å·¥ç¼–å·', result.columns)
        self.assertIn('å§“å', result.columns)
    
    def test_merge_data(self):
        """æµ‹è¯•æ•°æ®åˆå¹¶åŠŸèƒ½"""
        # è¯»å–æµ‹è¯•æ•°æ®
        info_df = pd.read_excel(self.test_data_dir / "å‘˜å·¥åŸºæœ¬ä¿¡æ¯è¡¨.xlsx")
        perf_df = pd.read_excel(self.test_data_dir / "å‘˜å·¥ç»©æ•ˆè¡¨.xlsx")
        
        # æ‰§è¡Œåˆå¹¶
        merged_df = pd.merge(
            info_df, 
            perf_df, 
            on='å‘˜å·¥ç¼–å·', 
            how='left'
        )
        
        # éªŒè¯ç»“æœ
        self.assertEqual(len(merged_df), 3)
        self.assertIn('ç»¼åˆå¾—åˆ†', merged_df.columns)
        self.assertIn('ç»©æ•ˆç­‰çº§', merged_df.columns)
    
    def test_data_validation(self):
        """æµ‹è¯•æ•°æ®éªŒè¯åŠŸèƒ½"""
        df = pd.read_excel(self.test_data_dir / "å‘˜å·¥åŸºæœ¬ä¿¡æ¯è¡¨.xlsx")
        
        # éªŒè¯å¿…éœ€åˆ—å­˜åœ¨
        required_columns = ['å‘˜å·¥ç¼–å·', 'å§“å', 'éƒ¨é—¨']
        for col in required_columns:
            self.assertIn(col, df.columns)
        
        # éªŒè¯å‘˜å·¥ç¼–å·å”¯ä¸€æ€§
        self.assertFalse(df['å‘˜å·¥ç¼–å·'].duplicated().any())
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        import shutil
        if self.test_data_dir.exists():
            shutil.rmtree(self.test_data_dir)


class TestCovidDataProcessor(unittest.TestCase):
    """ç–«æƒ…æ•°æ®å¤„ç†å™¨æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.processor = CovidDataProcessor()
    
    def test_get_daily_summary(self):
        """æµ‹è¯•æ¯æ—¥æ±‡æ€»æ•°æ®è·å–"""
        summary = self.processor.get_daily_summary()
        
        self.assertIn('dates', summary)
        self.assertIn('new_cases', summary)
        self.assertIn('total_cases', summary)
    
    def test_get_district_distribution(self):
        """æµ‹è¯•åŒºåŸŸåˆ†å¸ƒæ•°æ®è·å–"""
        distribution = self.processor.get_district_distribution()
        
        self.assertIsInstance(distribution, list)
        if len(distribution) > 0:
            self.assertIn('name', distribution[0])
            self.assertIn('value', distribution[0])


class TestHospitalBedDataProcessor(unittest.TestCase):
    """åŒ»é™¢ç—…åºŠæ•°æ®å¤„ç†å™¨æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.processor = HospitalBedDataProcessor()
    
    def test_get_key_indicators(self):
        """æµ‹è¯•å…³é”®æŒ‡æ ‡è·å–"""
        indicators = self.processor.get_key_indicators()
        
        self.assertIn('total_beds', indicators)
        self.assertIn('occupied_beds', indicators)
        self.assertIn('occupancy_rate', indicators)
    
    def test_occupancy_rate_calculation(self):
        """æµ‹è¯•å ç”¨ç‡è®¡ç®—"""
        indicators = self.processor.get_key_indicators()
        
        expected_rate = round(
            indicators['occupied_beds'] / indicators['total_beds'] * 100, 1
        )
        self.assertEqual(indicators['occupancy_rate'], expected_rate)


if __name__ == '__main__':
    unittest.main(verbosity=2)
```

### 2. é›†æˆæµ‹è¯•

#### ç«¯åˆ°ç«¯æµ‹è¯•

```python
import pytest
import requests
import subprocess
import time


class TestEndToEnd:
    """ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    @pytest.fixture(scope="class")
    def flask_server(self):
        """å¯åŠ¨Flaskæµ‹è¯•æœåŠ¡å™¨"""
        # å¯åŠ¨æœåŠ¡å™¨
        process = subprocess.Popen(
            ["python", "code/ç–«æƒ…å¯è§†åŒ–å¤§å±.py"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
        time.sleep(3)
        
        yield process
        
        # å…³é—­æœåŠ¡å™¨
        process.terminate()
        process.wait()
    
    def test_home_page(self, flask_server):
        """æµ‹è¯•ä¸»é¡µè®¿é—®"""
        response = requests.get("http://localhost:5001/")
        assert response.status_code == 200
        assert "é¦™æ¸¯ç–«æƒ…æ•°æ®å¯è§†åŒ–å¤§å±" in response.text
    
    def test_daily_summary_api(self, flask_server):
        """æµ‹è¯•æ¯æ—¥æ±‡æ€»API"""
        response = requests.get("http://localhost:5001/api/daily_summary")
        assert response.status_code == 200
        
        data = response.json()
        assert "dates" in data
        assert "new_cases" in data
    
    def test_district_distribution_api(self, flask_server):
        """æµ‹è¯•åŒºåŸŸåˆ†å¸ƒAPI"""
        response = requests.get("http://localhost:5001/api/district_distribution")
        assert response.status_code == 200
        
        data = response.json()
        assert isinstance(data, list)
    
    def test_key_indicators_api(self, flask_server):
        """æµ‹è¯•å…³é”®æŒ‡æ ‡API"""
        response = requests.get("http://localhost:5001/api/key_indicators")
        assert response.status_code == 200
        
        data = response.json()
        assert "total_new" in data
        assert "recovery_rate" in data
```

### 3. æ€§èƒ½æµ‹è¯•

#### å‹åŠ›æµ‹è¯•

```python
import time
import asyncio
import aiohttp


class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""
    
    def test_data_loading_performance(self):
        """æµ‹è¯•æ•°æ®åŠ è½½æ€§èƒ½"""
        start_time = time.time()
        
        # åŠ è½½æ•°æ®
        processor = CovidDataProcessor()
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"æ•°æ®åŠ è½½è€—æ—¶: {duration:.2f}ç§’")
        assert duration < 5.0  # åº”åœ¨5ç§’å†…å®Œæˆ
    
    def test_api_response_time(self):
        """æµ‹è¯•APIå“åº”æ—¶é—´"""
        import requests
        
        endpoints = [
            "/api/daily_summary",
            "/api/district_distribution",
            "/api/key_indicators"
        ]
        
        for endpoint in endpoints:
            start_time = time.time()
            response = requests.get(f"http://localhost:5001{endpoint}")
            end_time = time.time()
            
            duration = (end_time - start_time) * 1000  # æ¯«ç§’
            print(f"{endpoint}: {duration:.2f}ms")
            
            assert response.status_code == 200
            assert duration < 1000  # åº”åœ¨1ç§’å†…å“åº”
    
    @pytest.mark.asyncio
    async def test_concurrent_requests(self):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚æ€§èƒ½"""
        async def make_request(session, url):
            async with session.get(url) as response:
                return await response.json()
        
        async with aiohttp.ClientSession() as session:
            tasks = [
                make_request(session, "http://localhost:5001/api/daily_summary")
                for _ in range(10)
            ]
            
            start_time = time.time()
            results = await asyncio.gather(*tasks)
            end_time = time.time()
            
            duration = end_time - start_time
            print(f"10ä¸ªå¹¶å‘è¯·æ±‚è€—æ—¶: {duration:.2f}ç§’")
            
            assert len(results) == 10
```

## éƒ¨ç½²ç­–ç•¥

### 1. å¼€å‘ç¯å¢ƒéƒ¨ç½²

#### Dockerå®¹å™¨åŒ–éƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /app/data /app/user_data

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV FLASK_APP=code/ç–«æƒ…å¯è§†åŒ–å¤§å±.py

# æš´éœ²ç«¯å£
EXPOSE 5001

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:5001/ || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["python", "code/ç–«æƒ…å¯è§†åŒ–å¤§å±.py"]
```

#### Docker Composeé…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  epidemic-dashboard:
    build: .
    container_name: epidemic-dashboard
    volumes:
      - ./data:/app/data
      - ./user_data:/app/user_data
    environment:
      - FLASK_DEBUG=1
    ports:
      - "5001:5001"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/"]
      interval: 30s
      timeout: 10s
      retries: 3

  hospital-dashboard:
    build: .
    container_name: hospital-dashboard
    volumes:
      - ./data:/app/data
    environment:
      - FLASK_DEBUG=1
    ports:
      - "5002:5002"
    restart: unless-stopped
    command: ["python", "code/åŒ»é™¢ç—…åºŠå¯è§†åŒ–å¤§å±.py"]
```

### 2. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### Gunicornéƒ¨ç½²

```python
# gunicorn.conf.py
import multiprocessing

# ç»‘å®šåœ°å€
bind = "0.0.0.0:5001"

# å·¥ä½œè¿›ç¨‹æ•°
workers = multiprocessing.cpu_count() * 2 + 1

# å·¥ä½œæ¨¡å¼
worker_class = "sync"

# è¶…æ—¶æ—¶é—´
timeout = 120

# æ—¥å¿—é…ç½®
accesslog = "/var/log/gunicorn/access.log"
errorlog = "/var/log/gunicorn/error.log"
loglevel = "info"
```

#### Nginxé…ç½®

```nginx
# nginx.conf
upstream epidemic_dashboard {
    server 127.0.0.1:5001;
}

upstream hospital_dashboard {
    server 127.0.0.1:5002;
}

server {
    listen 80;
    server_name dashboard.example.com;

    # ç–«æƒ…å¤§å±
    location /epidemic/ {
        proxy_pass http://epidemic_dashboard/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    # åŒ»é™¢å¤§å±
    location /hospital/ {
        proxy_pass http://hospital_dashboard/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }

    # é™æ€æ–‡ä»¶ç¼“å­˜
    location ~* \.(js|css|png|jpg|jpeg|gif|ico)$ {
        expires 1d;
        add_header Cache-Control "public, immutable";
    }
}
```

#### SystemdæœåŠ¡é…ç½®

```ini
# /etc/systemd/system/epidemic-dashboard.service
[Unit]
Description=Epidemic Data Visualization Dashboard
After=network.target

[Service]
User=www-data
Group=www-data
WorkingDirectory=/opt/cursor-programming
ExecStart=/opt/cursor-programming/.venv/bin/gunicorn \
    -c gunicorn.conf.py \
    code.ç–«æƒ…å¯è§†åŒ–å¤§å±:app
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
```

### 3. ç›‘æ§å’Œæ—¥å¿—

#### Prometheusç›‘æ§é…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'flask-dashboard'
    static_configs:
      - targets: ['localhost:5001', 'localhost:5002']
```

#### æ—¥å¿—é…ç½®

```python
# logging_config.py
import logging
import logging.config

LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'standard': {
            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        },
    },
    'handlers': {
        'console': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'standard',
        },
        'file': {
            'level': 'INFO',
            'class': 'logging.handlers.RotatingFileHandler',
            'formatter': 'standard',
            'filename': '/var/log/dashboard/app.log',
            'maxBytes': 10485760,
            'backupCount': 5
        }
    },
    'loggers': {
        '': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
        }
    }
}

def setup_logging():
    logging.config.dictConfig(LOGGING_CONFIG)
```

### 4. CI/CDæµæ°´çº¿

#### GitHub Actionsé…ç½®

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11, 3.12]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8
    
    - name: Lint with flake8
      run: |
        flake8 code/ --count --select=E9,F63,F7,F82 --show-source --statistics
    
    - name: Run tests
      run: |
        pytest tests/ --cov=code --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: |
        docker build -t cursor-dashboard:${{ github.sha }} .
        docker tag cursor-dashboard:${{ github.sha }} cursor-dashboard:latest
    
    - name: Push to registry
      run: |
        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
        docker push cursor-dashboard:${{ github.sha }}
        docker push cursor-dashboard:latest

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Deploy to production
      run: |
        # éƒ¨ç½²è„šæœ¬
        echo "Deploying to production..."
```

## éƒ¨ç½²éªŒè¯

### 1. éƒ¨ç½²åéªŒè¯è„šæœ¬

```python
# deployment_validator.py
import requests
import time
import logging

logger = logging.getLogger(__name__)

def validate_deployment(base_url: str, timeout: int = 60):
    """éªŒè¯éƒ¨ç½²æ˜¯å¦æˆåŠŸ"""
    
    # 1. å¥åº·æ£€æŸ¥
    try:
        response = requests.get(f"{base_url}/", timeout=5)
        if response.status_code == 200:
            logger.info("âœ… ä¸»é¡µè®¿é—®æˆåŠŸ")
        else:
            logger.error(f"âŒ ä¸»é¡µè®¿é—®å¤±è´¥: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"âŒ è¿æ¥å¤±è´¥: {e}")
        return False
    
    # 2. APIæµ‹è¯•
    endpoints = [
        "/api/daily_summary",
        "/api/district_distribution",
        "/api/key_indicators"
    ]
    
    for endpoint in endpoints:
        try:
            response = requests.get(f"{base_url}{endpoint}", timeout=10)
            if response.status_code == 200:
                logger.info(f"âœ… API {endpoint} æ­£å¸¸")
            else:
                logger.error(f"âŒ API {endpoint} å¤±è´¥")
                return False
        except Exception as e:
            logger.error(f"âŒ API {endpoint} å¼‚å¸¸: {e}")
            return False
    
    logger.info("ğŸ‰ éƒ¨ç½²éªŒè¯å…¨éƒ¨é€šè¿‡")
    return True

def wait_for_deployment(base_url: str, max_wait_time: int = 300):
    """ç­‰å¾…éƒ¨ç½²å®Œæˆ"""
    start_time = time.time()
    
    while time.time() - start_time < max_wait_time:
        if validate_deployment(base_url):
            return True
        logger.info("ç­‰å¾…éƒ¨ç½²å®Œæˆ...")
        time.sleep(10)
    
    logger.error("éƒ¨ç½²éªŒè¯è¶…æ—¶")
    return False
```

### 2. å›æ»šç­–ç•¥

```bash
#!/bin/bash
# rollback.sh

# è·å–ä¸Šä¸€ä¸ªç‰ˆæœ¬
PREVIOUS_VERSION=$(docker images cursor-dashboard --format "{{.Tag}}" | head -2 | tail -1)

echo "å›æ»šåˆ°ç‰ˆæœ¬: $PREVIOUS_VERSION"

# åœæ­¢å½“å‰å®¹å™¨
docker stop epidemic-dashboard
docker rm epidemic-dashboard

# å¯åŠ¨ä¸Šä¸€ç‰ˆæœ¬
docker run -d \
    --name epidemic-dashboard \
    -p 5001:5001 \
    cursor-dashboard:$PREVIOUS_VERSION

echo "å›æ»šå®Œæˆ"
```

---

*æœ€åæ›´æ–°: 2026å¹´2æœˆ21æ—¥*
*æµ‹è¯•å’Œéƒ¨ç½²ç‰ˆæœ¬: v1.0*
*è¿ç»´å›¢é˜Ÿ: DevOpsè¿ç»´ç»„*
