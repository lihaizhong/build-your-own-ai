# 员工离职预测分析项目 - 使用指南

## 环境准备

### 1. 系统要求
- **操作系统**: Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **Python版本**: 3.11+
- **内存**: 最小4GB，推荐8GB+
- **存储空间**: 最小1GB，推荐2GB+

### 2. 依赖安装

#### 方式一：使用uv（推荐）
```bash
# 进入项目目录
cd practice/09-CASE-员工离职预测分析-P1

# 创建虚拟环境
uv venv --python 3.11

# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# 或
.venv\Scripts\activate     # Windows

# 安装依赖
uv sync

# 运行数据检查
uv run python code/check.py
```

#### 方式二：使用pip
```bash
# 创建虚拟环境
python -m venv .venv

# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# 或
.venv\Scripts\activate     # Windows

# 安装依赖
pip install pandas numpy matplotlib seaborn scikit-learn

# 运行数据检查
python code/check.py
```

### 3. 项目依赖

```
pandas>=2.0.0
numpy>=1.24.0
matplotlib>=3.7.0
seaborn>=0.12.0
scikit-learn>=1.3.0
```

可选依赖（用于高级模型）：
```
xgboost>=2.0.0
lightgbm>=4.0.0
imbalanced-learn>=0.11.0
```

## 快速开始

### 1. 数据快速检查

#### 运行数据检查脚本
```bash
# 激活虚拟环境
source .venv/bin/activate

# 运行快速检查
uv run python code/check.py
```

#### 预期输出
```
员工离职预测数据快速检查
============================================================

训练集信息:
  形状: 1177 行 × 35 列
  列名: ['user_id', 'Age', 'Attrition', 'BusinessTravel', 'DailyRate', ...]
  目标变量 'Attrition' 分布:
  No     987
  Yes    190
  Name: Attrition, dtype: int64
  比例:
  No     0.839
  Yes    0.161
  Name: Attrition, dtype: float64

测试集信息:
  形状: XXX 行 × 34 列
  是否包含目标变量: False

训练集缺失值检查:
  无缺失值

训练集数据类型分布:
  int64     23
  object    10
  float64    2
  dtype: int64

数值特征数量: 25
重要数值特征示例:
  ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EmployeeNumber', ...]

分类特征数量: 10
分类特征:
  ['Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender', ...]

数据质量总结:
1. 数据完整，无缺失值
2. 目标变量存在类别不平衡（需要验证）
3. 包含数值和分类特征混合
4. 特征数量较多，适合机器学习建模

建议下一步操作:
1. 深入EDA（探索性数据分析）
2. 特征工程：创建新特征，编码分类变量
3. 数据预处理：标准化/归一化数值特征
4. 建立基线模型（如逻辑回归、随机森林）
5. 模型评估与优化
```

### 2. 数据探索性分析

#### 运行EDA脚本
```bash
# 激活虚拟环境
source .venv/bin/activate

# 运行EDA分析
uv run python code/eda.py
```

#### 预期输出
```
员工离职预测数据探索性分析 (EDA)
============================================================

============================================================
训练集基本信息
============================================================
形状: 1177 行 × 35 列

列名:
 1. user_id
 2. Age
 3. Attrition
 4. BusinessTravel
 5. DailyRate
 ...

数据类型:
int64     23
object    10
float64    2
dtype: int64

前5行数据:
   user_id  Age Attrition     BusinessTravel  ...  YearsWithCurrManager
0     1374   58        No    Travel_Rarely    ...                    0
1     1092   45        No    Travel_Rarely    ...                    3
...

缺失值统计:
  无缺失值

============================================================
目标变量分析
============================================================
目标变量 'Attrition' 分布:
  No: 987 (83.86%)
  Yes: 190 (16.14%)

[显示目标变量分布图表]

============================================================
数值特征分析
============================================================
数值特征数量: 25
数值特征: ['user_id', 'Age', 'DailyRate', ...]

数值特征描述性统计:
                    count    mean     std   min   25%   50%    75%    max
Age               1177.0   36.94    9.14  18.0  30.0  36.0   43.0   60.0
DailyRate         1177.0  802.49  403.13 103.0 465.0 804.0 1156.0 1499.0
...

[显示相关性热图]

============================================================
分类特征分析
============================================================
分类特征数量: 10
分类特征: ['Attrition', 'BusinessTravel', 'Department', ...]

特征 'BusinessTravel' 的分布:
  唯一值数量: 3
  Travel_Rarely: 714 (60.66%)
  Travel_Frequently: 278 (23.62%)
  Non-Travel: 185 (15.72%)

...

============================================================
特征与目标变量关系分析
============================================================

特征 'BusinessTravel' 与 'Attrition' 的关系:
Attrition               No        Yes
BusinessTravel                      
Non-Travel        0.918919  0.081081
Travel_Frequently 0.755396  0.244604
Travel_Rarely     0.856583  0.143417

[显示特征与目标关系图表]

============================================================
数据质量总结
============================================================
1. 训练集大小: (1177, 35)
2. 测试集大小: (XXX, 34)
3. 目标变量分布:
   - 离职 (Yes): 190
   - 未离职 (No): 987
4. 建议下一步:
   - 特征工程: 创建新特征，如工作满意度综合评分
   - 数据预处理: 编码分类变量，标准化数值特征
   - 建模: 尝试逻辑回归、随机森林、XGBoost等算法
   - 评估: 使用交叉验证和ROC曲线评估模型性能
```

## 数据探索

### 1. 基本信息分析

```python
import pandas as pd
from pathlib import Path

# 加载数据
data_dir = Path("data")
train_df = pd.read_csv(data_dir / "train.csv")
test_df = pd.read_csv(data_dir / "test.csv")

# 基本信息
print(f"训练集形状: {train_df.shape}")
print(f"测试集形状: {test_df.shape}")

# 数据类型
print("\n数据类型分布:")
print(train_df.dtypes.value_counts())

# 缺失值检查
missing = train_df.isnull().sum()
print(f"\n缺失值数量: {missing.sum()}")
```

### 2. 目标变量分析

```python
# 目标变量分布
target_counts = train_df['Attrition'].value_counts()
print("目标变量分布:")
print(target_counts)
print(f"\n离职比例: {target_counts['Yes'] / len(train_df) * 100:.2f}%")

# 可视化
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
target_counts.plot(kind='bar', color=['skyblue', 'salmon'])
plt.title('离职分布')
plt.xlabel('Attrition')
plt.ylabel('数量')
plt.xticks(rotation=0)

plt.subplot(1, 2, 2)
plt.pie(target_counts.values, labels=target_counts.index, 
        autopct='%1.1f%%', colors=['lightblue', 'lightcoral'])
plt.title('离职占比')

plt.tight_layout()
plt.savefig('docs/target_distribution.png', dpi=300, bbox_inches='tight')
plt.show()
```

### 3. 特征相关性分析

```python
import numpy as np

# 获取数值特征
numeric_cols = train_df.select_dtypes(include=[np.number]).columns
numeric_cols = [col for col in numeric_cols if col not in ['user_id', 'EmployeeNumber', 'EmployeeCount', 'StandardHours']]

# 相关性矩阵
correlation = train_df[numeric_cols].corr()

# 相关性热图
plt.figure(figsize=(14, 12))
sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', 
           center=0, square=True, linewidths=0.5)
plt.title('数值特征相关性热图')
plt.tight_layout()
plt.savefig('docs/numeric_correlation.png', dpi=300, bbox_inches='tight')
plt.show()

# 与目标变量相关性最高的特征
if 'Attrition' in train_df.columns:
    # 编码目标变量
    train_df['Attrition_encoded'] = (train_df['Attrition'] == 'Yes').astype(int)
    
    # 计算相关性
    target_corr = train_df[numeric_cols].corrwith(train_df['Attrition_encoded']).abs()
    target_corr = target_corr.sort_values(ascending=False)
    
    print("\n与离职最相关的特征（Top 10）:")
    print(target_corr.head(10))
```

### 4. 分类特征分析

```python
# 分类特征列表
categorical_cols = train_df.select_dtypes(include=['object']).columns
categorical_cols = [col for col in categorical_cols if col != 'Attrition']

# 分析每个分类特征
for col in categorical_cols[:5]:  # 分析前5个
    print(f"\n特征 '{col}' 分析:")
    print(f"唯一值数量: {train_df[col].nunique()}")
    print(f"值分布:")
    print(train_df[col].value_counts())
    
    # 与目标变量的关系
    cross_tab = pd.crosstab(train_df[col], train_df['Attrition'], normalize='index') * 100
    print(f"\n各分类的离职率:")
    print(cross_tab['Yes'].round(2))
```

## 特征工程

### 1. 数据预处理

```python
from sklearn.preprocessing import LabelEncoder, StandardScaler

# 删除无用特征
useless_cols = ['EmployeeCount', 'StandardHours', 'EmployeeNumber', 'Over18', 'user_id']
train_processed = train_df.drop(columns=useless_cols, errors='ignore')

# 分离特征和目标
X = train_processed.drop('Attrition', axis=1)
y = train_processed['Attrition']

# 编码目标变量
y_encoded = (y == 'Yes').astype(int)
```

### 2. 分类特征编码

```python
# 获取分类特征列
categorical_cols = X.select_dtypes(include=['object']).columns.tolist()

# 使用独热编码
X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

print(f"编码后特征数量: {X_encoded.shape[1]}")
```

### 3. 特征缩放

```python
from sklearn.preprocessing import StandardScaler

# 标准化数值特征
numeric_cols = X_encoded.select_dtypes(include=[np.number]).columns.tolist()

scaler = StandardScaler()
X_scaled = X_encoded.copy()
X_scaled[numeric_cols] = scaler.fit_transform(X_encoded[numeric_cols])

print("特征标准化完成")
```

### 4. 创建新特征

```python
def create_features(df):
    """创建新特征"""
    
    # 工作稳定性指标
    df['JobStability'] = df['YearsAtCompany'] / (df['TotalWorkingYears'] + 1)
    
    # 满意度综合评分
    df['SatisfactionScore'] = (
        df['JobSatisfaction'] + 
        df['EnvironmentSatisfaction'] + 
        df['RelationshipSatisfaction'] + 
        df['WorkLifeBalance']
    ) / 4
    
    # 薪资相对水平（相对于同级别平均薪资）
    df['IncomeRatio'] = df['MonthlyIncome'] / df.groupby('JobLevel')['MonthlyIncome'].transform('mean')
    
    # 职业发展停滞指标
    df['CareerStagnation'] = df['YearsSinceLastPromotion'] / (df['YearsAtCompany'] + 1)
    
    # 加班和出差综合指标
    df['WorkIntensity'] = df['OverTime'].map({'Yes': 1, 'No': 0}).fillna(0) + \
                          df['BusinessTravel'].map({'Non-Travel': 0, 'Travel_Rarely': 1, 
                                                     'Travel_Frequently': 2}).fillna(0)
    
    return df

# 应用特征工程
X_featured = create_features(X.copy())
print(f"特征工程后特征数量: {X_featured.shape[1]}")
```

## 模型训练

### 1. 数据划分

```python
from sklearn.model_selection import train_test_split

# 划分训练集和验证集
X_train, X_val, y_train, y_val = train_test_split(
    X_scaled, y_encoded, 
    test_size=0.2, 
    random_state=42,
    stratify=y_encoded  # 保持类别比例
)

print(f"训练集大小: {X_train.shape}")
print(f"验证集大小: {X_val.shape}")
print(f"训练集离职比例: {y_train.mean():.2%}")
print(f"验证集离职比例: {y_val.mean():.2%}")
```

### 2. 基线模型训练

```python
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score

# 逻辑回归基线模型
lr_model = LogisticRegression(random_state=42, max_iter=1000)
lr_model.fit(X_train, y_train)

# 预测
y_pred_lr = lr_model.predict(X_val)
y_prob_lr = lr_model.predict_proba(X_val)

# 评估
print("逻辑回归模型评估:")
print(classification_report(y_val, y_pred_lr))
print(f"AUC: {roc_auc_score(y_val, y_prob_lr[:, 1]):.4f}")
```

### 3. 随机森林模型

```python
# 随机森林模型
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    n_jobs=-1
)
rf_model.fit(X_train, y_train)

# 预测
y_pred_rf = rf_model.predict(X_val)
y_prob_rf = rf_model.predict_proba(X_val)

# 评估
print("随机森林模型评估:")
print(classification_report(y_val, y_pred_rf))
print(f"AUC: {roc_auc_score(y_val, y_prob_rf[:, 1]):.4f}")

# 特征重要性
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\n特征重要性 (Top 10):")
print(feature_importance.head(10))
```

### 4. 交叉验证

```python
from sklearn.model_selection import cross_val_score, StratifiedKFold

# 交叉验证
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 逻辑回归
lr_scores = cross_val_score(lr_model, X_scaled, y_encoded, cv=skf, scoring='f1')
print(f"逻辑回归 F1: {lr_scores.mean():.4f} (+/- {lr_scores.std():.4f})")

# 随机森林
rf_scores = cross_val_score(rf_model, X_scaled, y_encoded, cv=skf, scoring='f1')
print(f"随机森林 F1: {rf_scores.mean():.4f} (+/- {rf_scores.std():.4f})")
```

## 模型评估

### 1. 混淆矩阵

```python
from sklearn.metrics import confusion_matrix

def plot_confusion_matrix(y_true, y_pred, title='混淆矩阵'):
    """绘制混淆矩阵"""
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['未离职', '离职'],
                yticklabels=['未离职', '离职'])
    plt.title(title)
    plt.xlabel('预测值')
    plt.ylabel('真实值')
    plt.show()

# 绘制混淆矩阵
plot_confusion_matrix(y_val, y_pred_rf, '随机森林混淆矩阵')
```

### 2. ROC曲线

```python
from sklearn.metrics import roc_curve, auc

def plot_roc_curve(y_true, y_prob, title='ROC曲线'):
    """绘制ROC曲线"""
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    roc_auc = auc(fpr, tpr)
    
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, 
             label=f'ROC curve (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('假正率')
    plt.ylabel('真正率')
    plt.title(title)
    plt.legend(loc="lower right")
    plt.show()

# 绘制ROC曲线
plot_roc_curve(y_val, y_prob_rf[:, 1], '随机森林ROC曲线')
```

### 3. 模型对比

```python
# 对比多个模型
models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42)
}

results = []
for name, model in models.items():
    # 训练
    model.fit(X_train, y_train)
    
    # 预测
    y_pred = model.predict(X_val)
    y_prob = model.predict_proba(X_val)[:, 1]
    
    # 评估
    results.append({
        'Model': name,
        'Accuracy': accuracy_score(y_val, y_pred),
        'Precision': precision_score(y_val, y_pred),
        'Recall': recall_score(y_val, y_pred),
        'F1': f1_score(y_val, y_pred),
        'AUC': roc_auc_score(y_val, y_prob)
    })

# 显示结果
results_df = pd.DataFrame(results)
print(results_df.round(4))
```

## 预测输出

### 1. 测试集预测

```python
# 加载测试数据
test_df = pd.read_csv('data/test.csv')

# 预处理测试数据
test_processed = test_df.drop(columns=useless_cols, errors='ignore')
test_encoded = pd.get_dummies(test_processed, columns=categorical_cols, drop_first=True)

# 确保特征一致
for col in X_train.columns:
    if col not in test_encoded.columns:
        test_encoded[col] = 0

test_encoded = test_encoded[X_train.columns]

# 标准化
test_scaled = test_encoded.copy()
test_scaled[numeric_cols] = scaler.transform(test_encoded[numeric_cols])

# 预测
predictions = rf_model.predict(test_scaled)
probabilities = rf_model.predict_proba(test_scaled)[:, 1]

# 保存结果
results = pd.DataFrame({
    'user_id': test_df['user_id'],
    'Attrition_Predicted': ['Yes' if p == 1 else 'No' for p in predictions],
    'Attrition_Probability': probabilities
})

results.to_csv('prediction_result/predictions.csv', index=False)
print(f"预测结果已保存，共 {len(results)} 条记录")
```

### 2. 风险等级划分

```python
def risk_level(prob):
    """根据概率划分风险等级"""
    if prob < 0.2:
        return '低风险'
    elif prob < 0.5:
        return '中低风险'
    elif prob < 0.8:
        return '中高风险'
    else:
        return '高风险'

results['RiskLevel'] = results['Attrition_Probability'].apply(risk_level)

# 风险等级分布
print("风险等级分布:")
print(results['RiskLevel'].value_counts())
```

## 常见问题解决

### 1. 类别不平衡问题

```python
from imblearn.over_sampling import SMOTE

# 使用SMOTE过采样
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

print(f"原始样本: {len(y_train)}")
print(f"过采样后: {len(y_resampled)}")
print(f"原始离职比例: {y_train.mean():.2%}")
print(f"过采样后离职比例: {y_resampled.mean():.2%}")

# 使用过采样数据训练模型
rf_model_balanced = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model_balanced.fit(X_resampled, y_resampled)
```

### 2. 特征选择优化

```python
from sklearn.feature_selection import SelectKBest, f_classif

# 选择最重要的20个特征
selector = SelectKBest(score_func=f_classif, k=20)
X_selected = selector.fit_transform(X_train, y_train)

selected_features = X_train.columns[selector.get_support()].tolist()
print(f"选择的特征: {selected_features}")
```

### 3. 模型调参

```python
from sklearn.model_selection import GridSearchCV

# 定义参数网格
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# 网格搜索
grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='f1',
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

print(f"最佳参数: {grid_search.best_params_}")
print(f"最佳F1分数: {grid_search.best_score_:.4f}")

# 使用最佳模型
best_model = grid_search.best_estimator_
```

---

*最后更新: 2026年2月15日*
*使用指南版本: v1.0*
*技术支持: build-your-own-ai项目团队*
