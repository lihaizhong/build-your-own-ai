# 知识库处理系统 - 使用指南

## 环境准备

### 1. 系统要求
- **操作系统**: Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **Python版本**: 3.11+
- **内存**: 最小4GB，推荐8GB+
- **存储空间**: 最小2GB，推荐5GB+

### 2. API密钥配置

本项目使用阿里云DashScope API，需要配置API密钥：

```bash
# 创建.env文件
cp .env.example .env

# 编辑.env文件，添加API密钥
DASHSCOPE_API_KEY=your_api_key_here
```

### 3. 依赖安装

#### 方式一：使用uv（推荐）
```bash
# 克隆项目
git clone <repository-url>
cd practice/16-CASE-知识库处理

# 创建虚拟环境
uv venv --python 3.11

# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# 或
.venv\Scripts\activate     # Windows

# 安装依赖
uv sync

# 运行程序
uv run python code/main.py --help
```

#### 方式二：使用pip
```bash
# 创建虚拟环境
python -m venv .venv

# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# 或
.venv\Scripts\activate     # Windows

# 安装依赖
pip install -r requirements.txt

# 运行程序
python code/main.py --help
```

## 快速开始

### 1. 查看帮助信息

```bash
uv run python code/main.py --help
```

**预期输出：**
```
usage: main.py [-h] [--question] [--conversation] [--health] [--version] [--all] [--data DATA]

知识库处理工具 - 迪士尼RAG助手

options:
  -h, --help       show this help message and exit
  --question, -q   运行问题生成与检索优化
  --conversation, -c  运行对话知识提取
  --health, -H     运行知识库健康度检查
  --version, -v    运行知识库版本管理
  --all, -a        运行所有功能演示
  --data DATA      指定知识库数据文件路径（JSON格式）
```

### 2. 运行所有功能演示

```bash
uv run python code/main.py --all
```

**预期输出：**
```
============================================================
知识库处理工具 - 迪士尼RAG助手
============================================================

============================================================
知识库问题生成与检索优化（BM25版本）
============================================================

示例1: 为知识切片生成多样化问题
知识内容: 上海迪士尼乐园位于上海市浦东新区...

生成的5个问题:
  1. 上海迪士尼乐园的具体位置在哪里？ (类型: 直接问, 难度: 简单)
  2. 上海迪士尼乐园有哪些主题园区？ (类型: 直接问, 难度: 中等)
  ...

----------------------------------------

示例2: 评估两种检索方法的准确度
正在为知识库生成问题...
为知识库生成问题完毕
测试查询数量: 3
BM25原文检索准确率: 66.7%
BM25问题检索准确率: 100.0%

...

============================================================
处理完成
============================================================
```

### 3. 运行单个功能模块

#### 问题生成与检索优化
```bash
uv run python code/main.py --question
```

#### 对话知识提取
```bash
uv run python code/main.py --conversation
```

#### 健康度检查
```bash
uv run python code/main.py --health
```

#### 版本管理
```bash
uv run python code/main.py --version
```

### 4. 使用自定义知识库

```bash
uv run python code/main.py --data /path/to/your/knowledge_base.json --all
```

## 命令行参数详解

### 参数说明

| 参数 | 简写 | 说明 |
|------|------|------|
| `--question` | `-q` | 运行问题生成与检索优化功能 |
| `--conversation` | `-c` | 运行对话知识提取功能 |
| `--health` | `-H` | 运行知识库健康度检查功能 |
| `--version` | `-v` | 运行知识库版本管理功能 |
| `--all` | `-a` | 运行所有功能演示 |
| `--data` | - | 指定知识库数据文件路径（JSON格式） |

### 使用示例

```bash
# 只运行问题生成功能
uv run python code/main.py -q

# 运行问题生成和健康检查
uv run python code/main.py --question --health

# 使用自定义数据运行所有功能
uv run python code/main.py --all --data ./my_knowledge.json

# 使用自定义数据运行版本管理
uv run python code/main.py -v --data ./my_knowledge.json
```

## 各功能模块使用示例

### 1. 问题生成与检索优化

#### 基本使用
```python
from question_generator import KnowledgeBaseOptimizer

# 创建优化器实例
optimizer = KnowledgeBaseOptimizer()

# 为单个知识切片生成问题
knowledge_chunk = "上海迪士尼乐园位于上海市浦东新区..."
questions = optimizer.generate_questions_for_chunk(knowledge_chunk, num_questions=5)

for q in questions:
    print(f"问题: {q['question']}")
    print(f"类型: {q['question_type']}")
    print(f"难度: {q['difficulty']}")
```

#### 构建索引并检索
```python
# 构建知识库索引
knowledge_base = [
    {"id": "kb_001", "content": "知识内容1", "category": "分类1"},
    {"id": "kb_002", "content": "知识内容2", "category": "分类2"},
]

# 为知识库生成问题
for chunk in knowledge_base:
    chunk['generated_questions'] = optimizer.generate_questions_for_chunk(
        chunk['content']
    )

# 构建索引
optimizer.build_knowledge_index(knowledge_base)

# 执行检索
results = optimizer.search_similar_chunks("查询内容", k=3, search_type="content")
```

#### 评估检索效果
```python
# 定义测试查询
test_queries = [
    {"query": "上海迪士尼在哪里？", "correct_chunk": "..."},
    {"query": "门票多少钱？", "correct_chunk": "..."},
]

# 评估检索方法
results = optimizer.evaluate_retrieval_methods(knowledge_base, test_queries)

print(f"内容检索准确率: {sum(results['content_similarity'])/len(results['content_similarity'])*100:.1f}%")
print(f"问题检索准确率: {sum(results['question_similarity'])/len(results['question_similarity'])*100:.1f}%")
```

### 2. 对话知识提取

#### 基本使用
```python
from conversation_extractor import ConversationKnowledgeExtractor

# 创建提取器实例
extractor = ConversationKnowledgeExtractor()

# 从单次对话中提取知识
conversation = """
用户: "我想去上海迪士尼乐园玩，门票多少钱？"
AI: "上海迪士尼乐园的门票价格根据日期有所不同..."
"""

result = extractor.extract_knowledge_from_conversation(conversation)

print(f"对话摘要: {result['conversation_summary']}")
print(f"用户意图: {result['user_intent']}")
print(f"提取的知识点:")
for knowledge in result['extracted_knowledge']:
    print(f"  - {knowledge['knowledge_type']}: {knowledge['content'][:50]}...")
```

#### 批量提取和合并
```python
# 批量提取知识
conversations = [conv1, conv2, conv3]
all_knowledge = extractor.batch_extract_knowledge(conversations)

# 合并相似知识
merged_knowledge = extractor.merge_similar_knowledge(all_knowledge)

print(f"提取前: {len(all_knowledge)} 个知识点")
print(f"合并后: {len(merged_knowledge)} 个知识点")

# 获取统计信息
stats = extractor.get_knowledge_stats()
print(f"知识点分布: {stats['type_distribution']}")
```

### 3. 健康度检查

#### 基本使用
```python
from health_checker import KnowledgeBaseHealthChecker

# 创建检查器实例
checker = KnowledgeBaseHealthChecker()

# 定义知识库和测试查询
knowledge_base = [...]
test_queries = [
    {"query": "上海迪士尼在哪里？", "expected_answer": "浦东"},
    {"query": "门票多少钱？", "expected_answer": "价格"},
]

# 生成健康度报告
health_report = checker.generate_health_report(knowledge_base, test_queries)

print(f"整体健康度评分: {health_report['overall_health_score']:.2f}")
print(f"健康等级: {health_report['health_level']}")
```

#### 详细分析
```python
# 缺少的知识分析
missing = health_report['missing_knowledge']
print(f"覆盖率: {missing['coverage_score']*100:.1f}%")
print(f"缺少知识点: {len(missing['missing_knowledge'])} 个")

# 过期知识分析
outdated = health_report['outdated_knowledge']
print(f"新鲜度评分: {outdated['freshness_score']:.2f}")
print(f"过期知识点: {len(outdated['outdated_knowledge'])} 个")

# 冲突知识分析
conflicting = health_report['conflicting_knowledge']
print(f"一致性评分: {conflicting['consistency_score']:.2f}")
print(f"冲突数量: {len(conflicting['conflicting_knowledge'])} 个")

# 改进建议
for i, rec in enumerate(health_report['recommendations'], 1):
    print(f"{i}. {rec}")
```

### 4. 版本管理

#### 基本使用
```python
from version_manager import KnowledgeBaseVersionManager

# 创建版本管理器实例
manager = KnowledgeBaseVersionManager()

# 创建版本
knowledge_base_v1 = knowledge_base[:3]
v1_info = manager.create_version(knowledge_base_v1, "v1.0", "基础版本")

knowledge_base_v2 = knowledge_base.copy()
v2_info = manager.create_version(knowledge_base_v2, "v2.0", "增强版本")

print(f"版本1知识切片数: {v1_info['statistics']['total_chunks']}")
print(f"版本2知识切片数: {v2_info['statistics']['total_chunks']}")
```

#### 版本比较
```python
# 比较版本差异
comparison = manager.compare_versions("v1.0", "v2.0")

changes = comparison['changes']
print(f"新增: {len(changes['added_chunks'])} 个")
print(f"删除: {len(changes['removed_chunks'])} 个")
print(f"修改: {len(changes['modified_chunks'])} 个")
```

#### 性能评估
```python
# 评估版本性能
test_queries = [...]
perf_v1 = manager.evaluate_version_performance("v1.0", test_queries)
perf_v2 = manager.evaluate_version_performance("v2.0", test_queries)

print(f"版本1准确率: {perf_v1['overall_metrics']['accuracy']*100:.1f}%")
print(f"版本2准确率: {perf_v2['overall_metrics']['accuracy']*100:.1f}%")

# 性能比较
comparison = manager.compare_version_performance("v1.0", "v2.0", test_queries)
print(f"建议: {comparison['recommendation']}")
```

#### 保存和加载版本
```python
# 保存版本到文件
manager.save_version("v1.0", "./versions/v1.0.json")

# 从文件加载版本
manager.load_version("./versions/v1.0.json", "v1.0_restored")
```

## 常见问题解决

### 1. API密钥问题

#### 问题现象
```
ValueError: DASHSCOPE_API_KEY 环境变量未设置
```

#### 解决方案
```bash
# 检查环境变量
echo $DASHSCOPE_API_KEY

# 设置环境变量
export DASHSCOPE_API_KEY=your_api_key

# 或在.env文件中配置
echo "DASHSCOPE_API_KEY=your_api_key" > .env
```

### 2. 依赖安装问题

#### 问题现象
```
ModuleNotFoundError: No module named 'rank_bm25'
```

#### 解决方案
```bash
# 使用uv安装
uv add rank-bm25

# 或使用pip
pip install rank-bm25
```

### 3. 内存不足问题

#### 问题现象
```
MemoryError: Unable to allocate array
```

#### 解决方案
```python
# 减少批处理大小
def generate_questions_batch(chunks, batch_size=10):
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i+batch_size]
        for chunk in batch:
            yield generate_questions(chunk)
```

### 4. JSON解析错误

#### 问题现象
```
JSONDecodeError: Expecting value
```

#### 解决方案
```python
# 使用预处理函数
from utils import preprocess_json_response

response = llm_response  # LLM返回的响应
response = preprocess_json_response(response)  # 清理markdown格式
result = json.loads(response)
```

## 性能调优

### 1. BM25检索优化

```python
# 调整BM25参数
from rank_bm25 import BM25Okapi

# 默认参数: k1=1.5, b=0.75
bm25 = BM25Okapi(corpus, k1=1.2, b=0.8)

# 自定义分词
def custom_tokenize(text):
    words = jieba.lcut(text)
    # 自定义过滤逻辑
    return [w for w in words if len(w) > 1]
```

### 2. LLM调用优化

```python
# 批量调用
def batch_generate_questions(chunks, batch_size=5):
    results = []
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i+batch_size]
        # 合并prompt减少API调用
        combined_prompt = create_combined_prompt(batch)
        response = get_completion(combined_prompt)
        results.extend(parse_response(response))
    return results
```

### 3. 向量索引优化

```python
# 使用更高效的索引类型
import faiss

# 小数据集
nlist = 100
quantizer = faiss.IndexFlatL2(dimension)
index = faiss.IndexIVFFlat(quantizer, dimension, nlist)

# 大数据集
M = 32  # 每个向量的连接数
index = faiss.IndexHNSWFlat(dimension, M)
```

## 监控和调试

### 1. 日志配置

```python
from loguru import logger

# 配置日志
logger.add("logs/app.log", rotation="1 day", level="INFO")

# 使用日志
logger.info("开始处理知识库")
logger.debug(f"知识切片数量: {len(knowledge_base)}")
logger.error(f"处理失败: {e}")
```

### 2. 性能监控

```python
import time

def monitor_performance(func):
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        duration = time.time() - start
        logger.info(f"{func.__name__} 执行时间: {duration:.2f}秒")
        return result
    return wrapper

@monitor_performance
def process_knowledge_base(knowledge_base):
    # 处理逻辑
    pass
```

---

*最后更新: 2026年2月14日*
*使用指南版本: v1.0*
*技术支持: build-your-own-ai项目团队*
