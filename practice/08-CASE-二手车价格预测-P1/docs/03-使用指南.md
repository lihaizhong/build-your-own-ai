# 二手车价格预测项目 - 使用指南

## 环境准备

### 1. 系统要求
- **操作系统**: Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **Python版本**: 3.11+
- **内存**: 最小8GB，推荐16GB+
- **存储空间**: 最小2GB，推荐5GB+

### 2. 依赖安装

#### 方式一：使用uv（推荐）
```bash
# 进入项目目录
cd practice/08-CASE-二手车价格预测-P1

# 创建虚拟环境
uv venv --python 3.11

# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# 或
.venv\Scripts\activate     # Windows

# 安装依赖（如果有pyproject.toml）
uv sync

# 运行模型
uv run python code/modeling_v28.py
```

#### 方式二：使用pip
```bash
# 创建虚拟环境
python -m venv .venv

# 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# 或
.venv\Scripts\activate     # Windows

# 安装依赖
pip install pandas numpy scikit-learn lightgbm xgboost catboost matplotlib seaborn joblib

# 运行模型
python code/modeling_v28.py
```

## 快速开始

### 1. 数据准备

#### 数据文件位置
```plaintext
data/
├── used_car_train_20200313.csv   # 训练数据 (150,000条)
├── used_car_testB_20200421.csv   # 测试数据 (50,000条)
└── used_car_sample_submit.csv    # 提交样例
```

#### 数据格式说明
- **分隔符**: 空格分隔
- **缺失值标记**: '-'（连字符）
- **编码**: UTF-8

### 2. 运行完整流程

#### 使用最新版本模型（推荐）
```bash
# 激活虚拟环境
source .venv/bin/activate

# 运行V28版本模型（最佳性能）
python code/modeling_v28.py
```

#### 预期输出
```
================================================================================
开始V28融合创新模型训练
基于表现最佳模型的深度分析和融合创新
目标：突破488.7255分，冲击480分以内
================================================================================

步骤1: 增强数据预处理...
原始训练集: (150000, 31)
原始测试集: (50000, 30)
处理后训练集: (150000, XX)
处理后测试集: (50000, XX)

步骤2: 创新特征工程...
执行动态特征重要性分析...
从XX个特征中选择了XX个高价值特征

训练第 1 折...
  LightGBM MAE: XXX.XX, XGBoost MAE: XXX.XX, CatBoost MAE: XXX.XX
训练第 2 折...
  ...

平均验证分数:
  LightGBM: XXX.XX (±XX.XX)
  XGBoost: XXX.XX (±XX.XX)
  CatBoost: XXX.XX (±XX.XX)

执行创新集成策略...
创新集成权重:
  LGB: 0.XXX
  XGB: 0.XXX
  CAT: 0.XXX

执行增强校准算法...

预测结果已保存
```

### 3. 使用其他版本模型

#### 简化版本（快速训练）
```bash
python code/modeling_v24_simplified.py
```

#### 分层验证版本
```bash
python code/modeling_v23.py
```

#### 抗过拟合版本
```bash
python code/modeling_v26.py
```

## 模型训练

### 1. 基础训练流程

```python
import pandas as pd
from modeling_v28 import enhanced_preprocessing, create_innovative_features, train_innovative_models

# 1. 数据预处理
train_df, test_df = enhanced_preprocessing()

# 2. 特征工程
train_df = create_innovative_features(train_df)
test_df = create_innovative_features(test_df)

# 3. 准备特征
y_col = 'price'
X_train = train_df.drop(columns=[y_col, 'SaleID'])
y_train = train_df[y_col]
X_test = test_df.drop(columns=['SaleID'])

# 4. 模型训练
lgb_pred, xgb_pred, cat_pred, scores, models = train_innovative_models(X_train, y_train, X_test)

# 5. 模型集成
from modeling_v28 import innovative_ensemble
ensemble_pred = innovative_ensemble(lgb_pred, xgb_pred, cat_pred, scores)

# 6. 结果校准
from modeling_v28 import enhanced_calibration
final_pred = enhanced_calibration(ensemble_pred, y_train)
```

### 2. 自定义参数训练

```python
import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold

# 自定义LightGBM参数
custom_params = {
    'objective': 'mae',
    'metric': 'mae',
    'num_leaves': 31,
    'max_depth': 7,
    'learning_rate': 0.05,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'lambda_l1': 0.1,
    'lambda_l2': 0.1,
    'min_child_samples': 20,
    'random_state': 42
}

# 创建模型
model = lgb.LGBMRegressor(**custom_params, n_estimators=1000)

# 训练
model.fit(
    X_train, y_train,
    eval_set=[(X_val, y_val)],
    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(50)]
)
```

### 3. 交叉验证训练

```python
from sklearn.model_selection import StratifiedKFold

# 分层K折交叉验证
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 创建价格分层标签
y_bins = pd.qcut(y_train, q=10, labels=False)

predictions = np.zeros(len(X_test))
scores = []

for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_bins), 1):
    print(f"训练第 {fold} 折...")
    
    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]
    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]
    
    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)])
    
    predictions += model.predict(X_test) / 5
    score = mean_absolute_error(y_val, model.predict(X_val))
    scores.append(score)
    print(f"  Fold {fold} MAE: {score:.2f}")

print(f"平均 MAE: {np.mean(scores):.2f} (±{np.std(scores):.2f})")
```

## 预测与提交

### 1. 生成预测结果

```python
import pandas as pd

# 加载测试数据
test_df = pd.read_csv('data/used_car_testB_20200421.csv', sep=' ')

# 生成预测
predictions = model.predict(X_test)

# 确保预测值为正
predictions = np.maximum(predictions, 0)

# 创建提交文件
submission = pd.DataFrame({
    'SaleID': test_df['SaleID'],
    'price': predictions
})

# 保存结果
submission.to_csv('prediction_result/v28_result.csv', index=False)
print("预测结果已保存")
```

### 2. 结果分析

```python
import matplotlib.pyplot as plt

# 预测分布分析
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.hist(y_train, bins=50, alpha=0.7, label='训练集价格', density=True)
plt.hist(predictions, bins=50, alpha=0.7, label='预测价格', density=True)
plt.xlabel('价格')
plt.ylabel('密度')
plt.title('价格分布对比')
plt.legend()

plt.subplot(1, 2, 2)
plt.boxplot([y_train, predictions], labels=['训练集', '预测集'])
plt.ylabel('价格')
plt.title('价格箱线图对比')

plt.tight_layout()
plt.savefig('output/prediction_analysis.png', dpi=300)
plt.show()
```

## 常见问题解决

### 1. 内存不足问题

#### 问题现象
```
MemoryError: Unable to allocate array
```

#### 解决方案
```python
# 方案1：减少特征数量
X_train = X_train[top_features]

# 方案2：分批处理
def batch_predict(model, X, batch_size=10000):
    predictions = []
    for i in range(0, len(X), batch_size):
        batch = X.iloc[i:i+batch_size]
        pred = model.predict(batch)
        predictions.extend(pred)
    return np.array(predictions)

# 方案3：使用更少的数据采样
X_sample = X_train.sample(frac=0.5, random_state=42)
```

### 2. 模型加载失败

#### 问题现象
```
ModuleNotFoundError: No module named 'lightgbm'
```

#### 解决方案
```bash
# 安装缺失的包
pip install lightgbm xgboost catboost

# 如果安装失败，尝试使用conda
conda install -c conda-forge lightgbm
```

### 3. 数据读取错误

#### 问题现象
```
ParserError: Error tokenizing data
```

#### 解决方案
```python
# 检查分隔符和编码
df = pd.read_csv(
    'data/used_car_train_20200313.csv',
    sep=' ',           # 空格分隔
    na_values=['-'],   # 缺失值标记
    encoding='utf-8'   # 编码格式
)
```

### 4. 特征工程错误

#### 问题现象
```
ValueError: Cannot convert non-finite values (NA or inf) to integer
```

#### 解决方案
```python
# 处理无穷大值
df = df.replace([np.inf, -np.inf], np.nan)

# 填充缺失值
df = df.fillna(df.median())

# 再次检查
print(df.isnull().sum())
```

## 性能调优

### 1. 参数优化

#### 网格搜索
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'num_leaves': [31, 50, 70],
    'max_depth': [6, 8, 10],
    'learning_rate': [0.03, 0.05, 0.07],
    'feature_fraction': [0.7, 0.8, 0.9]
}

grid_search = GridSearchCV(
    estimator=lgb.LGBMRegressor(),
    param_grid=param_grid,
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1
)

grid_search.fit(X_train, y_train)
print(f"最佳参数: {grid_search.best_params_}")
print(f"最佳分数: {-grid_search.best_score_:.2f}")
```

#### 贝叶斯优化
```python
from skopt import BayesSearchCV

param_space = {
    'num_leaves': (20, 100),
    'max_depth': (4, 12),
    'learning_rate': (0.01, 0.1, 'log-uniform'),
    'lambda_l1': (0.0, 1.0),
    'lambda_l2': (0.0, 1.0)
}

bayes_search = BayesSearchCV(
    estimator=lgb.LGBMRegressor(),
    search_spaces=param_space,
    n_iter=50,
    cv=5,
    scoring='neg_mean_absolute_error',
    n_jobs=-1
)

bayes_search.fit(X_train, y_train)
```

### 2. 特征选择优化

```python
from sklearn.feature_selection import mutual_info_regression

# 计算特征重要性
mi_scores = mutual_info_regression(X_train, y_train)
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': mi_scores
}).sort_values('importance', ascending=False)

# 选择Top特征
top_features = feature_importance.head(50)['feature'].tolist()
X_train_selected = X_train[top_features]
X_test_selected = X_test[top_features]
```

## 监控和调试

### 1. 训练监控

```python
import logging

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/training.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# 训练过程记录
def train_with_logging(model, X_train, y_train, X_val, y_val):
    logger.info("开始模型训练...")
    logger.info(f"训练集大小: {X_train.shape}")
    logger.info(f"验证集大小: {X_val.shape}")
    
    model.fit(X_train, y_train, eval_set=[(X_val, y_val)])
    
    train_score = mean_absolute_error(y_train, model.predict(X_train))
    val_score = mean_absolute_error(y_val, model.predict(X_val))
    
    logger.info(f"训练集MAE: {train_score:.2f}")
    logger.info(f"验证集MAE: {val_score:.2f}")
    
    return model
```

### 2. 性能分析

```python
import time

def measure_performance(func):
    """性能测量装饰器"""
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        print(f"{func.__name__} 执行时间: {end_time - start_time:.2f}秒")
        return result
    return wrapper

@measure_performance
def train_model(X, y):
    model.fit(X, y)
    return model
```

---

*最后更新: 2026年2月15日*
*使用指南版本: v1.0*
*技术支持: build-your-own-ai项目团队*
