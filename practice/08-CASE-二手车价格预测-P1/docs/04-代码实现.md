# 二手车价格预测项目 - 代码实现详解

## 核心代码结构

### 1. 项目路径管理模块

```python
import os
import sys

def get_project_path(*paths: str) -> str:
    """获取项目路径的统一方法"""
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(current_dir)
        return os.path.join(project_dir, *paths)
    except NameError:
        return os.path.join(os.getcwd(), *paths)
```

**功能特点：**
- **统一路径管理**: 提供项目路径的标准化获取方法
- **容错处理**: 处理不同运行环境下的路径差异
- **灵活扩展**: 支持任意层级的路径构建

### 2. 主程序入口

```python
def v28_innovative_optimize():
    """
    V28融合创新模型训练流程
    主程序入口
    """
    print("=" * 80)
    print("开始V28融合创新模型训练")
    print("=" * 80)
    
    # 步骤1: 增强数据预处理
    train_df, test_df = enhanced_preprocessing()
    
    # 步骤2: 创新特征工程
    train_df = create_innovative_features(train_df)
    test_df = create_innovative_features(test_df)
    
    # 步骤3: 准备特征
    y_col = 'price'
    X_train = train_df.drop(columns=[y_col, 'SaleID'])
    y_train = train_df[y_col]
    X_test = test_df.drop(columns=['SaleID'])
    
    # 步骤4: 特征选择
    X_train, X_test, feature_importance = dynamic_feature_selection(
        X_train, y_train, X_test, max_features=80
    )
    
    # 步骤5: 模型训练
    lgb_pred, xgb_pred, cat_pred, scores, models = train_innovative_models(
        X_train, y_train, X_test
    )
    
    # 步骤6: 模型集成
    ensemble_pred = innovative_ensemble(lgb_pred, xgb_pred, cat_pred, scores)
    
    # 步骤7: 结果校准
    final_pred = enhanced_calibration(ensemble_pred, y_train)
    
    # 步骤8: 保存结果
    save_predictions(final_pred, test_df['SaleID'])
```

## 数据预处理模块详解

### 1. 数据加载和清洗

```python
def enhanced_preprocessing():
    """
    增强的数据预处理 - 融合各版本最佳实践
    """
    # 加载数据
    train_path = get_project_path('data', 'used_car_train_20200313.csv')
    test_path = get_project_path('data', 'used_car_testB_20200421.csv')
    
    train_df = pd.read_csv(train_path, sep=' ', na_values=['-'])
    test_df = pd.read_csv(test_path, sep=' ', na_values=['-'])
    
    print(f"原始训练集: {train_df.shape}")
    print(f"原始测试集: {test_df.shape}")
    
    # 合并数据进行预处理
    all_df = pd.concat([train_df, test_df], ignore_index=True, sort=False)
    
    return train_df, test_df
```

### 2. 缺失值处理策略

```python
def handle_missing_values(df):
    """智能缺失值处理"""
    # 分类特征处理
    categorical_cols = ['fuelType', 'gearbox', 'bodyType', 'model', 'brand']
    
    for col in categorical_cols:
        if col in df.columns:
            # 创建缺失标记
            df[f'{col}_missing'] = (df[col].isnull()).astype(int)
            
            # model特征：按品牌填充众数
            if col == 'model' and 'brand' in df.columns:
                for brand in df['brand'].unique():
                    brand_mask = df['brand'] == brand
                    brand_mode = df[brand_mask][col].mode()
                    if len(brand_mode) > 0:
                        df.loc[brand_mask & df[col].isnull(), col] = brand_mode.iloc[0]
            
            # 全局众数填充剩余缺失值
            mode_value = df[col].mode()
            if len(mode_value) > 0:
                df[col] = df[col].fillna(mode_value.iloc[0])
    
    return df
```

**处理策略：**
- **分类变量**: 使用众数填充，并创建缺失标记特征
- **model特征**: 按品牌分组填充，提高填充准确性
- **数值变量**: 使用中位数填充

### 3. 异常值处理

```python
def handle_outliers(df):
    """异常值处理"""
    # power异常值处理（>600设为600）
    if 'power' in df.columns:
        df['power'] = np.clip(df['power'], 0, 600)
        df['power_is_zero'] = (df['power'] <= 0).astype(int)
        df['power_is_high'] = (df['power'] > 400).astype(int)
    
    return df
```

## 特征工程模块详解

### 1. 时间特征提取

```python
def create_time_features(df):
    """创建时间相关特征"""
    df = df.copy()
    
    # 解析注册日期
    df['regDate'] = pd.to_datetime(df['regDate'], format='%Y%m%d', errors='coerce')
    current_year = 2020
    
    # 基础时间特征
    df['car_age'] = current_year - df['regDate'].dt.year
    df['car_age'] = df['car_age'].fillna(0).astype(int)
    df['reg_month'] = df['regDate'].dt.month.fillna(6).astype(int)
    df['reg_quarter'] = df['regDate'].dt.quarter.fillna(2).astype(int)
    df['reg_dayofweek'] = df['regDate'].dt.dayofweek.fillna(3).astype(int)
    
    # 季节特征
    df['reg_season'] = df['reg_month'].map({
        12: 1, 1: 1, 2: 1,   # 冬季
        3: 2, 4: 2, 5: 2,    # 春季
        6: 3, 7: 3, 8: 3,    # 夏季
        9: 4, 10: 4, 11: 4   # 秋季
    })
    df['is_winter_reg'] = df['reg_month'].isin([12, 1, 2]).astype(int)
    df['is_summer_reg'] = df['reg_month'].isin([6, 7, 8]).astype(int)
    
    # 周期性编码
    df['reg_month_sin'] = np.sin(2 * np.pi * df['reg_month'] / 12)
    df['reg_month_cos'] = np.cos(2 * np.pi * df['reg_month'] / 12)
    
    return df
```

**技术亮点：**
- **周期性编码**: 使用sin/cos变换捕捉月份的周期性
- **季节特征**: 将月份映射为季节，捕捉季节性模式
- **容错处理**: 对无效日期进行合理填充

### 2. 业务特征构建

```python
def create_business_features(df):
    """创建业务逻辑特征"""
    df = df.copy()
    
    # 功率相关特征
    if 'power' in df.columns and 'car_age' in df.columns:
        df['power_age_ratio'] = df['power'] / (df['car_age'] + 1)
        df['power_decay'] = df['power'] * np.exp(-df['car_age'] * 0.05)
        df['log_power'] = np.log1p(np.maximum(df['power'], 1))
        df['sqrt_power'] = np.sqrt(np.maximum(df['power'], 0))
        df['power_squared'] = (df['power'] ** 2) / 1000
    
    # 里程相关特征
    if 'kilometer' in df.columns and 'car_age' in df.columns:
        car_age_safe = np.maximum(df['car_age'], 0.1)
        df['km_per_year'] = df['kilometer'] / car_age_safe
        df['km_per_year'] = np.clip(df['km_per_year'], 0, 40000)
        df['log_kilometer'] = np.log1p(df['kilometer'])
        df['sqrt_kilometer'] = np.sqrt(df['kilometer'])
    
    # 组合特征
    if 'power' in df.columns and 'kilometer' in df.columns:
        df['power_km_ratio'] = df['power'] / (df['kilometer'] + 1)
        df['power_km_interaction'] = df['power'] * np.log1p(df['kilometer'])
    
    return df
```

### 3. 统计特征生成

```python
def create_statistical_features(df):
    """创建统计特征"""
    df = df.copy()
    
    # 品牌统计特征
    if 'price' in df.columns and 'brand' in df.columns:
        brand_stats = df.groupby('brand')['price'].agg([
            'mean', 'count', 'std', 'median'
        ]).reset_index()
        
        global_mean = df['price'].mean()
        smooth_factor = 40
        
        # 平滑均值
        brand_stats['smooth_mean'] = (
            (brand_stats['mean'] * brand_stats['count'] + global_mean * smooth_factor) / 
            (brand_stats['count'] + smooth_factor)
        )
        
        # 变异系数
        brand_stats['cv'] = brand_stats['std'] / brand_stats['mean']
        brand_stats['cv'] = brand_stats['cv'].fillna(brand_stats['cv'].median())
        
        # 映射特征
        df['brand_avg_price'] = df['brand'].map(
            brand_stats.set_index('brand')['smooth_mean']
        ).fillna(global_mean)
        df['brand_price_stability'] = df['brand'].map(
            brand_stats.set_index('brand')['cv']
        ).fillna(brand_stats['cv'].median())
    
    # v特征统计
    v_cols = [col for col in df.columns if col.startswith('v_')]
    if len(v_cols) >= 3:
        df['v_mean'] = df[v_cols].mean(axis=1)
        df['v_std'] = df[v_cols].std(axis=1).fillna(0)
        df['v_max'] = df[v_cols].max(axis=1)
        df['v_min'] = df[v_cols].min(axis=1)
        df['v_range'] = df['v_max'] - df['v_min']
    
    return df
```

### 4. 目标编码实现

```python
def create_target_encoding(df):
    """创建目标编码特征"""
    if 'price' not in df.columns:
        return df
    
    df = df.copy()
    
    for col in ['brand', 'model', 'bodyType', 'fuelType', 'gearbox']:
        if col not in df.columns:
            continue
        
        # 计算目标均值
        target_mean = df.groupby(col)['price'].mean()
        global_mean = df['price'].mean()
        count = df[col].value_counts()
        
        # 平滑因子（根据类别数量调整）
        if col == 'brand':
            smooth_factor = 100
        elif col == 'model':
            smooth_factor = 50
        else:
            smooth_factor = 20
        
        # 平滑编码
        smooth_encoding = (target_mean * count + global_mean * smooth_factor) / (count + smooth_factor)
        df[f'{col}_target_enc'] = df[col].map(smooth_encoding).fillna(global_mean)
        
        # 频率编码
        freq_map = df[col].value_counts().to_dict()
        df[f'{col}_freq'] = df[col].map(freq_map)
    
    return df
```

## 模型训练模块详解

### 1. 分层交叉验证实现

```python
def train_innovative_models(X_train, y_train, X_test):
    """训练创新模型 - 融合各版本精华"""
    print("训练创新融合模型...")
    
    # 对数变换
    y_train_log = np.log1p(y_train)
    
    # 分层K折交叉验证
    y_bins = pd.qcut(y_train, q=10, labels=False)
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    # 存储预测结果
    lgb_predictions = np.zeros(len(X_test))
    xgb_predictions = np.zeros(len(X_test))
    cat_predictions = np.zeros(len(X_test))
    
    # 存储验证分数
    lgb_scores, xgb_scores, cat_scores = [], [], []
    
    # 交叉验证训练
    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_bins), 1):
        print(f"训练第 {fold} 折...")
        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]
        y_tr_log, y_val_log = y_train_log.iloc[train_idx], y_train_log.iloc[val_idx]
        
        # LightGBM训练
        lgb_model = lgb.LGBMRegressor(**lgb_params, n_estimators=iterations)
        lgb_model.fit(X_tr, y_tr_log, 
                     eval_set=[(X_val, y_val_log)], 
                     callbacks=[lgb.early_stopping(120), lgb.log_evaluation(0)])
        
        lgb_predictions += np.expm1(lgb_model.predict(X_test)) / 5
        lgb_mae = mean_absolute_error(np.expm1(y_val_log), np.expm1(lgb_model.predict(X_val)))
        lgb_scores.append(lgb_mae)
        
        # XGBoost和CatBoost类似...
    
    print(f"平均验证分数:")
    print(f"  LightGBM: {np.mean(lgb_scores):.2f}")
    print(f"  XGBoost: {np.mean(xgb_scores):.2f}")
    print(f"  CatBoost: {np.mean(cat_scores):.2f}")
    
    return lgb_predictions, xgb_predictions, cat_predictions, scores, models
```

### 2. 自适应参数调优

```python
def adaptive_parameter_tuning(X_train, y_train):
    """自适应参数调优"""
    print("执行自适应参数调优...")
    
    n_samples, n_features = X_train.shape
    y_std = y_train.std()
    
    # 根据数据规模调整参数
    if n_samples < 50000:
        base_learning_rate = 0.08
        base_num_leaves = 31
        base_depth = 7
        base_iterations = 1200
    else:
        base_learning_rate = 0.07
        base_num_leaves = 37
        base_depth = 8
        base_iterations = 1800
    
    # 根据特征数量调整正则化
    if n_features > 60:
        reg_factor = 1.2
        feature_fraction = 0.8
    else:
        reg_factor = 1.0
        feature_fraction = 0.9
    
    return {
        'learning_rate': base_learning_rate,
        'num_leaves': base_num_leaves,
        'max_depth': base_depth,
        'iterations': base_iterations,
        'feature_fraction': feature_fraction,
        'reg_factor': reg_factor
    }
```

### 3. 模型集成策略

```python
def innovative_ensemble(lgb_pred, xgb_pred, cat_pred, scores_info):
    """创新集成策略"""
    print("执行创新集成策略...")
    
    # 基于性能的自适应权重
    lgb_score = np.mean(scores_info['lgb_scores'])
    xgb_score = np.mean(scores_info['xgb_scores'])
    cat_score = np.mean(scores_info['cat_scores'])
    
    # 计算基础权重（MAE反比）
    total_inv_score = 1/lgb_score + 1/xgb_score + 1/cat_score
    raw_weights = {
        'lgb': (1/lgb_score) / total_inv_score,
        'xgb': (1/xgb_score) / total_inv_score,
        'cat': (1/cat_score) / total_inv_score
    }
    
    # 稳定性调整
    stability_factor = {
        'lgb': 1 / (1 + np.std(scores_info['lgb_scores']) * 2),
        'xgb': 1 / (1 + np.std(scores_info['xgb_scores']) * 2),
        'cat': 1 / (1 + np.std(scores_info['cat_scores']) * 2)
    }
    
    # 应用稳定性调整
    for model in raw_weights:
        raw_weights[model] *= stability_factor[model]
    
    # 权重范围限制
    balanced_weights = {
        model: np.clip(weight, 0.12, 0.65) 
        for model, weight in raw_weights.items()
    }
    
    # 重新归一化
    total_weight = sum(balanced_weights.values())
    final_weights = {model: weight/total_weight for model, weight in balanced_weights.items()}
    
    print(f"创新集成权重:")
    for model, weight in final_weights.items():
        print(f"  {model.upper()}: {weight:.3f}")
    
    # 加权集成
    ensemble_pred = (final_weights['lgb'] * lgb_pred + 
                    final_weights['xgb'] * xgb_pred + 
                    final_weights['cat'] * cat_pred)
    
    return ensemble_pred
```

### 4. 结果校准算法

```python
def enhanced_calibration(predictions, y_train):
    """多阶段校准算法"""
    print("执行增强校准算法...")
    
    train_mean = y_train.mean()
    train_median = y_train.median()
    pred_mean = predictions.mean()
    pred_median = np.median(predictions)
    
    # 第一阶段：分位数校准
    quantiles = [5, 10, 25, 40, 50, 60, 75, 90, 95]
    train_quantiles = np.percentile(y_train, quantiles)
    pred_quantiles = np.percentile(predictions, quantiles)
    
    quantile_factors = train_quantiles / pred_quantiles
    quantile_factors = np.clip(quantile_factors, 0.7, 1.3)
    
    quantile_calibrated = apply_quantile_calibration(predictions, quantile_factors)
    
    # 第二阶段：均值校准
    mean_calibration_factor = train_mean / pred_mean if pred_mean > 0 else 1.0
    mean_calibration_factor = np.clip(mean_calibration_factor, 0.85, 1.15)
    mean_calibrated = predictions * mean_calibration_factor
    
    # 第三阶段：中位数校准
    median_calibration_factor = train_median / pred_median if pred_median > 0 else 1.0
    median_calibration_factor = np.clip(median_calibration_factor, 0.9, 1.1)
    median_calibrated = predictions * median_calibration_factor
    
    # 智能权重融合
    pred_skew = (predictions.mean() - np.median(predictions)) / predictions.std()
    
    if abs(pred_skew) > 0.5:
        weights = {'quantile': 0.6, 'mean': 0.25, 'median': 0.15}
    else:
        weights = {'quantile': 0.4, 'mean': 0.35, 'median': 0.25}
    
    final_predictions = (
        weights['quantile'] * quantile_calibrated +
        weights['mean'] * mean_calibrated +
        weights['median'] * median_calibrated
    )
    
    # 确保预测值为正
    final_predictions = np.maximum(final_predictions, 0)
    
    return final_predictions
```

## 错误处理和调试机制

### 1. 数据验证

```python
def validate_data(df):
    """数据验证"""
    # 检查缺失值
    missing_pct = df.isnull().sum() / len(df)
    print("缺失值比例:")
    print(missing_pct[missing_pct > 0])
    
    # 检查数据类型
    print("\n数据类型分布:")
    print(df.dtypes.value_counts())
    
    # 检查异常值
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        q1, q99 = df[col].quantile([0.01, 0.99])
        outliers = ((df[col] < q1) | (df[col] > q99)).sum()
        if outliers > 0:
            print(f"{col}: {outliers} 个潜在异常值")
```

### 2. 模型诊断

```python
def diagnose_model(model, X_train, y_train, X_val, y_val):
    """模型诊断"""
    train_pred = model.predict(X_train)
    val_pred = model.predict(X_val)
    
    train_mae = mean_absolute_error(y_train, train_pred)
    val_mae = mean_absolute_error(y_val, val_pred)
    
    print(f"训练集 MAE: {train_mae:.2f}")
    print(f"验证集 MAE: {val_mae:.2f}")
    print(f"过拟合程度: {val_mae - train_mae:.2f}")
    
    if val_mae > train_mae * 1.5:
        print("⚠️  警告: 可能存在过拟合")
```

---

*最后更新: 2026年2月15日*
*代码实现版本: v1.0*
*开发团队: AI系统开发组*
