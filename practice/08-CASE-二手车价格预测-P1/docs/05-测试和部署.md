# äºŒæ‰‹è½¦ä»·æ ¼é¢„æµ‹é¡¹ç›® - æµ‹è¯•å’Œéƒ¨ç½²

## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•

#### æ•°æ®é¢„å¤„ç†æµ‹è¯•

```python
import unittest
import pandas as pd
import numpy as np
from code.data_analysis_tools import DataPreprocessor


class TestDataPreprocessing(unittest.TestCase):
    """æ•°æ®é¢„å¤„ç†æ¨¡å—æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.preprocessor = DataPreprocessor()
        self.test_data = pd.DataFrame({
            'SaleID': [1, 2, 3],
            'price': [1000, 2000, 3000],
            'power': [100, 200, 600],
            'kilometer': [50000, 100000, 150000],
            'brand': [1, 2, 1],
            'model': [1, np.nan, 2],
            'fuelType': [1, np.nan, 2]
        })
    
    def test_missing_value_handling(self):
        """æµ‹è¯•ç¼ºå¤±å€¼å¤„ç†"""
        result = self.preprocessor.handle_missing_values(self.test_data)
        
        # æ£€æŸ¥ç¼ºå¤±å€¼æ˜¯å¦è¢«å¡«å……
        self.assertFalse(result['model'].isnull().any())
        self.assertFalse(result['fuelType'].isnull().any())
        
        # æ£€æŸ¥ç¼ºå¤±æ ‡è®°æ˜¯å¦åˆ›å»º
        self.assertIn('model_missing', result.columns)
        self.assertIn('fuelType_missing', result.columns)
    
    def test_outlier_handling(self):
        """æµ‹è¯•å¼‚å¸¸å€¼å¤„ç†"""
        result = self.preprocessor.handle_outliers(self.test_data)
        
        # æ£€æŸ¥poweræ˜¯å¦è¢«æˆªæ–­
        self.assertLessEqual(result['power'].max(), 600)
    
    def test_feature_engineering(self):
        """æµ‹è¯•ç‰¹å¾å·¥ç¨‹"""
        result = self.preprocessor.create_features(self.test_data)
        
        # æ£€æŸ¥æ–°ç‰¹å¾æ˜¯å¦åˆ›å»º
        self.assertIn('car_age', result.columns)
        self.assertIn('power_age_ratio', result.columns)


class TestFeatureEngineering(unittest.TestCase):
    """ç‰¹å¾å·¥ç¨‹æ¨¡å—æµ‹è¯•"""
    
    def test_time_features(self):
        """æµ‹è¯•æ—¶é—´ç‰¹å¾æå–"""
        df = pd.DataFrame({
            'regDate': [20100101, 20150615, 20181231]
        })
        
        result = create_time_features(df)
        
        # æ£€æŸ¥æ—¶é—´ç‰¹å¾
        self.assertIn('car_age', result.columns)
        self.assertIn('reg_month', result.columns)
        self.assertIn('reg_season', result.columns)
    
    def test_business_features(self):
        """æµ‹è¯•ä¸šåŠ¡ç‰¹å¾æ„å»º"""
        df = pd.DataFrame({
            'power': [100, 150, 200],
            'car_age': [5, 10, 15],
            'kilometer': [50000, 100000, 150000]
        })
        
        result = create_business_features(df)
        
        # æ£€æŸ¥ä¸šåŠ¡ç‰¹å¾
        self.assertIn('power_age_ratio', result.columns)
        self.assertIn('km_per_year', result.columns)
        self.assertGreater(result['km_per_year'].iloc[0], 0)


class TestModelTraining(unittest.TestCase):
    """æ¨¡å‹è®­ç»ƒæ¨¡å—æµ‹è¯•"""
    
    def test_model_initialization(self):
        """æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–"""
        trainer = ModelTrainer()
        
        self.assertIsNotNone(trainer.models)
        self.assertIn('lgb', trainer.models)
        self.assertIn('xgb', trainer.models)
        self.assertIn('cat', trainer.models)
    
    def test_cross_validation(self):
        """æµ‹è¯•äº¤å‰éªŒè¯"""
        X = pd.DataFrame(np.random.rand(100, 10))
        y = pd.Series(np.random.rand(100) * 1000)
        
        trainer = ModelTrainer()
        scores = trainer.cross_validate(X, y, n_splits=3)
        
        self.assertEqual(len(scores), 3)
        for score in scores:
            self.assertGreater(score, 0)


if __name__ == '__main__':
    unittest.main(verbosity=2)
```

### 2. é›†æˆæµ‹è¯•

#### ç«¯åˆ°ç«¯æµ‹è¯•

```python
import pytest
import tempfile
import os


class TestEndToEnd:
    """ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    @pytest.fixture
    def temp_dir(self):
        """åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•"""
        with tempfile.TemporaryDirectory() as temp_dir:
            yield temp_dir
    
    def test_complete_pipeline(self, temp_dir):
        """æµ‹è¯•å®Œæ•´æ•°æ®å¤„ç†ç®¡é“"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        train_data = create_sample_train_data()
        test_data = create_sample_test_data()
        
        # ä¿å­˜æµ‹è¯•æ•°æ®
        train_path = os.path.join(temp_dir, 'train.csv')
        test_path = os.path.join(temp_dir, 'test.csv')
        train_data.to_csv(train_path, sep=' ', index=False)
        test_data.to_csv(test_path, sep=' ', index=False)
        
        # è¿è¡Œå®Œæ•´ç®¡é“
        preprocessor = DataPreprocessor()
        train_df, test_df = preprocessor.load_and_preprocess(train_path, test_path)
        
        # éªŒè¯ç»“æœ
        assert len(train_df) == len(train_data)
        assert len(test_df) == len(test_data)
        assert 'car_age' in train_df.columns
    
    def test_model_prediction(self):
        """æµ‹è¯•æ¨¡å‹é¢„æµ‹"""
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model = load_model('model/v28_lgb_model.pkl')
        
        # åˆ›å»ºæµ‹è¯•ç‰¹å¾
        X_test = create_test_features()
        
        # é¢„æµ‹
        predictions = model.predict(X_test)
        
        # éªŒè¯
        assert len(predictions) == len(X_test)
        assert all(p >= 0 for p in predictions)
```

### 3. æ€§èƒ½æµ‹è¯•

#### å‹åŠ›æµ‹è¯•

```python
import time
import numpy as np
from concurrent.futures import ThreadPoolExecutor


class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""
    
    def test_training_performance(self):
        """æµ‹è¯•è®­ç»ƒæ€§èƒ½"""
        # åˆ›å»ºå¤§è§„æ¨¡æµ‹è¯•æ•°æ®
        X = pd.DataFrame(np.random.rand(10000, 50))
        y = pd.Series(np.random.rand(10000) * 10000)
        
        trainer = ModelTrainer()
        
        start_time = time.time()
        trainer.train(X, y)
        duration = time.time() - start_time
        
        print(f"è®­ç»ƒæ—¶é—´: {duration:.2f}ç§’")
        assert duration < 300  # åº”åœ¨5åˆ†é’Ÿå†…å®Œæˆ
    
    def test_prediction_performance(self):
        """æµ‹è¯•é¢„æµ‹æ€§èƒ½"""
        model = load_model('model/v28_lgb_model.pkl')
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        X_test = pd.DataFrame(np.random.rand(10000, 50))
        
        start_time = time.time()
        predictions = model.predict(X_test)
        duration = time.time() - start_time
        
        print(f"é¢„æµ‹æ—¶é—´: {duration:.2f}ç§’")
        assert duration < 10  # åº”åœ¨10ç§’å†…å®Œæˆ
    
    def test_concurrent_predictions(self):
        """æµ‹è¯•å¹¶å‘é¢„æµ‹"""
        model = load_model('model/v28_lgb_model.pkl')
        
        def predict_worker(data):
            return model.predict(data)
        
        test_data = [pd.DataFrame(np.random.rand(100, 50)) for _ in range(10)]
        
        start_time = time.time()
        with ThreadPoolExecutor(max_workers=4) as executor:
            results = list(executor.map(predict_worker, test_data))
        duration = time.time() - start_time
        
        print(f"å¹¶å‘é¢„æµ‹æ—¶é—´: {duration:.2f}ç§’")
        assert len(results) == 10
```

## éƒ¨ç½²ç­–ç•¥

### 1. å¼€å‘ç¯å¢ƒéƒ¨ç½²

#### Dockerå®¹å™¨åŒ–éƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    make \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /app/data /app/model /app/output /app/logs

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV DATA_DIR=/app/data
ENV MODEL_DIR=/app/model
ENV OUTPUT_DIR=/app/output

# æš´éœ²ç«¯å£ï¼ˆå¦‚æœéœ€è¦APIæœåŠ¡ï¼‰
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["python", "code/modeling_v28.py"]
```

#### Docker Composeé…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  car-price-predictor:
    build: .
    container_name: car-price-predictor
    volumes:
      - ./data:/app/data
      - ./model:/app/model
      - ./output:/app/output
      - ./logs:/app/logs
    environment:
      - PYTHONUNBUFFERED=1
      - DATA_DIR=/app/data
      - MODEL_DIR=/app/model
      - OUTPUT_DIR=/app/output
    restart: unless-stopped
```

### 2. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### Kuberneteséƒ¨ç½²

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: car-price-predictor
  labels:
    app: car-price-predictor
spec:
  replicas: 2
  selector:
    matchLabels:
      app: car-price-predictor
  template:
    metadata:
      labels:
        app: car-price-predictor
    spec:
      containers:
      - name: predictor
        image: car-price-predictor:latest
        ports:
        - containerPort: 8000
        env:
        - name: MODEL_DIR
          value: "/app/model"
        - name: DATA_DIR
          value: "/app/data"
        volumeMounts:
        - name: model-volume
          mountPath: /app/model
        - name: data-volume
          mountPath: /app/data
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
      volumes:
      - name: model-volume
        persistentVolumeClaim:
          claimName: model-pvc
      - name: data-volume
        persistentVolumeClaim:
          claimName: data-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: predictor-service
spec:
  selector:
    app: car-price-predictor
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
```

### 3. APIæœåŠ¡éƒ¨ç½²

#### FastAPIæœåŠ¡

```python
# api_server.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import joblib
import pandas as pd
import numpy as np

app = FastAPI(title="äºŒæ‰‹è½¦ä»·æ ¼é¢„æµ‹API")

# åŠ è½½æ¨¡å‹
model = joblib.load('model/v28_lgb_model.pkl')


class CarFeatures(BaseModel):
    """è½¦è¾†ç‰¹å¾æ¨¡å‹"""
    power: int
    kilometer: float
    brand: int
    model: int
    bodyType: int
    fuelType: int
    gearbox: int
    car_age: int
    # ... å…¶ä»–ç‰¹å¾


class PredictionResponse(BaseModel):
    """é¢„æµ‹å“åº”æ¨¡å‹"""
    price: float
    confidence: float


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy"}


@app.post("/predict", response_model=PredictionResponse)
async def predict_price(features: CarFeatures):
    """é¢„æµ‹äºŒæ‰‹è½¦ä»·æ ¼"""
    try:
        # è½¬æ¢ä¸ºDataFrame
        X = pd.DataFrame([features.dict()])
        
        # ç‰¹å¾å·¥ç¨‹
        X = create_features(X)
        
        # é¢„æµ‹
        price = model.predict(X)[0]
        
        return PredictionResponse(
            price=max(0, price),
            confidence=0.85  # ç¤ºä¾‹ç½®ä¿¡åº¦
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/batch_predict")
async def batch_predict(features_list: list[CarFeatures]):
    """æ‰¹é‡é¢„æµ‹"""
    try:
        X = pd.DataFrame([f.dict() for f in features_list])
        X = create_features(X)
        predictions = model.predict(X)
        
        return {
            "predictions": [max(0, p) for p in predictions],
            "count": len(predictions)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### 4. ç›‘æ§å’Œæ—¥å¿—

#### æ—¥å¿—é…ç½®

```python
# logging_config.py
import logging
import logging.config

LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'standard': {
            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        },
        'detailed': {
            'format': '%(asctime)s [%(levelname)s] %(name)s:%(lineno)d: %(message)s'
        },
    },
    'handlers': {
        'console': {
            'level': 'INFO',
            'class': 'logging.StreamHandler',
            'formatter': 'standard',
            'stream': 'ext://sys.stdout'
        },
        'file': {
            'level': 'INFO',
            'class': 'logging.handlers.RotatingFileHandler',
            'formatter': 'detailed',
            'filename': 'logs/predictor.log',
            'maxBytes': 10485760,
            'backupCount': 5
        }
    },
    'loggers': {
        '': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': False
        }
    }
}

def setup_logging():
    logging.config.dictConfig(LOGGING_CONFIG)
```

### 5. CI/CDæµæ°´çº¿

#### GitHub Actionsé…ç½®

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.11, 3.12]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8
    
    - name: Lint with flake8
      run: |
        flake8 code/ --count --select=E9,F63,F7,F82 --show-source --statistics
    
    - name: Run tests
      run: |
        pytest tests/ --cov=code --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: |
        docker build -t car-price-predictor:${{ github.sha }} .
        docker tag car-price-predictor:${{ github.sha }} car-price-predictor:latest
    
    - name: Push to registry
      run: |
        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
        docker push car-price-predictor:${{ github.sha }}
        docker push car-price-predictor:latest
```

## éƒ¨ç½²éªŒè¯

### 1. éƒ¨ç½²åéªŒè¯

```python
# deployment_validator.py
import requests
import time
import logging

logger = logging.getLogger(__name__)

def validate_deployment(base_url: str, timeout: int = 60):
    """éªŒè¯éƒ¨ç½²æ˜¯å¦æˆåŠŸ"""
    
    # å¥åº·æ£€æŸ¥
    health_url = f"{base_url}/health"
    try:
        response = requests.get(health_url, timeout=5)
        if response.status_code == 200:
            logger.info("âœ… å¥åº·æ£€æŸ¥é€šè¿‡")
        else:
            logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"âŒ å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
        return False
    
    # åŠŸèƒ½æµ‹è¯•
    test_features = {
        "power": 150,
        "kilometer": 50000,
        "brand": 1,
        "model": 1,
        "bodyType": 1,
        "fuelType": 1,
        "gearbox": 1,
        "car_age": 5
    }
    
    predict_url = f"{base_url}/predict"
    try:
        response = requests.post(predict_url, json=test_features, timeout=10)
        if response.status_code == 200:
            result = response.json()
            if result.get("price") and result["price"] > 0:
                logger.info(f"âœ… é¢„æµ‹æµ‹è¯•é€šè¿‡ï¼Œä»·æ ¼: {result['price']}")
            else:
                logger.warning(f"âš ï¸ é¢„æµ‹ç»“æœå¼‚å¸¸: {result}")
        else:
            logger.error(f"âŒ é¢„æµ‹å¤±è´¥: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"âŒ é¢„æµ‹å¼‚å¸¸: {e}")
        return False
    
    logger.info("ğŸ‰ éƒ¨ç½²éªŒè¯å…¨éƒ¨é€šè¿‡")
    return True
```

### 2. å›æ»šç­–ç•¥

```python
# rollback_manager.py
import subprocess
import logging

logger = logging.getLogger(__name__)

class RollbackManager:
    """å›æ»šç®¡ç†å™¨"""
    
    def __init__(self, deployment_name: str, namespace: str = "default"):
        self.deployment_name = deployment_name
        self.namespace = namespace
    
    def rollback_to_version(self, version: str, timeout: int = 300):
        """å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬"""
        try:
            cmd = [
                "kubectl", "set", "image", "deployment", self.deployment_name,
                f"{self.deployment_name}=car-price-predictor:{version}",
                "-n", self.namespace
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                logger.info(f"âœ… å¼€å§‹å›æ»šåˆ°ç‰ˆæœ¬: {version}")
                return True
            else:
                logger.error(f"âŒ å›æ»šå¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ å›æ»šå¼‚å¸¸: {e}")
            return False
```

---

*æœ€åæ›´æ–°: 2026å¹´2æœˆ15æ—¥*
*æµ‹è¯•å’Œéƒ¨ç½²ç‰ˆæœ¬: v1.0*
*è¿ç»´å›¢é˜Ÿ: DevOpsè¿ç»´ç»„*
