# LangChain å·¥å…·é“¾ç»„åˆè®¾è®¡ - ä»£ç å®ç°è¯¦è§£

## æ ¸å¿ƒä»£ç ç»“æ„

### é¡¹ç›®æ–‡ä»¶æ¦‚è§ˆ

```
code/
â”œâ”€â”€ __init__.py              # æ¨¡å—æ¨¡å—åˆå§‹åŒ–
â”œâ”€â”€ main.py                  # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ tools/                   # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py          # å·¥å…·å¯¼å‡º
â”‚   â”œâ”€â”€ text_analysis.py     # æ–‡æœ¬åˆ†æå·¥å…·
â”‚   â”œâ”€â”€ data_conversion.py   # æ•°æ®è½¬æ¢å·¥å…·
â”‚   â”œâ”€â”€ text_processing.py   # æ–‡æœ¬å¤„ç†å·¥å…·
â”‚   â”œâ”€â”€ network_diagnosis.py # ç½‘ç»œè¯Šæ–­å·¥å…·
â”‚   â”œâ”€â”€ config_analysis.py   # é…ç½®åˆ†æå·¥å…·
â”‚   â””â”€â”€ log_analysis.py      # æ—¥å¿—åˆ†æå·¥å…·
â””â”€â”€ agents/                  # Agent æ¨¡å—
    â”œâ”€â”€ __init__.py          # Agent å¯¼å‡º
    â””â”€â”€ network_engineer_agent.py  # ç½‘ç»œå·¥ç¨‹å¸ˆ Agent
```

## ä¸»ç¨‹åºå…¥å£

### main.py

ä¸»ç¨‹åºæä¾›ä¸‰ç§è¿è¡Œæ¨¡å¼çš„å…¥å£ï¼š

```python
"""
LangChain å·¥å…·é“¾ç»„åˆè®¾è®¡ - ä¸»ç¨‹åºå…¥å£

ä½¿ç”¨æ–¹æ³•ï¼š
    python main.py --mode interactive    # äº¤äº’æ¨¡å¼
    python main.py --mode demo           # æ¼”ç¤ºæ¨¡å¼
    python main.py --mode test           # æµ‹è¯•æ¨¡å¼
"""

import os
import sys
import argparse
from pathlib import Path
from typing import Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

from dotenv import load_dotenv
load_dotenv()

# å¯¼å…¥å·¥å…·å’Œ Agent
from tools import (
    TextAnalysisTool,
    DataConversionTool,
    TextProcessingTool,
    NetworkDiagnosisTool,
    ConfigAnalysisTool,
    LogAnalysisTool,
)
from agents import NetworkEngineerAgent


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="LangChain å·¥å…·é“¾ç»„åˆè®¾è®¡ - ç½‘ç»œå·¥ç¨‹å¸ˆæ™ºèƒ½åŠ©æ‰‹"
    )
    parser.add_argument(
        "--mode",
        choices=["interactive", "demo", "test"],
        default="interactive",
        help="è¿è¡Œæ¨¡å¼ï¼šinteractiveï¼ˆäº¤äº’ï¼‰ã€demoï¼ˆæ¼”ç¤ºï¼‰ã€testï¼ˆæµ‹è¯•ï¼‰"
    )
    
    args = parser.parse_args()
    
    if args.mode == "interactive":
        interactive_mode()
    elif args.mode == "demo":
        demo_mode()
    elif args.mode == "test":
        test_mode()


if __name__ == "__main__":
    main()
```

### äº¤äº’æ¨¡å¼å®ç°

```python
def interactive_mode():
    """äº¤äº’æ¨¡å¼ - ä¸ Agent å¯¹è¯"""
    print_banner()
    
    # æ£€æŸ¥ API Key
    api_key = os.environ.get("DASHSCOPE_API_KEY") or os.environ.get("OPENAI_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½® DASHSCOPE_API_KEY æˆ– OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    # ç¡®å®š LLM ç±»å‹
    llm_type = "tongyi" if os.environ.get("DASHSCOPE_API_KEY") else "openai"
    
    try:
        # åˆ›å»º Agent
        print("\næ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½åŠ©æ‰‹...")
        agent = NetworkEngineerAgent(llm_type=llm_type, verbose=True)
        
        print("\nâœ… æ™ºèƒ½åŠ©æ‰‹å·²å°±ç»ªï¼")
        
        while True:
            try:
                user_input = input("\nğŸ‘¤ ä½ : ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() == "quit":
                    print("\nğŸ‘‹ å†è§ï¼")
                    break
                
                if user_input.lower() == "clear":
                    agent.clear_memory()
                    print("âœ… å¯¹è¯è®°å¿†å·²æ¸…é™¤")
                    continue
                
                # è·å–å“åº”
                print("\nğŸ¤– åŠ©æ‰‹: ", end="")
                response = agent.chat(user_input)
                print(response)
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼")
                break
                
    except Exception as e:
        print(f"\nâŒ åˆå§‹åŒ–å¤±è´¥: {e}")
```

## å·¥å…·ç±»è¯¦è§£

### 1. æ–‡æœ¬åˆ†æå·¥å…· (TextAnalysisTool)

#### ç±»å®šä¹‰
```python
class TextAnalysisTool:
    """æ–‡æœ¬åˆ†æå·¥å…·ç±»"""
    
    def __init__(self):
        self.name = "æ–‡æœ¬åˆ†æå·¥å…·"
        self.description = (
            "åˆ†ææ–‡æœ¬å†…å®¹çš„å·¥å…·ã€‚"
            "å¯ä»¥ç»Ÿè®¡å­—æ•°ã€å­—ç¬¦æ•°ï¼Œè¿›è¡Œæƒ…æ„Ÿåˆ†æï¼Œæå–å…³é”®è¯ã€‚"
        )
```

#### æ ¸å¿ƒæ–¹æ³•
```python
def run(self, text: str) -> str:
    """è¿è¡Œæ–‡æœ¬åˆ†æ"""
    if not text or not isinstance(text, str):
        return "é”™è¯¯ï¼šè¯·æä¾›æœ‰æ•ˆçš„æ–‡æœ¬å†…å®¹"
    
    result = self._analyze(text)
    return self._format_result(result)

def _analyze(self, text: str) -> Dict[str, Any]:
    """æ‰§è¡Œæ–‡æœ¬åˆ†æ"""
    # åŸºç¡€ç»Ÿè®¡
    char_count = len(text)
    char_count_no_space = len(text.replace(" ", "").replace("\n", ""))
    
    # ä¸­æ–‡å’Œè‹±æ–‡åˆ†åˆ«ç»Ÿè®¡
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    english_words = re.findall(r'[a-zA-Z]+', text)
    
    # å…³é”®è¯æå–
    keywords = self._extract_keywords(text)
    
    # æƒ…æ„Ÿåˆ†æ
    sentiment = self._simple_sentiment(text)
    
    return {
        "å­—ç¬¦æ€»æ•°": char_count,
        "ä¸­æ–‡å­—ç¬¦æ•°": len(chinese_chars),
        "è‹±æ–‡å•è¯æ•°": len(english_words),
        "é«˜é¢‘å…³é”®è¯": keywords,
        "æƒ…æ„Ÿå€¾å‘": sentiment,
    }
```

#### LangChain Tool å°è£…
```python
def create_text_analysis_tool():
    """åˆ›å»º LangChain Tool å®ä¾‹"""
    from langchain_core.tools import Tool
    
    tool = TextAnalysisTool()
    return Tool(
        name=tool.name,
        func=tool.run,
        description=tool.description
    )
```

### 2. æ•°æ®è½¬æ¢å·¥å…· (DataConversionTool)

#### ç±»å®šä¹‰
```python
class DataConversionTool:
    """æ•°æ®è½¬æ¢å·¥å…·ç±»"""
    
    def __init__(self):
        self.name = "æ•°æ®è½¬æ¢å·¥å…·"
        self.description = (
            "æ•°æ®æ ¼å¼è½¬æ¢å·¥å…·ã€‚"
            "æ”¯æŒ JSON/YAML/CSV æ ¼å¼äº’è½¬ï¼Œæ•°æ®æ ¼å¼éªŒè¯ã€‚"
            "è¾“å…¥æ ¼å¼ï¼š'è½¬æ¢ç±»å‹|æ•°æ®å†…å®¹'"
        )
```

#### è½¬æ¢æ–¹æ³•
```python
def run(self, input_str: str) -> str:
    """è¿è¡Œæ•°æ®è½¬æ¢"""
    if not input_str or "|" not in input_str:
        return self._show_usage()
    
    parts = input_str.split("|", 1)
    conversion_type = parts[0].strip().lower()
    data = parts[1].strip()
    
    return self._convert(conversion_type, data)

def _convert(self, conversion_type: str, data: str) -> str:
    """æ‰§è¡Œè½¬æ¢"""
    converters = {
        "json2yaml": self._json_to_yaml,
        "yaml2json": self._yaml_to_json,
        "json2csv": self._json_to_csv,
        "validate": self._validate_json,
        "format": self._format_json,
        "cisco2json": self._cisco_to_json,
    }
    
    return converters[conversion_type](data)
```

### 3. æ–‡æœ¬å¤„ç†å·¥å…· (TextProcessingTool)

#### ç±»å®šä¹‰
```python
class TextProcessingTool:
    """æ–‡æœ¬å¤„ç†å·¥å…·ç±»"""
    
    def __init__(self):
        self.name = "æ–‡æœ¬å¤„ç†å·¥å…·"
        self.description = (
            "æ–‡æœ¬å¤„ç†å·¥å…·ã€‚"
            "æ”¯æŒæ–‡æœ¬æ¸…æ´—ã€åˆ†å‰²ã€æ­£åˆ™åŒ¹é…ç­‰æ“ä½œã€‚"
        )
```

#### å¤„ç†æ–¹æ³•
```python
def run(self, input_str: str) -> str:
    """è¿è¡Œæ–‡æœ¬å¤„ç†"""
    parts = input_str.split("|")
    process_type = parts[0].strip().lower()
    
    if len(parts) == 2:
        data = parts[1]
        return self._process(process_type, data)
    else:
        param = parts[1].strip()
        data = "|".join(parts[2:])
        return self._process_with_param(process_type, param, data)

def _process(self, process_type: str, data: str) -> str:
    """æ‰§è¡Œå¤„ç†"""
    processors = {
        "clean": self._clean_text,
        "extract_ip": self._extract_ips,
        "extract_url": self._extract_urls,
        "extract_email": self._extract_emails,
        "lowercase": lambda x: x.lower(),
        "uppercase": lambda x: x.upper(),
    }
    return processors[process_type](data)
```

### 4. ç½‘ç»œè¯Šæ–­å·¥å…· (NetworkDiagnosisTool)

#### ç±»å®šä¹‰
```python
class NetworkDiagnosisTool:
    """ç½‘ç»œè¯Šæ–­å·¥å…·ç±»ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
    
    def __init__(self):
        self.name = "ç½‘ç»œè¯Šæ–­å·¥å…·"
        # æ¨¡æ‹Ÿå·²çŸ¥ä¸»æœº
        self.known_hosts = {
            "www.baidu.com": {"ip": "180.101.50.188", "status": "up"},
            "www.google.com": {"ip": "142.250.189.68", "status": "up"},
            "localhost": {"ip": "127.0.0.1", "status": "up"},
        }
```

#### è¯Šæ–­æ–¹æ³•
```python
def run(self, input_str: str) -> str:
    """è¿è¡Œç½‘ç»œè¯Šæ–­"""
    parts = input_str.split("|")
    diag_type = parts[0].strip().lower()
    
    diags = {
        "ping": self._ping,
        "dns": self._dns_lookup,
        "port": self._port_check,
        "trace": self._traceroute,
        "check": self._comprehensive_check,
    }
    
    return diags[diag_type](target, *args)

def _ping(self, target: str) -> str:
    """æ¨¡æ‹Ÿ Ping æµ‹è¯•"""
    host_info = self.known_hosts.get(target)
    if host_info and host_info["status"] == "up":
        # è¿”å›æˆåŠŸç»“æœ
        return f"Ping {target} [{host_info['ip']}]: ä¸»æœºå¯è¾¾"
    else:
        return f"Ping {target}: ä¸»æœºä¸å¯è¾¾"
```

### 5. é…ç½®åˆ†æå·¥å…· (ConfigAnalysisTool)

#### ç±»å®šä¹‰
```python
class ConfigAnalysisTool:
    """é…ç½®åˆ†æå·¥å…·ç±»"""
    
    def __init__(self):
        self.name = "é…ç½®åˆ†æå·¥å…·"
        # å®‰å…¨æ£€æŸ¥è§„åˆ™
        self.security_rules = {
            "password_encryption": {
                "pattern": r"service password-encryption",
                "description": "å¯†ç åŠ å¯†æœåŠ¡",
                "severity": "é«˜"
            },
            "ssh_enabled": {
                "pattern": r"line vty.*\n.*transport input ssh",
                "description": "SSH è¿œç¨‹è®¿é—®",
                "severity": "é«˜"
            },
            # ... æ›´å¤šè§„åˆ™
        }
```

#### åˆ†ææ–¹æ³•
```python
def run(self, input_str: str) -> str:
    """è¿è¡Œé…ç½®åˆ†æ"""
    parts = input_str.split("|", 1)
    analysis_type = parts[0].strip().lower()
    config = parts[1].strip()
    
    analyzers = {
        "parse": self._parse_config,
        "security": self._security_check,
        "interfaces": self._extract_interfaces,
        "routing": self._extract_routing,
        "acl": self._extract_acl,
        "vendor": self._identify_vendor,
    }
    
    return analyzers[analysis_type](config)

def _security_check(self, config: str) -> str:
    """å®‰å…¨é…ç½®æ£€æŸ¥"""
    passed = []
    failed = []
    
    for rule_name, rule in self.security_rules.items():
        if re.search(rule["pattern"], config, re.MULTILINE):
            passed.append(rule["description"])
        else:
            failed.append(rule["description"])
    
    # è®¡ç®—å®‰å…¨è¯„åˆ†
    score = int((len(passed) / len(self.security_rules)) * 100)
    
    return f"å®‰å…¨è¯„åˆ†ï¼š{score}/100"
```

### 6. æ—¥å¿—åˆ†æå·¥å…· (LogAnalysisTool)

#### ç±»å®šä¹‰
```python
class LogAnalysisTool:
    """æ—¥å¿—åˆ†æå·¥å…·ç±»"""
    
    def __init__(self):
        self.name = "æ—¥å¿—åˆ†æå·¥å…·"
        # é”™è¯¯çº§åˆ«å…³é”®è¯
        self.error_keywords = {
            "critical": ["critical", "fatal", "CRITICAL", "FATAL"],
            "error": ["error", "fail", "ERROR", "FAIL"],
            "warning": ["warning", "warn", "WARNING", "WARN"],
            "info": ["info", "INFO"],
        }
```

#### åˆ†ææ–¹æ³•
```python
def run(self, input_str: str) -> str:
    """è¿è¡Œæ—¥å¿—åˆ†æ"""
    parts = input_str.split("|", 1)
    analysis_type = parts[0].strip().lower()
    logs = parts[1].strip()
    
    analyzers = {
        "summary": self._log_summary,
        "errors": self._extract_errors,
        "ips": self._ip_statistics,
        "patterns": self._pattern_recognition,
        "firewall": self._firewall_analysis,
        "level": self._level_statistics,
    }
    
    return analyzers[analysis_type](logs)

def _extract_errors(self, logs: str) -> str:
    """æå–é”™è¯¯æ—¥å¿—"""
    error_lines = []
    for line in logs.split("\n"):
        for level, keywords in self.error_keywords.items():
            if level in ["critical", "error", "warning"]:
                for kw in keywords:
                    if kw in line:
                        error_lines.append((level, line))
                        break
    return self._format_errors(error_lines)
```

## NetworkEngineerAgent å®ç°

### ç±»å®šä¹‰

```python
class NetworkEngineerAgent:
    """ç½‘ç»œå·¥ç¨‹å¸ˆæ™ºèƒ½åŠ©æ‰‹"""
    
    def __init__(
        self,
        llm_type: str = "tongyi",
        model_name: str = "qwen-turbo",
        api_key: Optional[str] = None,
        verbose: bool = True,
    ):
        # åˆå§‹åŒ– LLM
        self.llm = self._init_llm(llm_type, model_name, api_key)
        
        # åˆå§‹åŒ–å·¥å…·
        self.tools = self._init_tools()
        self.tools_dict = {tool.name: tool for tool in self.tools}
        
        # åˆå§‹åŒ–è®°å¿†
        self.memory: List[Dict] = []
        
        # åˆå§‹åŒ–ç³»ç»Ÿæç¤º
        self.system_prompt = self._build_system_prompt()
```

### LLM é›†æˆ

```python
def _init_llm(self, llm_type: str, model_name: str, api_key: Optional[str]):
    """åˆå§‹åŒ– LLM"""
    if llm_type == "tongyi":
        from langchain_community.llms import Tongyi
        dashscope_api_key = api_key or os.environ.get("DASHSCOPE_API_KEY")
        return Tongyi(
            model_name=model_name,
            dashscope_api_key=dashscope_api_key,
            temperature=0.7,
        )
    
    elif llm_type == "openai":
        from langchain_openai import ChatOpenAI
        openai_api_key = api_key or os.environ.get("OPENAI_API_KEY")
        return ChatOpenAI(
            model=model_name,
            openai_api_key=openai_api_key,
            temperature=0.7,
        )
```

### å·¥å…·æ³¨å†Œ

```python
def _init_tools(self) -> List[Tool]:
    """åˆå§‹åŒ–å·¥å…·åˆ—è¡¨"""
    tools = [
        Tool(
            name="æ–‡æœ¬åˆ†æ",
            func=TextAnalysisTool().run,
            description="åˆ†ææ–‡æœ¬å†…å®¹çš„å·¥å…·..."
        ),
        Tool(
            name="æ•°æ®è½¬æ¢",
            func=DataConversionTool().run,
            description="æ•°æ®æ ¼å¼è½¬æ¢å·¥å…·..."
        ),
        # ... æ›´å¤šå·¥å…·
    ]
    return tools
```

### ç³»ç»Ÿæç¤ºè¯

```python
def _build_system_prompt(self) -> str:
    """æ„å»ºç³»ç»Ÿæç¤º"""
    tool_descriptions = "\n".join([
        f"- {tool.name}: {tool.description}"
        for tool in self.tools
    ])
    
    return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç½‘ç»œå·¥ç¨‹å¸ˆæ™ºèƒ½åŠ©æ‰‹ï¼Œæ“…é•¿ç½‘ç»œæ•…éšœè¯Šæ–­ã€é…ç½®åˆ†æå’Œæ—¥å¿—å¤„ç†ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ï¼š

{tool_descriptions}

å½“éœ€è¦ä½¿ç”¨å·¥å…·æ—¶ï¼Œè¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›å¤ï¼š
ã€ä½¿ç”¨å·¥å…·ï¼šå·¥å…·åç§°ã€‘
ã€è¾“å…¥å‚æ•°ï¼šå‚æ•°å†…å®¹ã€‘

è¯·å§‹ç»ˆç”¨ä¸­æ–‡å›å¤ï¼Œä¿æŒä¸“ä¸šå’Œå‹å¥½çš„æ€åº¦ã€‚"""
```

### å·¥å…·è°ƒç”¨æœºåˆ¶

```python
def _parse_tool_call(self, response: str) -> Optional[Dict[str, str]]:
    """è§£æå·¥å…·è°ƒç”¨"""
    import re
    
    tool_pattern = r'ã€ä½¿ç”¨å·¥å…·[ï¼š:]\s*([^ã€‘]+)ã€‘'
    input_pattern = r'ã€è¾“å…¥å‚æ•°[ï¼š:]\s*([^ã€‘]+)ã€‘'
    
    tool_match = re.search(tool_pattern, response)
    input_match = re.search(input_pattern, response)
    
    if tool_match:
        return {
            "tool_name": tool_match.group(1).strip(),
            "tool_input": input_match.group(1).strip() if input_match else ""
        }
    return None
```

### è¿è¡Œæµç¨‹

```python
def run(self, query: str) -> str:
    """è¿è¡Œ Agent"""
    # æ„å»ºå¯¹è¯å†å²
    conversation = f"ç³»ç»Ÿæç¤ºï¼š{self.system_prompt}\n\n"
    
    for msg in self.memory[-5:]:
        conversation += f"ç”¨æˆ·ï¼š{msg['user']}\n"
        conversation += f"åŠ©æ‰‹ï¼š{msg['assistant']}\n"
    
    conversation += f"ç”¨æˆ·ï¼š{query}\nåŠ©æ‰‹ï¼š"
    
    # è·å– LLM å“åº”
    response = self.llm.invoke(conversation)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
    tool_call = self._parse_tool_call(response)
    
    if tool_call:
        tool_name = tool_call["tool_name"]
        tool_input = tool_call["tool_input"]
        
        if tool_name in self.tools_dict:
            # æ‰§è¡Œå·¥å…·
            tool_result = self.tools_dict[tool_name].invoke(tool_input)
            
            # å°†å·¥å…·ç»“æœåé¦ˆç»™ LLM
            conversation += f"{response}\n\nå·¥å…·è¿”å›ç»“æœï¼š\n{tool_result}\n\nè¯·æ ¹æ®ç»“æœå›ç­”ï¼š"
            
            final_response = self.llm.invoke(conversation)
            
            # ä¿å­˜è®°å¿†
            self.memory.append({
                "user": query,
                "assistant": final_response
            })
            
            return final_response
    
    # ä¿å­˜è®°å¿†
    self.memory.append({
        "user": query,
        "assistant": response
    })
    
    return response
```

### å·¥å‚å‡½æ•°

```python
def create_network_engineer_agent(
    llm_type: str = "tongyi",
    model_name: str = "qwen-turbo",
    api_key: Optional[str] = None,
    verbose: bool = True,
) -> NetworkEngineerAgent:
    """åˆ›å»ºç½‘ç»œå·¥ç¨‹å¸ˆ Agent çš„å·¥å‚å‡½æ•°"""
    return NetworkEngineerAgent(
        llm_type=llm_type,
        model_name=model_name,
        api_key=api_key,
        verbose=verbose,
    )
```

## é”™è¯¯å¤„ç†

### 1. å·¥å…·é”™è¯¯å¤„ç†

```python
def run(self, input_str: str) -> str:
    try:
        # æ‰§è¡Œå·¥å…·é€»è¾‘
        return result
    except Exception as e:
        return f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}"
```

### 2. Agent é”™è¯¯å¤„ç†

```python
def run(self, query: str) -> str:
    try:
        response = self.llm.invoke(conversation)
        return response
    except Exception as e:
        return f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}"
```

## ä»£ç ç»„ç»‡æœ€ä½³å®è·µ

### 1. æ¨¡å—åŒ–è®¾è®¡
- æ¯ä¸ªå·¥å…·ç‹¬ç«‹æ–‡ä»¶
- ç»Ÿä¸€çš„æ¥å£è§„èŒƒ
- æ¸…æ™°çš„ä¾èµ–å…³ç³»

### 2. ç±»å‹æç¤º
```python
from typing import Dict, List, Optional, Any

def run(self, input_str: str) -> str:
    ...

def _analyze(self, text: str) -> Dict[str, Any]:
    ...
```

### 3. æ–‡æ¡£å­—ç¬¦ä¸²
```python
def run(self, input_str: str) -> str:
    """
    è¿è¡Œæ–‡æœ¬åˆ†æ
    
    Args:
        input_str: è¾“å…¥å‚æ•°å­—ç¬¦ä¸²
        
    Returns:
        åˆ†æç»“æœå­—ç¬¦ä¸²
    """
```

---

*æœ€åæ›´æ–°: 2026å¹´2æœˆ17æ—¥*
*æ–‡æ¡£ç‰ˆæœ¬: v1.0*
*ç»´æŠ¤å›¢é˜Ÿ: build-your-own-aié¡¹ç›®å›¢é˜Ÿ*
