# DeepSeek使用与Prompt工程项目 - 项目概述

## 项目简介

DeepSeek使用与Prompt工程项目是一个完整的大模型应用实践项目，演示了如何通过多种方式调用DeepSeek大模型，并深入学习Prompt工程技术。该项目涵盖了从云端API调用到本地模型部署的完整技术栈，为开发者提供了丰富的实践案例。

## 核心功能

### 1. DeepSeek API调用
- 通过阿里云DashScope代理调用DeepSeek API
- 支持DeepSeek-V3和DeepSeek-R1模型
- 完整的对话和情感分析示例
- 灵活的参数配置

### 2. Prompt工程实践
- 结构化Prompt设计模式
- 输出格式控制（JSON模式）
- 任务分解与条件判断
- 提示词优化技巧

### 3. 本地模型部署
- ModelScope模型下载与管理
- DeepSeek-R1本地推理
- Ollama本地运行环境
- 多种模型规格支持

### 4. 服务封装与部署
- FastAPI RESTful服务
- 流式响应处理
- Python客户端封装
- 生产环境部署方案

## 应用场景

### 1. 智能客服系统
- 产品咨询自动回复
- 用户意图识别
- 多轮对话管理
- 服务规范检查

### 2. 数据分析助手
- 结构化数据提取
- 文本情感分析
- 信息分类整理
- 报告自动生成

### 3. 内容创作工具
- 文案自动生成
- 内容优化建议
- 风格转换
- 多语言支持

### 4. 开发辅助工具
- 代码生成与补全
- 代码审查
- 文档自动生成
- 技术问题解答

## 技术特点

### 1. 多样化调用方式
- **云端API**: 通过阿里云DashScope代理，稳定可靠
- **本地部署**: 支持Ollama和ModelScope两种本地方案
- **服务封装**: FastAPI提供标准化RESTful接口

### 2. Prompt工程最佳实践
- 结构化Prompt模板
- 明确的任务描述
- 输出格式控制
- 上下文管理

### 3. 灵活的部署方案
- 支持云端和本地混合部署
- 容器化部署支持
- 流式和非流式响应
- 可扩展的架构设计

### 4. 完整的示例代码
- 涵盖多种使用场景
- 详细的代码注释
- 可直接运行的示例
- 最佳实践参考

## 项目结构

```
02-CASE-DeepSeek使用与Prompt工程/
├── code/                               # 核心代码目录
│   ├── 1-情感分析-Deepseek-阿里代理.py   # API基础调用示例
│   ├── 2-提示词工程使用.py               # Prompt工程实践
│   ├── 3-deepseek-r1-7b使用.py          # 本地模型推理
│   ├── 4-model-download.py             # 模型下载脚本
│   ├── 5-ollama使用.py                 # Ollama基础调用
│   ├── 6-ollama-stream.py              # 流式响应处理
│   ├── 7-ollama-fastapi.py             # FastAPI服务端
│   └── 7-ollama-fastapi-python客户端.py # FastAPI客户端
├── docs/                               # 文档目录
│   ├── 00-文档索引.md                   # 文档导航
│   ├── 01-项目概述.md                   # 本文档
│   ├── 02-技术架构.md                   # 技术架构
│   ├── 03-使用指南.md                   # 使用指南
│   ├── 04-代码实现.md                   # 代码实现
│   └── 05-测试和部署.md                 # 测试部署
├── models/                             # 本地模型存储目录
└── README.md                           # 项目说明文档
```

## 技术栈

### 核心技术
- **Python 3.11+**: 主要编程语言
- **DashScope**: 阿里云AI服务平台
- **ModelScope**: 模型下载与管理
- **Ollama**: 本地大模型运行环境
- **FastAPI**: 现代Web框架

### API与模型
- **DeepSeek-V3**: 通用对话模型
- **DeepSeek-R1**: 推理增强模型
- **DeepSeek-R1-Distill**: 轻量级蒸馏模型

### 依赖库
- **dashscope**: 阿里云API SDK
- **modelscope**: 模型管理库
- **torch**: 深度学习框架
- **transformers**: Hugging Face库
- **requests**: HTTP请求库
- **uvicorn**: ASGI服务器

## 性能指标

### API调用性能
- **响应时间**: 1-3秒（非流式）
- **流式响应**: 首token 100-300ms
- **并发支持**: 支持多用户并发

### 本地模型性能
| 模型规格 | 参数量 | 显存需求 | 推理速度 |
|---------|-------|---------|---------|
| 1.5B | 15亿 | 4GB | 快 |
| 7B | 70亿 | 8GB | 中等 |
| 8B | 80亿 | 10GB | 中等 |

### Prompt优化效果
- **输出准确性**: 提升30-50%
- **格式规范率**: 提升80%+
- **任务完成率**: 提升40%+

## 项目价值

### 1. 学习价值
- 掌握大模型API调用方法
- 深入理解Prompt工程技术
- 学习本地模型部署方案
- 了解生产环境最佳实践

### 2. 实用价值
- 提供可直接使用的代码示例
- 支持多种部署场景
- 可扩展的架构设计
- 完整的文档支持

### 3. 技术价值
- 展示大模型应用的最佳实践
- 提供多种技术方案对比
- 推动AI技术的普及应用
- 为企业AI落地提供参考

## 发展规划

### 短期目标
- [x] 完成基础API调用示例
- [x] 实现Prompt工程实践
- [x] 支持本地模型部署
- [ ] 添加更多应用场景示例

### 中期目标
- [ ] 支持更多模型（Qwen、GLM等）
- [ ] 实现RAG应用集成
- [ ] 添加Function Calling示例
- [ ] 完善测试覆盖

### 长期目标
- [ ] 构建完整的AI应用框架
- [ ] 支持多模态能力
- [ ] 实现Agent智能体
- [ ] 企业级部署方案

---

*最后更新: 2026年2月21日*
*项目版本: v1.0*
*技术支持: build-your-own-ai项目团队*
