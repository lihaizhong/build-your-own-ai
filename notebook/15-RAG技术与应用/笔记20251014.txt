Q：上次那个酒店推荐系统的向量也是做词频作为特征计算3347维的余弦相似度吗
TFIDF = TF（词频） * IDF （逆向文档率）

Q：我的理解是，训练是一个确定的操作，不存在随机性，每次训练，只要参数不变，训练得到的结果都相关，我的理解对吗？
random_state 随机数种子

Q：请问使用wucai的时候，“剩余x%上下文”指的是什么？我原来理解是对当前项目的分析+当前已经生成的thinking和代码
对的，prompt会累计，多轮对话，每一次对话都会有token

Q：但发现每次输入新的指令后，这个上下文都会变回100%。所以不是很理解。
不应该是100%，还在查找问题的原因
LLM 回复的时候会有一个 usage告诉我他消耗了多少token

Q：wucai 能不能支持API
后面可以考虑

Q：32b和70b的模型差距大嘛？用户语义和知识库的理解
差距不大


Q：tesseract-ocr-w64-setup-5.5.0.20241111 这个文件需要先安装吗？
应该是需要的

Q：wucai 压缩的对话 怎么解压出来重新用？
/compact 压缩之后，就成为你的上下文 history


Q：二手车用catboost跑了3万4千轮，终于到497分了
恭喜


Q：老师wucai cli开源吗？
免费使用，但是不开源

Q：老师dashscope的API运行几次token就用完了，有免费的平替API提供吗
如果你用的wucai，可以用 Qwen OAuth


Q：今天讲的这个RAG跟之前在扣子做的知识库有啥区别，底层原理一样吗？
底层原理一样，Coze低代码（使用远程的SaaS），今天是高代码（自己本地可以控制的）


Q：embedding的数据，是找邻居的个数，怎么变成向量那种0.几的数据
embedding = 多维向量，1024维，打印出来就是 [0.01, ...


Q：对 我也是跑了3万多才到500以下


Q：我们的数据集只有15万 为啥能训练3万多轮 这个合理吗
应该不需要那么多轮，重点还是特征工程

Q：LLM上下文窗口有大小限制，超过了这个大小怎么办
compact

Q：老师的wucai是本地部署的qwen3吗？用的是多大的模型
qwen3-coder-plus


Q：model = word2vec.Word2Vec(sentences, vector_size=200, window=3, min_count=2)
这个参数设置怎么是最优的？



Q：老师 YOLO钢铁缺陷检测那个打卡 训练是一定要显卡吗？我笔记本光跑demo 5 epoch就花了2小时。。。
不一定是显卡，我在本地用 yolov12，cpu，也花了2个小时


Q：五彩可以读取word格式的接口文档，然后写程序代码么？我是了下千问网页版可以
应该是可以的

npm install -g @wucai/wucai-code


https://huggingface.co/spaces/mteb/leaderboard



Query => 知识库有1000万的chunks （500个token）
=> 100个chunk （相似度高的100）
=> 10个chunk（Rerank）


1000万 => 粗筛 100人 => 面试 （计算成本要高于 粗筛成本）


1000万 => 面试 找10人


Q：CHUNK 是向量吗?
chunk 是原文小块 => 下一步需要转换成 向量


Q：rag一定要清洗再重新向量化吗？我有个例子，往数据库（密塔）中把文档（十几篇国外的规范）扔进去后面用检索的问题时候还不错。还是说密塔在我放进去的时候已经rag了
向量是模糊查询；
如果没有向量数据库，不做模糊查询 => 也可以做RAG
关键词查询


Q：chuck的大小怎么定的？
人定的，
小一些：300-500 => 适合回答细节问题
中等：600-800
大一些：1000 => 适合回答整体的宏观一些的问题

Q：检索：就是 “翻书找答案”。AI用我们之前讲的“感觉相机”（Embeddings）和“超级管理员”（向量数据库），从一堆资料里迅速找到和你问题最相关的内容。


Q：kimi是不是一个增强版的RAG？
是，RAG很强
kimi 这个大模型，非常适合做长文的理解
RAG 可以准备多个文档，很长的RAG知识


Q：怎么确定通过向量计算后找到的备选答案是比较合适的答案，是不是需要定义一个向量计算的值，达到这个值或者超过这个值的答案才筛选出来，这个值的定义或者设置是怎么实现？
TopK，最好的K个知识
阈值，

那你再把你讲的穿一遍，让我们整体了解一下



rag相当于外部数据库？是不是可以理解为通用大模型也有自己的rag内部
数据库，那query的时候是怎么决定查询内外部数据库的？


embedding模型 VS LLM模型
embedding模型 => 知识的一种向量化，一种转义，计算机语言中的这个知识的表达，会有固定的向量长度，比如1024维

LLM模型 => 问答，回答用户的问题

instruction 指令问题，比如 翻译这篇文章，用不超过2000字

Question = [指令] + [信息]

模型ID：BAAI/bge-m3
BAAI/bge-m3

#模型下载
from modelscope import snapshot_download
model_dir = snapshot_download('BAAI/bge-m3', cache_dir='/root/autodl-tmp/models')


Q：回答的描述性文案生成，是怎么生成的？把所有相似度高的文字累计起来吗？
embedding => 目的是从向量数据库中检索相似的知识 R
A => 知识库 + question => LLM
G 

把所有相似度高的文字累计起来 送给大模型，大模型来生成答案


Q：embedding会输出相似度高的一整个chunk还是会把chunk自己总结切分一下输出呢


Q：从token的embedding到段落内容的embedding是怎么计算的？
word2vec => word embedding
sentence => 100个word embedding


Q：昨天讲的WORD2VEC是Embedding 模型吗
是的
king, woman, man

Q：如果kimi作为rag已经不错了，本地的RAG只是数据安全问题才需要吗？要是光有数据，没有问题，就不是rag了吗
kimi 的数据是来自互联网（数据源）
我们的数据如果很多，kimi 也不是对所有的数据进行 RAG
1000万chunks



Q：原始数据先分片，然后再向量，然后再存储到数据库中对吗？



Q：比如刚才的例子，一个问题才几个字，但是他匹配的答案确实几十个字，他们的embedding向量的维度都是一样的吗？那假如字数超过了向量维度呢？
是的，字数1个字 也是1024维
10000个字 也是1024维


Q：如果使用query召回到两段相似的chunk，但这两段相似的chunk包含了不同的含义，就是看起来相似但实际上不相似
embedding模型 对于query提问要找的知识理解，能力如何？ =>粗筛



# 检索 TopK个 相似的知识
docs = knowledgeBase.similarity_search(query,k=2)

input_data = {"input_documents": docs, "question": query}

1、跑通代码 =>输出结果



Q：有点不明白，比方PDF文件作为知识库，分多个chunk, 如何分解，如果一页（或2页）一个chunk，这样的话有可能一个知识点，被分到2个chunk里。
是的，这种切分策略，不一定是最优；
方法1：固定规则，不超过1000个token，标点符号
overlap 补偿策略

方法2：LLM进行切分（消耗LLM的token）



Q：pdf含图片怎么办？
qwen-vl 对图片内容进行理解


Q：chain问答链什么作用
langchain 是一个LLM框架，里面有很多封装好的工具
QA Chain 就是针对QA任务已经封装好了工具，可以直接用


text-embedding-v3, text-embedding-v4
1024, 1024


CLIP：支持图像的理解，也支持文字的理解 （多模态：图像模态 + 文本模态）

OCR：
 

--- 步骤 1 & 2: 正在解析、Embedding并索引知识库 ---
  - 正在处理: 1-上海迪士尼门票规则.docx
  - 正在处理: 2-迪士尼老人票价规定.docx
  - 正在处理: 3-迪士尼乐园游玩攻略清单.docx
  - 正在处理: 4-上海迪士尼乐园酒店会员制度.docx
  - 正在处理独立图片文件...
    - 处理图片: 1-聚在一起说奇妙.jpg
    - 处理图片: 2-万圣节.jpeg
索引构建完成。共索引 30 个文本片段和 2 张图片。

=============================================
迪士尼客服RAG助手已准备就绪，开始模拟提问。
=============================================

--- 收到用户提问: '我想了解一下迪士尼门票的退款流程' ---
  - 步骤 1: 向量化查询并进行检索...
    - 文本检索命中 (ID: 0, 距离: 0.5303)
    - 文本检索命中 (ID: 1, 距离: 0.6309)
    - 文本检索命中 (ID: 2, 距离: 0.6513)
  - 步骤 2: 构建 Prompt...
--- Prompt Start ---
你是一个迪士尼客服助手。请根据以下背景知识，用友好和专业的语气回答用户的问题。请只使用背景知识中的信息，不要自行发挥。

[背景知识]
背景知识 1 (来源: 1-上海迪士尼门票规则.docx):
上海迪士尼门票规则

背景知识 2 (来源: 1-上海迪士尼门票规则.docx):
上海迪士尼乐园门票分为一日票、两日票和特定日票三种类型。一日票可在购买时选定日期使用，价格根据季节浮动，平日成人票475元起，高峰日659元起，特别高峰日799元起。 两日票需连续两天使用，总价比购买两天单日票优惠约9折。特定日票包含部分节庆活动时段，需注意门票标注的有效期限。

背景知识 3 (来源: 1-上海迪士尼门票规则.docx):
购票渠道以官方渠道为主，包括上海迪士尼官网、官方App、微信公众号及小程序。第三方平台如飞猪、携程等合作代理商也可购票，但需认准官方授权标识。所有电子票需绑定身 份证件，港澳台居民可用通行证，外籍游客用护照，儿童票需提供出生证明或户口本复印件。


[用户问题]
我想了解一下迪士尼门票的退款流程

--- Prompt End ---

  - 步骤 3: 调用 LLM 生成最终答案...

--- 最终答案 ---
关于上海迪士尼门票的退款流程，目前根据官方规定，**已售出的门票不支持退票**。但若您因特殊原因无法使用门票，可参考以下情况：

1. **未使用的电子票**：若门票尚未使用，且在有效期内，您可以通过官方渠道（如上海迪士尼官网、官方App、微信公众号及小程序）申请“门票延期”服务，将门票有效期顺延至后续可用日期。

2. **特殊情况**：如遇上海迪士尼乐园临时关闭或重大不可抗力因素导致无法入园，官方会发布通知并提供相应解决方案，包括免费延期或退款。

建议您通过上海迪士尼官方渠道查询最新政策或联系客服获取帮助。请务必认准官方授权渠道，避免通过非正规平台购票。

---------------------------------------------


--- 收到用户提问: '最近万圣节的活动海报是什么' ---
  - 步骤 1: 向量化查询并进行检索...
    - 文本检索命中 (ID: 12, 距离: 1.1134)
    - 文本检索命中 (ID: 8, 距离: 1.1237)
    - 文本检索命中 (ID: 13, 距离: 1.2508)
  - 检测到图像查询关键词，执行图像检索...
    - 图像检索命中 (ID: 30, 距离: 165.7778)
  - 步骤 2: 构建 Prompt...
--- Prompt Start ---
你是一个迪士尼客服助手。请根据以下背景知识，用友好和专业的语气回答用户的问题。请只使用背景知识中的信息，不要自行发挥。

[背景知识]
背景知识 1 (来源: 1-上海迪士尼门票规则.docx):
疫情防控常态化期间仍需备好随申码，体温检测异常者需在临时观察区等待复查。雨天政策照常运营，雷暴天气部分户外项目暂停，可凭票根在官网申请雨天补偿券。季节性活动期间票价可能上浮，如万圣节夜场票需单独购买。

背景知识 2 (来源: 1-上海迪士尼门票规则.docx):
生日福利需在官方渠道登记，可获赠生日徽章和甜品券。半年内有效结婚证持有者可购买特别套票，含皇家宴会厅双人餐。军人优惠现役及退役军人凭证件享8折，需至少提前3天登记审批。

背景知识 3 (来源: 1-上海迪士尼门票规则.docx):
票务诈骗常见于二手平台，注意识别票面二维码真伪。转赠门票需在官方渠道操作，私下转让可能导致门票失效。员工折扣票仅限在职员工直系亲属使用，需提前报备个人信息。  

背景知识 4 (来源: 独立图片: 1-聚在一起说奇妙.jpg):
找到一张相关图片，图片路径: disney_knowledge_base\images\1-聚在一起说奇妙.jpg。图片上的文字是: ''


[用户问题]
最近万圣节的活动海报是什么

--- Prompt End ---

  - 步骤 3: 调用 LLM 生成最终答案...

--- 最终答案 ---
很抱歉，我无法提供最近万圣节活动的海报。建议您访问上海迪士尼度假区官方网站或官方社交媒体平台，获取最新的活动资讯和海报信息。

(同时，我为您找到了相关图片，路径为: disney_knowledge_base\images\1-聚在一起说奇妙.jpg)

---------------------------------------------


--- 收到用户提问: '迪士尼年卡有什么优惠' ---
  - 步骤 1: 向量化查询并进行检索...
    - 文本检索命中 (ID: 14, 距离: 0.6444)
    - 文本检索命中 (ID: 27, 距离: 0.6526)
    - 文本检索命中 (ID: 5, 距离: 0.7085)
  - 步骤 2: 构建 Prompt...
--- Prompt Start ---
你是一个迪士尼客服助手。请根据以下背景知识，用友好和专业的语气回答用户的问题。请只使用背景知识中的信息，不要自行发挥。

[背景知识]
背景知识 1 (来源: 2-迪士尼老人票价规定.docx):
迪士尼老人票价规定

背景知识 2 (来源: 4-上海迪士尼乐园酒店会员制度.docx):
首先迪士尼vip服务大致分为三种，一种是尊享卡（园区内十二个热门项目可单独购买）入园以后在上海迪士尼度假区app绑定门票以后可购买，这相当于单次的快速通道，价格的话每天都会有波动，客流量小的日子单次80一位，客流量大的日子会有单次100，120，150，180等价格不等，具体以app公布为准。尊享卡由于需要入园购买，所以入园比较晚的朋友 可能会买不到，因为如果尊享卡出售的多了大家都购买排队也就长了，所以官方为了控制尊享卡通道排队时长都是限量出售的，售罄就没了。比较容易售罄的是热门项目，飞跃地平线小矮人矿山车等。但是特别喜欢某个小项目的，就可以多次购买同一个项目的尊享卡，多次进入，曾经淡季时候我儿子把飞跃地平线连刷了五次，当天尊享卡120一次，小孩子还 必须有一个大人陪同，尊享卡是有单独的通道的，一般在正常的免费排队通道旁边，也就是大家通常说的vip通道。

背景知识 3 (来源: 1-上海迪士尼门票规则.docx):
年卡分为宝石卡、珍珠卡、翡翠卡三种，价格从2399元至4399元不等。年卡用户享提前入园、商品餐饮折扣、专属活动等权益。年卡激活需本人持证件办理，补卡费200元，转让需 支付卡面价30%手续费。


[用户问题]
迪士尼年卡有什么优惠

--- Prompt End ---

  - 步骤 3: 调用 LLM 生成最终答案...

--- 最终答案 ---
迪士尼年卡用户可享受以下优惠权益：

- 提前入园
- 商品及餐饮折扣
- 专属活动参与机会

年卡分为宝石卡、珍珠卡、翡翠卡三种，价格从2399元至4399元不等。年卡需本人持证件激活，如需补卡，费用为200元；如转让年卡，需支付卡面价30%的手续费。


paddleocr

Q：老师，源文件分段向量化后，存入向量数据库，然后从向量数据库检索出来的内容和源文件是否完全一样，还是近似
一样
向量数据库 =  embedding（用这个来计算相似度，来筛选） + 原文（给你返回结果）

Q：企业内的知识库信息更新，每次都要重新切片、embedding吗，这个更新机制应该怎么做
增量更新
100个文件 => faiss
再来一个文件  => 添加新的知识



1. 使用多模态跑一遍图片+文字，得到结果A；
2. 用纯文本跑一遍，得到结果B；
3. AB对比评分得出最后结果。
这种方式是否比例子更好



今天的例子中，为什么文本向量维度更高，文本
1000，图像维度500


Q：OCR和CLIP有什么区别
ocr： png => 文本
CLIP： png => 512向量

Q：多模态理解这块，直接用qwenvl3进行大一统就好了吧，不需要做前面的零散的CV任务
可以的


Q：同一个任务如果有物体图像识别，又有OCR提取文本分类，将这两种内容提取做处理的话，需要特意将物体图像和文本图片预先做分类吗


Q：有的答案很简单，比如迟到多久算旷工。 有的答案很长，比如公司完整的企业文化。对于这种情况，可以针对不同的文件进行不同的切片策略吗？
可以
chunk=300
chunk=1000
人工标记 
内容1
===
内容2
===
内容3
===


Q：切片得到的一个文本块是不是就是一个向量
切片就是对原文本做分割 => 还是文本 => embedding模型转换后，就变成向量

Q：从公司的合规考虑，如果我用API计算向量，模型提供商会记录我的原始知识吗？


Q：用RAG回答关于长篇小说或者破案可以吗？可以的话怎么切片比较好？
可以，LLM，人工



Q：老师，可以讲一下RAG系统如何减少幻觉，这个经常作为面试题
LLM输出答案的时候，要带上 参考的来源 [1]
LLM 为什么有幻觉，LLM要生成一个你满意的答案，写一个作文

prompt：根据以下的知识进行用户问题的回答
是有明确的知识


Q：可以这几种切分都跑一遍，然后一起排序比较吗


Q：一份文档里不同切片的大小可以差距很大吗
有可能的


Q：为什么不能通过模型训练来做分块呢这样不应该更准确吗？
LLM

Q：给chat GPT 一个论文，然后问它相关问题，这个属于RAG吗
算


Q：方便转化为向量进行储存


老师，RAG准备：智能文档技术，第75PPT，能再讲详细点吗