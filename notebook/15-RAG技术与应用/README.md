# RAG技术与应用

## RAG 步骤

1. 对优质文档进行某种格式的转换（或者称为编码）。
    - 例如：基于 BERT 将文本段落转换成 *数值格式的向量*（这个称为 embedding），然后将这些 embeddings 存储到合适的数据库（例如 ES 或者 Faiss 等向量数据库）
2. 针对用户进行数据库检索。
    - 对用户输入的 query 进行相同的转换（embeddings），然后利用 *最近邻等相似性算法*，在文档库中寻找最相似的文本段落（与给定答案最相关的段落）。
3. 大模型生成返回给用户的内容。
    - 将找到的文档段落送到大模型，辅助生成最终的输出文本，返回给用户。

PS：主要关注 *步骤一* 和 *步骤二* 的 embeddings & retrieval 阶段。

## 信息检索（information retrieval）技术三大发展阶段

信息检索的发展大致可分为三个阶段：

1. 基于统计信息的关键字匹配（statistical keyword matching）
    - 1970s - 2010s
    - 典型算法：TF-IDF、BM25（对 TD-IDF 的改进）
    - 是一种 sparse embedding —— embedding 向量的大部分字段都是 0；
2. 基于深度学习模型的上下文和语义理解
    - 典型模型：Word2Vec（2013）、BERT（2019）
    - 属于 dense embedding —— embedding 向量的大部分字段都非零；
3. 所谓的“学习型”表示，组合上面两种的优点，称为 learned sparse embedding
    - 既有深度学习模型的上下文和语义理解能力；
    - 又具备稀疏表示的可解释性（interpretability of sparse representations）和低计算复杂度。

## RAG 技术与应用

- 大模型应用开发的三种模式
- RAG 的核心原理与流程
- NativeRAG
- Embedding模型选择
- RAG 常见问题--如何提升 RAG 质量

---

1. 没问清楚 => 提示词工程
2. 缺乏知识 => RAG
3. 能力不足 => 微调

## RAG 的优势

- 解决知识时效性问题
- 减少模型幻觉
- 提升专业领域回答质量

---

流程

1. 数据预处理
    - 知识库构建
    - 文档分块
    - 向量化处理
2. 检索阶段
    - 查询处理
    - 重排序
3. 生成阶段
    - 上下文组装
    - 生成回答

## chunk的大小如何定？

- 300 - 500（小）=> 适合回答细节问题
- 600 - 800（中）
- 1000（大）=> 适合回答整体的宏观一些的问题

## RAG 步骤

- Indexing => 如何更好地把知识存起来
- Retrieval => 如何在大量的知识中，找到一小部分有用的，给到模型参考
- Generation => 如何结合用户的提问和检索到的知识，让模型生成有用的答案

这三个步骤虽然看似简单，但在 RAG 应用从构建到落地实施的整个过程中，涉及较多复杂的工作内容。

## Embedding 模型选择

类型区分

- 通用文本嵌入模型
- 中文嵌入模型
- 指令驱动与复杂任务模型
- 企业级与复杂系统

## LangChain 问答链

**chain_type**

- stuff
- map_reduce
- refine
- map_rerank

## RAG 存在的意义

- 效率与成本
- 知识更新
- 可解释性
- 定制化
- 数据隐私

## 切片策略

- 改进的固定长度切片
- 语义切片
- LLM 语义切片
- 层次切片
- 滑动窗口切片
