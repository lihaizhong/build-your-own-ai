# 机器学习与深度学习理论基础（作业）

> Q: 提问
> MA: 我的答案
> SA: 标准答案
> EXP: 解释

## 单项选择题

【注意】请下载附件的答案，做完之后，自行核对即可。

Q: 机器学习算法通常根据其学习范式进行分类。哪一项最准确地描述了机器学习的三种主要范式？

- A. 监督学习、无监督学习、深度学习
- B. **监督学习、无监督学习、强化学习**
- C. 监督学习、半监督学习、自监督学习
- D. 监督学习、特征工程、模型评估

> MA: C
>
> SA: B
>
> EXP: 
> 这是机器学习最经典和基础的三大分类。
> - 监督学习从标记数据中学习
> - 无监督学习从未标记数据中发现模式
> - 强化学习通过与环境交互学习策略

---

Q: 在线性回归模型的训练过程中，梯度下降算法的核心目标是什么？

- A. **最小化模型在训练数据上的预测误差，通常通过最小化损失函数（如均方误差）来实现**
- B. 最大化模型参数的数量以提高模型复杂度
- C. 确保所有特征对预测结果的贡献相同
- D. 直接计算损失函数的全局最优解

> MA: A
>
> SA: A
>
> EXP:
> 梯度下降是一种优化算法，通过迭代调整模型参数以逐步减小损失函数的值，从而使模型预测更接近真实值。

---

Q: K-means 算法是一种广泛应用的无监督学习算法，其主要目的是什么？

- A. 预测一个连续值输出
- B. **将数据集划分为具有相似特征的 K 个不同的簇**
- C. 降低数据集的维度以便于可视化
- D. 识别数据集中的异常点

> MA: B
>
> SA: B
>
> EXP:
> K-means 的核心思想是将数据点分配到 K 个簇中，使得同一簇内的数据点尽可能相似，不同簇之间的数据点尽可能不同。

---

Q: 在设计神经网络时，激活函数的引入至关重要，它们的主要作用是什么？

- A. 仅用于将神经元的输出限制在特定范围内
- B. **为网络引入非线性，使其能够学习和表示复杂的模式和数据关系**
- C. 减少网络中的参数数量，防止过拟合
- D. 加速网络的收敛速度，但不影响其表达能力

> MA: B
>
> SA: B
>
> EXP:
> 如果没有激活函数或使用线性激活函数，多层神经网络本质上等同于一个单层线性模型，无法学习复杂函数。非线性激活函数是深度学习模型强大表达能力的关键。

---

Q: 神经网络通过反向传播算法进行学习和参数调整。这个过程的核心机制是什么？

- A. 逐层计算网络输出，并将输入数据映射到预测结果
- B. **从网络输出层开始，将误差逐层向后传播，并根据误差梯度更新网络权重**
- C. 随机初始化网络权重，以打破对称性
- D. 在训练过程中动态增加或减少神经元数量

> MA: B
>
> SA: B
>
> EXP:
> 反向传播算法利用链式法则计算损失函数相对于网络各层权重的梯度，然后使用这些梯度通过优化算法（如梯度下降）更新权重。

---

Q: 卷积神经网络（CNN）在图像处理任务中表现出色，其关键的组成部分“卷积层”主要功能是什么？

- A. 对输入特征图进行下采样，减少计算量
- B. 引入非线性，增强模型的表达能力
- C. **通过可学习的滤波器（卷积核）提取输入数据的局部特征，如边缘、纹理等**
- D. 将多维特征图展平为一维向量，以便输入到全连接层

> MA: C
>
> SA: C
>
> EXP:
> 卷积操作通过在输入上滑动卷积核并计算点积，来响应特定的局部模式，这些模式（如边缘、角点）是构成更复杂视觉特征的基础。

---

Q: 深度残差网络（ResNet）通过引入“残差连接”（Skip Connections）有效地解决了什么问题？

- A. 显著减少了模型的参数数量
- B. **使得非常深的网络也能有效训练，缓解了梯度消失和网络退化问题**
- C. 提高了模型对输入扰动的鲁棒性
- D. 实现了模型并行化训练

> MA: B
>
> SA: B
>
> EXP:
> 残差连接允许梯度更直接地反向传播到较早的层，从而缓解了深层网络中常见的梯度消失问题，并解决了网络层数增加时可能出现的性能退化问题。

---

Q: 长短期记忆网络（LSTM）是对传统循环神经网络（RNN）的重要改进，它主要解决了 RNN 在处理序列数据时的哪个核心问题？

- A. 难以处理可变长度的输入序列
- B. 计算成本过高，训练时间过长
- C. **难以捕捉和学习序列中的长期依赖关系，容易出现梯度消失或爆炸**
- D. 无法进行并行计算

> MA: C
>
> SA: C
>
> EXP:
> LSTM 通过其门控机制（输入门、遗忘门、输出门）和细胞状态，能够有选择地记忆和遗忘信息，从而更有效地处理长序列中的依赖关系。

---

Q: Hugging Face Transformers 库对自然语言处理（NLP）领域产生了巨大影响，其主要贡献是什么？

- A. 开发了一种全新的、超越 Transformer 的神经网络架构
- B. **提供了大量预训练的 Transformer 模型和便捷的 API，极大地简化了 SOTA 模型的应用和微调**
- C. 专注于提供高效的分布式训练硬件解决方案
- D. 主要提供传统机器学习算法的实现

> MA: B
>
> SA: B
>
> EXP:
> Hugging Face Transformers 通过提供易于使用的模型库、工具和社区，极大地推动了 Transformer 架构在 NLP 及其他领域的普及和发展。

---

Q: 在深度学习模型训练中，AdamW 优化器相较于 Adam 优化器的主要改进点是什么？

- A. 引入了动量（Momentum）来加速梯度下降
- B. 实现了对每个参数自适应调整学习率
- C. **正确地实现了权重衰减（Weight Decay）与 L2 正则化的解耦，使其更符合原始 L2 正则化的意图，通常能带来更好的泛化性能**
D. 显著减少了优化器的内存占用

> MA: C
>
> SA: C
>
> EXP:
> Adam 中的 L2 正则化（权重衰减）与自适应学习率耦合，可能导致对具有较大梯度的权重施加较小的有效权重衰减。AdamW 通过解耦这两者，使得权重衰减更像原始的 L2 正则化，通常在训练大型模型时效果更好。

---

Q: 当一个机器学习模型在训练数据上表现很好，但在未见过的测试数据上表现较差时，这种情况通常称为什么？

- A. 欠拟合 (Underfitting)
- B. **过拟合 (Overfitting)**
- C. 高偏差 (High Bias)
- D. 模型收敛

> MA: B
>
> SA: B
>
> EXP:
> 过拟合指模型学习了训练数据中的噪声和细节，而不是潜在的数据分布，导致其在训练集上表现优异，但在新数据上泛化能力差。

---

Q: 在机器学习中，“偏差 - 方差权衡”（Bias-Variance Tradeoff）是一个核心概念。一个具有高偏差（High Bias）的模型通常意味着什么？

- A. 模型对训练数据拟合得非常好，但在新数据上泛化能力差
- B. **模型过于简单，未能捕捉到数据中的基本模式，导致在训练数据和测试数据上表现均不佳**
- C. 模型对训练数据的微小变化非常敏感
- D. 模型参数过多，导致计算复杂

> MA: B
>
> SA: B
>
> EXP:
> 高偏差通常与欠拟合相关，意味着模型对数据的假设过于简化，无法很好地拟合训练数据，因此在测试数据上表现也差。

---

Q: 主成分分析（PCA）是一种常用的无监督学习技术，其主要目标是什么？

- A. 将数据点分配到预定义数量的簇中
- B. 预测一个离散的类别标签
- C. **通过线性变换将高维数据投影到低维空间，同时最大程度地保留原始数据的方差**
- D. 识别并移除数据集中的异常值

> MA: C
>
> SA: C
>
> EXP:
> PCA 寻找一组新的正交基（主成分），使得数据在这些基上的投影方差最大，从而在降维的同时保留数据的主要信息。

---

Q: 迁移学习（Transfer Learning）在深度学习中被广泛应用，其核心思想是什么？

- A. 从头开始训练一个全新的模型，不依赖任何已有知识
- B. **将在一个任务上学到的知识（如特征、权重）应用于另一个相关但不同的任务，以提高学习效率和性能**
- C. 仅使用无标签数据进行模型训练
- D. 专注于减少模型训练所需的计算资源

> MA: B
>
> SA: B
>
> EXP:
> 迁移学习利用预训练模型在大规模数据集上学到的通用知识，将其作为新任务的起点，特别使用于目标任务数据量较少的情况。

---

Q: 注意力机制（Attention Mechanism）在深度学习模型中（尤其是在 NLP 和计算机视觉领域）扮演了重要角色，其主要用途是什么？

- A. 显著降低模型训练所需的总计算量
- B. **允许模型在处理输入序列或图像时，动态地将焦点放在与当前任务最相关的部分**
- C. 替代传统的激活函数，提供更好的非线性能力
- D. 作为一种数据增强技术，扩充训练数据集

> MA: B
>
> SA: B
>
> EXP:
> 注意力机制通过为输入的不同部分分配不同的权重，使模型能够“关注”对当前预测或决策更重要的信息，提高了模型的性能和可解释性。

---

## 多项选择题

Q: 以下哪些属于监督学习的典型应用场景或任务？

- A. **根据房屋的面积、位置等特征预测其价格**
- B. **将新闻文章自动分类到体育、政治、科技等类别**
- C. 根据用户的历史购买记录将其划分为不同的消费群体
- D. 从大量未标记的图像中自动识别出不同的物体类别

> MA: A,B,C
>
> SA: A,B
>
> EXP:
> A 是回归问题（预测连续值）
> B 是分类问题（预测离散类别）
> 两者都使用带标签的数据进行训练，是监督学习的典型应用。
> 另外，
> C 是聚类（无监督）
> D 如果图像未标记则是无监督或自监督

---

Q: 以下哪些技术或概念与无监督学习密切相关？

- A. **聚类分析（如 K-means）**
- B. 决策树分类
- C. **降维（如 PCA）**
- D. **图像中物体边缘检测（通常作为特征提取，可用于后续监督或无监督任务，但边缘检测本身可视为一种模式发现）**

> MA: A,B
>
> SA: A,C,D
>
> EXP:
> A 和 C 是经典的无监督学习任务。D 边缘检测可以被视为一种低层次的特征提取，它在没有标签的情况下识别图像中的模式，可以用于后续的无监督或监督学习。B 决策树分类是监督学习。

---

Q: 构成一个典型前馈神经网络（Feedforward Neural Network）的基本元素或过程包括哪些？

- A. **输入层、隐藏层、输出层**
- B. **神经元之间的权重和偏置项**
- C. **每个神经元（除输入层外）的激活函数**
- D. **用于评估模型性能的损失函数和用于参数更新的优化算法**

> MA: A,B,C,D
>
> SA: A,B,C,D
>
> EXP:
> A,B,C 是神经网络结构的核心组成部分；D 是训练神经网络必不可少的过程和工具。

---

Q: 以下哪些是计算机视觉领域中经典的卷积神经网络（CNN）架构？

- A. AlexNet
- B. LSTM (长短期记忆网络)
- C. ResNet (残差网络)
- D. VGG (Visual Geometry Group Network)

> MA: A,B,C
>
> SA: A,C,D
>
> EXP:
> AlexNet，ResNet，VGG 都是计算机视觉发展史上的里程碑式 CNN 架构。LSTM 是 RNN 的一种，主要用于序列数据。

---

Q: 在当前的深度学习实践中，哪些是主流的、被广泛使用的开源深度学习框架？

- A. PyTorch
- B. Scikit-learn (主要用于传统机器学习，但可与 DL 框架配合使用)
- C. TensorFlow
- D. Apache Spark (主要用于大数据处理，包含 MLlib，但非专为深度学习设计)

> MA: A,C
>
> SA: A,C
>
> EXP:
> PyTorch 和 TensorFlow 是目前深度学习领域最主流的两大开源框架。
> Scikit-learn 主要用于传统机器学习。
> Apache Spark MLib 也支持一些机器学习，但不是专为深度学习设计，且不如前两者在深度学习社区流行。
> JAX 也是一个高性能数值计算库，常用于研究和构建 DL 模型，可以认为是主流之一，但相较于 PyTorch 和 TensorFlow，在工业界应用广泛性上可能稍逊。
> 如果题目允许选多个，JAX 也常被认为是主流。
> 考虑到通常选择最核心的，A 和 C 是最无争议的。

---
