# AI大模型基本原理及API使用

---

AI 大模型原理与 API 使用

- AI 的分类
- LLM 是如何训练的
- LLM 中的 token
- Temperature 与 Top P 的作用
- AI Chat 产品的超能力
- 联网搜索、读取文件、记忆功能
- 大模型 API 使用
- 系统提示词与用户提示词
- LLM 的输入与输出 Token 限制

---

## 什么是 AI

1956年 人工智能诞生 1970年 无人驾驶（专家系统）

---
AI 的核心目标是 **让机器能够执行通常需要人类智能的任务**，如语言理解、图像识别、复杂问题解决等

- 早期阶段：以规则为基础的专家系统，依赖预设的逻辑与规则。

- 机器学习时代：通过数据训练模型，使机器能够从数据中学习规律。

- 深度学习时代：利用神经网络模拟人脑的复杂结构，处理更复杂的任务。

- 大模型时代：以大模型数据和算力为基础，构建通用性强、性能卓越的 AI 模型。

---

## AI 的分类

## 分析式AI

- 也成为判别式AI，其核心任务是对已有数据进行分类、预测或决策。

- 优势在于其高精度和高效性，但其局限性在于仅能处理已有数据的模式，无法创造新的内容。

---

### 生成式AI

- 专注于创造新内容，例如文本、图像、音频等。

- 突破在于其创造性和灵活性，但也面临数据隐私、版权保护等挑战。

---

- 大语言模型 LLM
  - GPT系列、DeepSeek、Qwen等
- 生图/生视频模型
  - Gemini 2.5 Flash Image、DALL-E、Midjourney、Sora、即梦等
- 视觉识别模型
  - YOLO、ResNet等

---

## LLM是如何训练的

![GPT 是如何训练出来的](../../public/Pasted_Image_20250830131508.png)

---
早期训练通过人工标注

- [人工智能平台PAI](https://help.aliyun.com/zh/pai/?spm=a2c4g.11186623.0.0.14644cebF5Z70Y)

---

![Rank List 标注平台](../../public/Pasted_Image_20250830132627.png)

---

## LLM中的Token

[查看不同模型是怎么切分你输入的文本的](https://tiktokenizer.vercel.app/)

---

### 特殊标记

- 分隔符（Separator Token）
- 结束符（End-of-Sentence/End-of-Text Token）
- 起始符（Start Token）

---

## Temperature 与 Top P 的原理与作用

控制大模型内容生成的多样性

---

### Temperature（温度）

原理：在模型计算出下一个Token所有可能的概率分布后，Temperature会调整这个分布的“平滑度”。

- 高 -> 更具创造性（低概率的Token）
- 低 -> 更保守（高概率的Token）

---

### Top P （核采样）

原理：它设定一个概率阔值（P），然后从高到低累加所有Token的概率，直到总和超过 P 为止。模型只会在这个累加出来的“核心”词汇表中选择下一个 Token。

- 高 Top P（如 0.9）：候选词汇表较大，结果更多样。
- 低 Top P（如 0.1）：候选词汇表非常小，结果更具确定性。

---

## AI Chat 产品的“超能力”

大模型与外部协作的能力

- 联网搜索
- 读取文件
- 记忆能力

---

## 大模型 API 使用

### 角色

- system 系统
- user 用户
- assistant 助手回复

---

### 系统提示词与用户提示词

- 用户设定AI的角色、行为准则和输入格式，是贯穿对话的全局指令，为其提供了扮演的“人设”。
- 应在对话开始时设定，内容要清晰明确。
- 它会消耗token，不应在其中包含用户的具体问题。（频繁更改可能导致AI行为不稳定）

---

### LLM 的输入与输出 Token 限制

- 模型单词 API 调用能处理的最大信息量，包含系统提示词、历史对话和当前用户输入的所有内容。
- 所有输入内容的总长度不能超过此限制，否则API会报错。
- 我们需要自行管理历史对话长度，比如通过阶段或总结旧消息来确保请求不能超过上限。
