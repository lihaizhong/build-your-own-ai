Q：老师有大模型基础数据用于面试准备吗，类似之前的机器学习西瓜书
提示词工程，RAG，模型微调，大模型幻觉

老师,我的问题比较长。关于分析财务报告。“大型语言模型擅长从冗长报告中提取和总结数据。但其批判性思维能力薄弱，尤其在面对误导性或不完整信息时表现欠佳。分析师仍需
分析师仍需验证AI输出结果，并精心设计提示语以确保可靠性。“
我能想到的，
1，引入置信度；***
2，使用ReAct和深思熟虑模式；
3，FineTune教模型什么是误导或不完整信息，什么是具有批判性和洞察力的报告。
请问还有什么技术能提升吗？
4，RAG （类似的示例）


Q：Coding Agent会把我手动修改的代码改回去，怎么办？
Step1，帮你查看代码，给你建议及置信度（0-100），先不修改代码
Step2，确认后，再让它修改


magic-pdf -p 三 国演义.pdf -o ./output==Error: No such option: -p
是为什么
magic-pdf -h

Q：生成ppt能用一些较好的ppt微调，达到优化生成ppt的内容吗？


Q：本地显卡配置不给力，微调不了是不
autodl.com 


Q：可以直接在Python里装mineru跑出来问题比较少，不用magic-pdf也行
有批量的

Q：我现在写项目都是用灵码去写。
qwen3-coder-plus 还可以


Q：昨天刚做了个批量的
mineru可以批量上传后识别，昨天做过，照着官方示例弄就行了
我是本地运行，不上传，因为保密协议。


有gpu

有gpu的环境 需要额外写调用gpu代码还是程序默认用gpu

kimi 2 thinking 如何

MiniMax-M2很火，现在可以免费用。我用了下，感觉比qwen还要

Stable Difussion
civitai.com/


问的清
不清楚

Q：能力不足的模型，应该都有人做了吧，应该不用自己做我觉得
企业里面会有一些私有知识 => 
1）RAG
2）模型微调


Q：通过微调是不是可以解决rag和提示词能解决的问题，只是成本比较高？
对，成本高
1）GPU 训练时长
2）有可能会带来 降智
测试，之前的已掌握的内容，会不会衰退


Q：微调和蒸馏的关系是什么
在原有的参数上，增加一个  增量的参数 => 让它具备 某些其他的能力
蒸馏：一般是让大模型的知识，进行蒸馏（萃取） =>让小模型来学习


Q：微调需要多少资源
大模型尺寸相关，7B * 2.2=15G以上显存
1K - 1M

Q：数天是几卡？
4卡，8卡

微调：
1）全量微调
7B => 直接对这7B参数进行微调，训练成本高，需要准备的数据量也比较多
在高分辨率的图像上，进行PS 精修
2）高效微调
7B => 不直接对这7B参数进行微调
0.07B 大约1%
4M =>200K 5%



微调就是强化训练？


Q：所以lora是做了一个提取关键词的动作嘛？
LoRA 是一个 大模型的增量版本，7B

Q：现在转化为 微调 9 * 3 和 一个 3 * 9 的两个矩阵
9*9 
rank=3，用 A=9*3  B=3*9




Q：压缩后，再还原会不会降低大模型的质量
会的，
全量微调 质量高



图形是可以叠加的。图层叠加。



Q：没理解降智
修改了模型的参数 => 提升某种能力，因为我是专门给它 某类数据进行训练 （中医药的数据）



Q：老师，升维和降维是一种动态平衡吗？
PS 要对原始的图像进行PS
1000 * 1000 => 100 * 100 =>1000 * 1000

矩阵变换
9*9 变成3*9和9*3，怎样理解为降维和升维？

Q：新数据和旧数据大概是9:1？好像大部分是这个比例
4:1, 1:1, 9:1


这低秩有点类似于数据压缩


秩高=>数据熵高？



怎么找这个W


rag和微调用哪个有常规标准吗，文本模型的话

比如1000行 x 1000列 => 100万的参数 （原始）
1000行 + 1000行和第一行的倍数



Q：如何选定3？是要进行聚类探索来定吗？
人工给定，比如 r=128, 64, 32, 16, 8, 4
压缩式模型自己选择r




Q：R=3的依据是什么？定到多少是合理的？
人给定的，如果你想要更准确，精度更高 R就越大



Q：压缩是模型自己选择r还是人为定义吗？
人为



Q：如果一个小模型比如1B，回答某型特定的问题回答不准确，可以通过微调让他回答准确吗
可以


Loss = 误差 + 正则化项
误差 = (y - y') ^ 2 

方法1：2万/月，网约车 每天8点上班，晚上10点下班，一周工作6天
方法2：2万/月，公务员，每天9点上班，下午5点下班，一周工作5天

正则化项 = 模型的代价


那正则项的公式里面，那两个竖线和两个2是啥意思？

如果只看评分（只看误差）=> 容易过拟合 （训练的时候不错，但是用起来 分数不高）


Q：迭代的是啥？什么参数
迭代的是 模型中的参数权重
LoRA = 增量模型，iteration次

刚才的那些用户是否喜欢某部电影的那张表的数据，就是我们用来作为训练是数据吗？

迭代是为了找特征吗？

1000 * 1000 = 100万参数
R=10
1000*10 + 10*1000=2万
2%



Q：之所以要做lora，是不是对原矩阵不满意，并且目标矩阵已经确定下来，该目标矩阵跟原矩阵之间只存在微小差距，需要通过lora做微调呢？
是的, stable diffusion 已经能画图了，但是缺少某些风格


Q：矩阵分解就是聚类吗？
Rank = 聚类

矩阵反向推导

rank=3，怎么就是12x3 和 3x9呢 两个矩阵谁是增量?
LoRA = 两个小矩阵 （A*B）
A= (12, 3)
B = (3,9)
A * B = (12,3) * (3,9) = (12, 9)


Q：实际大模型里的参数都是模型自己生成的没有明确的含义怎么去进行低秩操作
Rank = 32, 16, 8

这个例子分解2个，实际大模型分解亿级矩阵？


仲夏夜未眠:21:38:34
用户电影表，如果全量微调，
怎么做呢


一颗会跳的葡萄:21:38:49
过拟合的负面影响是什么

Q：实际用的时候是原大模型+微调后的模型，还是只使用微调后的模型？
实际使用，需要 加载 原大模型 + LoRA插件（修改原大模型的权重变化）

1000*1000
100*100
10*10


Q：我想问的是因为电影猜你喜欢这个例子，由A* B以后，还原出来的ΔW就和原来的矩阵几乎对上了，不应该是ΔW+W才和原矩阵一致吗？这里这个例子我没完全理解
猜你喜欢，这个例子 讲解的是矩阵分解
如果将一个大矩阵，分成2个小矩阵，质量不怎么下降的时候，只用了1%的矩阵参数



训练的时候都得准备啥?得写代码训练吗？





Q：比如生成一张图片，原模型生成了一张有瑕疵的图片，LoRA在这张有瑕疵的图片基础上修改瑕疵

没看到增加了什么功能呀，只看到压缩了


Q：老师，能举个例子，微调前后比对的例子，结果好在哪里
微调前，stable diffusion 只能是写实的图像
我想画漫画的，stable diffusion不具备
那么我就准备了很多的漫画，原模型 + LoRA模型（漫画插件） => 画漫画

1000*1000 = 原尺寸

LoRA
1000*10
10*1000
=> 1000*1000 
在原尺寸的参数值的基础上 + LoRA的参数值


LoRA 是帮我们微调模型，在原尺寸模型的基础上，修改权重 => 可以更好的适合，我们给定的任务
如果不用LoRA，用全量微调，我们就需要找到一个 全尺寸的权重变化值 7B

LoRA 只需要找到2个小矩阵，用1%的矩阵，可以还原尺寸的 模型变化量



Q：怎么判断模型需要微调，依据是什么
模型能力不足，且我们有很多垂直的数据 

Q：类似在原模型上用LoRA做个补丁？让模型更准确？
对的

Q：能不能以数据的形式说明。比如没改之前数据是以什么形式存在哪里的，是一个个矩阵吗，存在自己的知识库吗？确定完A和B，马上用他们跑一遍知识库，将一个个矩阵修改一遍？
LLM 是一堆参数，假设参数是7B
query =>LLM => answer)
新的训练数据(Q, answer)
LLM + LoRA （低秩矩阵分解 R）


奇异值分解是不是原来推荐算法的实现方式？

AI里头都是二维矩阵吗？是否有三维矩阵，或者矩阵元素里头是否会有复数？


Q：lora 只是处理图片任务么
中医药的大模型的训练，原始大模型是普通的智能问答，LoRA
金融智能的问题

Q：那用LoRA修改后会影响原来任务的完成度吗？改成画漫画的会不会写实的画不出来了
有可能

<Q, 参考A>

微调会用到LLaMA-Factory、XTuner 这些工具软件吗，它们在微调操作中起到什么作用？
Unsloth

怎么租显卡
autodl.com



